{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This is a warning message this should be printed on your console, its level is above the set level\n",
      "INFO:root:This is an info message it should be printed now!\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler, TensorDataset\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import logging\n",
    "# Some weird stuff with logging going wrong, so manually disabling the root level. \n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "logging.basicConfig(level=logging.INFO) \n",
    "logging.warning('This is a warning message this should be printed on your console, its level is above the set level')\n",
    "logging.info('This is an info message it should be printed now!')\n",
    "logging.debug('This is a debug message which will not be shown, its level is below the set level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.tokenization_utils:Model name 'pdelobelle/robBERT-base' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming 'pdelobelle/robBERT-base' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/pdelobelle/robBERT-base/vocab.json from cache at /Users/lottewillems/.cache/torch/transformers/dc380186a811c183c3e4c18f48dcb0ccc43b3911653369b7e5ed1b4c6d248931.6a4061e8fc00057d21d80413635a86fdcf55b6e7594ad9e25257d2f99a02f4be\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/pdelobelle/robBERT-base/merges.txt from cache at /Users/lottewillems/.cache/torch/transformers/e5cbecfea4fc4f89fc09c0cb9c97c6093599463446706de81f575ffd1b19deb2.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/pdelobelle/robBERT-base/added_tokens.json from cache at None\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/pdelobelle/robBERT-base/special_tokens_map.json from cache at None\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/pdelobelle/robBERT-base/tokenizer_config.json from cache at None\n",
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/pdelobelle/robBERT-base/config.json from cache at /Users/lottewillems/.cache/torch/transformers/09385ae6c6a71a27f2346100bcf0141e76ca5a72ef7e0846896a07aee8ed222d.fdbcc22c14cda4b40b6c8a68eefccabecd218231a7f1d1fbe2a0f15c2d89331e\n",
      "INFO:transformers.configuration_utils:Model config RobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/pdelobelle/robBERT-base/pytorch_model.bin from cache at /Users/lottewillems/.cache/torch/transformers/a486cfc21a11b156d73aa28303ea569aecf93e9f24b223c0c9738c0d532812f7.e57a33d420083e3f2f2027797e1accb95d3692603e543ab6de958b9c9ddb2d08\n",
      "INFO:transformers.modeling_utils:Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"pdelobelle/robBERT-base\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"pdelobelle/robBERT-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath(os.path.join('..')))\n",
    "from src.train import Train as RobBERTTrainer\n",
    "from src.textdataset import TextDataset, load_and_cache_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train_config import Config\n",
    "config = Config()\n",
    "config.evaluate_dataset = \"../data/processed/dbrd/eval\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the data\n",
    "We use `load_and_cache_examples` to load in the training data, this will produce a tokenized version with torch tensors.\n",
    "\n",
    "For the test and evaluation sets, we'll use the following `evaluate` function, since we're in the end interested in a dataframe with all inputs and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataset, model):\n",
    "    df = pd.read_table(dataset + \".labels.txt\", header=None, names=['labels'])\n",
    "    df['sentence'] = pd.read_table(dataset + \".sentences.txt\", header=None, names=['sentence'])\n",
    "    model.eval() # disable dropout etc.\n",
    "    \n",
    "    mask_padding_with_zero = True\n",
    "    block_size = 512\n",
    "    results = []\n",
    "    for row in tqdm(df.iterrows(), total=len(df), mininterval=1, position=1, leave=True):\n",
    "        index = row[0]\n",
    "        sentence = row[1]['sentence']\n",
    "        label = row[1]['labels']\n",
    "\n",
    "        #tokens = roberta.encode(sentence)\n",
    "\n",
    "        tokenized_text = tokenizer.encode(tokenizer.tokenize(sentence)[- block_size + 3 : -1])\n",
    "\n",
    "        input_mask = [1 if mask_padding_with_zero else 0] * len(tokenized_text)\n",
    "\n",
    "        pad_token = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "        while len(tokenized_text) < block_size:\n",
    "            tokenized_text.append(pad_token)\n",
    "            input_mask.append(0 if mask_padding_with_zero else 1)\n",
    "            #segment_ids.append(pad_token_segment_id)\n",
    "            #p_mask.append(1)\n",
    "\n",
    "        #self.examples.append([tokenizer.build_inputs_with_special_tokens(tokenized_text[0 : block_size]), [0], [0]])\n",
    "        batch = tuple(torch.tensor(t).to(torch.device(\"cpu\")) for t in [tokenized_text[0 : block_size - 3], input_mask[0 : block_size- 3], [0], [1] if label else [0]])\n",
    "        inputs = {\"input_ids\": batch[0].unsqueeze(0), \"attention_mask\": batch[1].unsqueeze(0), \"labels\": batch[3].unsqueeze(0)}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "            results.append({\"sentence\": sentence, \"true\": label, \"predicted\": outputs[1][0].argmax().item()})\n",
    "\n",
    "    model.train() # make sure the model is back in training mode\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.textdataset:Creating features from dataset file at ../data/processed/dbrd\n",
      "INFO:src.textdataset:Saving features into cached file ../data/processed/dbrd/roberta_cached_lm_512_train\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_and_cache_examples(\"roberta\", tokenizer, \"../data/processed/dbrd/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Put RobBERT in training mode\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "logging.info(\"Put RobBERT in training mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "from pycm import ConfusionMatrix\n",
    "\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except ImportError:\n",
    "    from tensorboardX import SummaryWriter\n",
    "\n",
    "import json\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "class Train:\n",
    "    def train(args, train_dataset, model, tokenizer, evaluate_fn=None):\n",
    "        \"\"\" Train the model \"\"\"\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        model.train()\n",
    "\n",
    "        if args.local_rank in [-1, 0]:\n",
    "            tb_writer = SummaryWriter()\n",
    "            \n",
    "        # My device does not have GPU so args.device = cpu\n",
    "        args.device = \"cpu\"\n",
    "        args.n_gpu = torch.cuda.device_count() # 0\n",
    "        args.per_gpu_train_batch_size = 2\n",
    "        args.gradient_accumulation_steps = 4\n",
    "        \n",
    "        args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
    "        train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
    "        train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n",
    "        \n",
    "        args.output_dir = \"./dbrd_model2/\"\n",
    "        args.model_name_or_path = \"./dbrd_model2/\"\n",
    "    \n",
    "        if args.max_steps > 0:\n",
    "            t_total = args.max_steps\n",
    "            args.num_train_epochs = 2 ## args.max_steps // (len(train_dataset) // args.gradient_accumulation_steps) + 1\n",
    "        else:\n",
    "            t_total = len(train_dataset) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "\n",
    "        # Prepare optimizer and schedule (linear warmup and decay)\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": args.weight_decay,\n",
    "            },\n",
    "            {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "        ]\n",
    "\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
    "        )\n",
    "\n",
    "        # Check if saved optimizer or scheduler states exist\n",
    "        if os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\")) and os.path.isfile(\n",
    "            os.path.join(args.model_name_or_path, \"scheduler.pt\")\n",
    "        ):\n",
    "            # Load in optimizer and scheduler states\n",
    "            optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
    "            scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
    "\n",
    "        # device = cpu, I don't have a GPU\n",
    "        model.to(args.device)\n",
    "\n",
    "        # Train!\n",
    "        logging.info(\"***** Running training *****\")\n",
    "        logging.info(\"  Num examples = %d\", len(train_dataset))\n",
    "        logging.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
    "        logging.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
    "        logging.info(\n",
    "            \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
    "            args.train_batch_size\n",
    "            * args.gradient_accumulation_steps\n",
    "            * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n",
    "        )\n",
    "        logging.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
    "        logging.info(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "        global_step = 0\n",
    "        epochs_trained = 0\n",
    "        steps_trained_in_current_epoch = 0\n",
    "        \n",
    "        # Check if continuing training from a checkpoint\n",
    "#         if os.path.exists(args.model_name_or_path):\n",
    "#             # set global_step to gobal_step of last saved checkpoint from model path\n",
    "#             global_step = 0 # from global_step.txt\n",
    "#             epochs_trained = global_step // (len(train_dataset) // args.gradient_accumulation_steps)\n",
    "#             steps_trained_in_current_epoch = global_step % (len(train_dataset) // args.gradient_accumulation_steps)\n",
    "\n",
    "#             logging.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
    "#             logging.info(\"  Continuing training from epoch %d\", epochs_trained)\n",
    "#             logging.info(\"  Continuing training from global step %d\", global_step)\n",
    "#             logging.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n",
    "\n",
    "        tr_loss, logging_loss = 0.0, 0.0\n",
    "        model.zero_grad()\n",
    "        train_iterator = trange(\n",
    "            epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0],\n",
    "        )\n",
    "        # set_seed(args)  # Added here for reproductibility\n",
    "        for _ in train_iterator:\n",
    "            epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0], position=0, leave=True)\n",
    "            for step, batch in enumerate(epoch_iterator):\n",
    "\n",
    "                # Skip past any already trained steps if resuming training\n",
    "                if steps_trained_in_current_epoch > 0:\n",
    "                    steps_trained_in_current_epoch -= 1\n",
    "                    continue\n",
    "\n",
    "                model.train()\n",
    "                batch = tuple(t.to(args.device) for t in batch)\n",
    "                inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[3]}\n",
    "                if args.model_type != \"distilbert\":\n",
    "                    inputs[\"token_type_ids\"] = (\n",
    "                        batch[2] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
    "                    )  # XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids\n",
    "                outputs = model(**inputs)\n",
    "                loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
    "                \n",
    "                if args.gradient_accumulation_steps > 1:\n",
    "                    loss = loss / args.gradient_accumulation_steps\n",
    "                \n",
    "                loss.backward()\n",
    "\n",
    "                tr_loss += loss.item()\n",
    "                \n",
    "                if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()  # Update learning rate schedule\n",
    "                    model.zero_grad()\n",
    "                    global_step += 1\n",
    "                    \n",
    "                    if global_step % 20 == 0:\n",
    "                        output_dir = args.output_dir #os.path.join(args.output_dir, \"checkpoint-{}\".format(global_step))\n",
    "                        file_global_step = open(\"global_step.txt\",\"w\") # write mode \n",
    "                        file_global_step.write(str(global_step))\n",
    "                        file_global_step.close()\n",
    "                        model_to_save = (model.module if hasattr(model, \"module\") else model)\n",
    "                        model_to_save.save_pretrained(output_dir)\n",
    "                        tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "                        torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
    "                        logging.info(\"Saving model checkpoint to %s\", output_dir)\n",
    "\n",
    "                        torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
    "                        torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
    "                        logging.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n",
    "\n",
    "                    if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
    "                        logs = {}\n",
    "                        if (\n",
    "                            args.local_rank == -1 and args.evaluate_during_training\n",
    "                        ):  # Only evaluate when single GPU otherwise metrics may not average well\n",
    "                            # I don't have a GPU.. \n",
    "                            results = evaluate(args, model, tokenizer)\n",
    "                            for key, value in results.items():\n",
    "                                eval_key = \"eval_{}\".format(key)\n",
    "                                logs[eval_key] = value\n",
    "\n",
    "                        loss_scalar = (tr_loss - logging_loss) / args.logging_steps\n",
    "                        learning_rate_scalar = scheduler.get_lr()[0]\n",
    "                        logs[\"learning_rate\"] = learning_rate_scalar\n",
    "                        logs[\"loss\"] = loss_scalar\n",
    "                        logging_loss = tr_loss\n",
    "\n",
    "                        for key, value in logs.items():\n",
    "                            tb_writer.add_scalar(key, value, global_step)\n",
    "                        epoch_iterator.set_postfix({**logs, **{\"step\": global_step}})\n",
    "                    \n",
    "                if args.max_steps > 0 and global_step > args.max_steps:\n",
    "                    epoch_iterator.close()\n",
    "                    break\n",
    "            if args.max_steps > 0 and global_step > args.max_steps:\n",
    "                train_iterator.close()\n",
    "                break\n",
    "\n",
    "            if evaluate_fn is not None:\n",
    "                results = pd.DataFrame(evaluate_fn(args.evaluate_dataset, model))\n",
    "                cm = ConfusionMatrix(actual_vector=results['true'].values, predict_vector=results['predicted'].values)\n",
    "                logs = {}\n",
    "                logs[\"eval_f1_macro\"] = cm.F1_Macro\n",
    "                logs[\"eval_acc_macro\"] = cm.ACC_Macro\n",
    "                logs[\"eval_acc_overall\"] = cm.Overall_ACC\n",
    "                logging.info(\"Results on eval: {}\".format(logs))\n",
    "\n",
    "\n",
    "        if args.local_rank in [-1, 0]:\n",
    "            tb_writer.close()\n",
    "        \n",
    "        return global_step, tr_loss / global_step, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:***** Running training *****\n",
      "INFO:root:  Num examples = 10029\n",
      "INFO:root:  Num Epochs = 2\n",
      "INFO:root:  Instantaneous batch size per GPU = 2\n",
      "INFO:root:  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "INFO:root:  Gradient Accumulation steps = 4\n",
      "INFO:root:  Total optimization steps = 2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:   0%|          | 3/5015 [00:23<11:25:47,  8.21s/it]\u001b[A/Users/lottewillems/opt/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "Iteration:   2%|▏         | 79/5015 [09:47<9:22:30,  6.84s/it, learning_rate=6.74e-6, loss=0.00156, step=19]  INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:   3%|▎         | 159/5015 [19:33<9:19:38,  6.91s/it, learning_rate=6.17e-6, loss=0.000416, step=39] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:   5%|▍         | 239/5015 [29:09<9:03:18,  6.83s/it, learning_rate=5.6e-6, loss=0.738, step=59]     INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:   6%|▋         | 319/5015 [38:54<8:56:24,  6.85s/it, learning_rate=5.03e-6, loss=0.000675, step=79] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:   8%|▊         | 399/5015 [48:36<8:54:56,  6.95s/it, learning_rate=4.46e-6, loss=1.66, step=99]     INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  10%|▉         | 479/5015 [58:12<8:39:31,  6.87s/it, learning_rate=3.89e-6, loss=0.48, step=119]    INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  11%|█         | 559/5015 [1:07:47<8:29:52,  6.87s/it, learning_rate=3.31e-6, loss=0.145, step=139]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  13%|█▎        | 639/5015 [1:17:23<8:20:56,  6.87s/it, learning_rate=2.74e-6, loss=0.163, step=159]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  14%|█▍        | 719/5015 [1:26:58<8:13:12,  6.89s/it, learning_rate=2.17e-6, loss=0.00682, step=179]  INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  16%|█▌        | 799/5015 [1:36:33<8:03:23,  6.88s/it, learning_rate=1.6e-6, loss=1.42, step=199]      INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  18%|█▊        | 879/5015 [1:46:10<7:54:00,  6.88s/it, learning_rate=1.03e-6, loss=0.00207, step=219]  INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  19%|█▉        | 959/5015 [1:55:48<7:46:43,  6.90s/it, learning_rate=4.57e-7, loss=0.98, step=239]    INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  21%|██        | 1039/5015 [2:05:22<7:36:09,  6.88s/it, learning_rate=0, loss=0.00101, step=259]       INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  22%|██▏       | 1119/5015 [2:14:55<7:28:07,  6.90s/it, learning_rate=0, loss=0.74, step=279]    INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  24%|██▍       | 1199/5015 [2:24:31<7:18:37,  6.90s/it, learning_rate=0, loss=0.667, step=299]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  26%|██▌       | 1279/5015 [2:34:10<7:09:50,  6.90s/it, learning_rate=0, loss=1.03, step=319]    INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  27%|██▋       | 1359/5015 [2:44:04<7:02:59,  6.94s/it, learning_rate=0, loss=0.000599, step=339]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  29%|██▊       | 1439/5015 [2:53:46<6:50:42,  6.89s/it, learning_rate=0, loss=0.469, step=359]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  30%|███       | 1519/5015 [3:03:21<6:38:28,  6.84s/it, learning_rate=0, loss=0.000956, step=379]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  32%|███▏      | 1599/5015 [3:12:56<6:30:32,  6.86s/it, learning_rate=0, loss=0.0041, step=399]  INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  33%|███▎      | 1679/5015 [3:22:32<6:22:57,  6.89s/it, learning_rate=0, loss=1.65, step=419]    INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  35%|███▌      | 1759/5015 [3:32:06<6:13:31,  6.88s/it, learning_rate=0, loss=0.496, step=439]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  37%|███▋      | 1839/5015 [3:41:41<6:04:09,  6.88s/it, learning_rate=0, loss=0.000975, step=459]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  38%|███▊      | 1919/5015 [3:51:18<5:53:46,  6.86s/it, learning_rate=0, loss=0.00262, step=479] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  40%|███▉      | 1999/5015 [4:00:52<5:43:57,  6.84s/it, learning_rate=0, loss=0.00318, step=499] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  41%|████▏     | 2079/5015 [4:10:26<5:35:30,  6.86s/it, learning_rate=0, loss=0.000627, step=519]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  43%|████▎     | 2159/5015 [4:20:00<5:27:56,  6.89s/it, learning_rate=0, loss=0.668, step=539]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  45%|████▍     | 2239/5015 [4:29:39<5:19:53,  6.91s/it, learning_rate=0, loss=0.000589, step=559]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  46%|████▌     | 2319/5015 [4:39:26<5:09:27,  6.89s/it, learning_rate=0, loss=0.00533, step=579] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  48%|████▊     | 2399/5015 [4:49:06<4:59:32,  6.87s/it, learning_rate=0, loss=0.539, step=599]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  49%|████▉     | 2479/5015 [4:58:40<4:50:04,  6.86s/it, learning_rate=0, loss=0.0178, step=619]  INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  51%|█████     | 2559/5015 [5:08:14<4:40:54,  6.86s/it, learning_rate=0, loss=0.000887, step=639]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  53%|█████▎    | 2639/5015 [5:17:48<4:30:40,  6.84s/it, learning_rate=0, loss=0.685, step=659]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  54%|█████▍    | 2719/5015 [5:27:22<4:22:04,  6.85s/it, learning_rate=0, loss=0.00133, step=679] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  56%|█████▌    | 2799/5015 [5:36:55<4:12:41,  6.84s/it, learning_rate=0, loss=0.665, step=699]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  57%|█████▋    | 2879/5015 [5:46:31<4:20:25,  7.32s/it, learning_rate=0, loss=0.0208, step=719]  INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  59%|█████▉    | 2959/5015 [5:56:12<4:17:29,  7.51s/it, learning_rate=0, loss=0.000724, step=739]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  61%|██████    | 3039/5015 [6:05:53<3:48:05,  6.93s/it, learning_rate=0, loss=0.000826, step=759]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  62%|██████▏   | 3119/5015 [6:15:30<3:38:54,  6.93s/it, learning_rate=0, loss=0.000992, step=779]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  64%|██████▍   | 3199/5015 [6:25:06<3:29:26,  6.92s/it, learning_rate=0, loss=0.0211, step=799]  INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  65%|██████▌   | 3279/5015 [6:34:39<3:19:35,  6.90s/it, learning_rate=0, loss=0.0126, step=819]  INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  67%|██████▋   | 3359/5015 [6:44:24<3:11:58,  6.96s/it, learning_rate=0, loss=0.000693, step=839]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  69%|██████▊   | 3439/5015 [6:54:02<3:00:42,  6.88s/it, learning_rate=0, loss=0.000629, step=859]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  70%|███████   | 3519/5015 [7:03:36<2:51:06,  6.86s/it, learning_rate=0, loss=0.00092, step=879] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  72%|███████▏  | 3599/5015 [7:13:11<2:41:06,  6.83s/it, learning_rate=0, loss=0.000572, step=899]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  73%|███████▎  | 3679/5015 [7:22:44<2:32:37,  6.85s/it, learning_rate=0, loss=0.32, step=919]    INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  75%|███████▍  | 3759/5015 [7:32:18<2:23:18,  6.85s/it, learning_rate=0, loss=0.00108, step=939] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  77%|███████▋  | 3839/5015 [7:41:51<2:13:51,  6.83s/it, learning_rate=0, loss=0.000735, step=959]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  78%|███████▊  | 3919/5015 [7:51:27<2:04:54,  6.84s/it, learning_rate=0, loss=0.000554, step=979]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  80%|███████▉  | 3999/5015 [8:00:59<1:55:40,  6.83s/it, learning_rate=0, loss=0.00069, step=999] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  81%|████████▏ | 4079/5015 [8:10:33<1:47:01,  6.86s/it, learning_rate=0, loss=0.00106, step=1019] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  83%|████████▎ | 4159/5015 [8:20:06<1:37:53,  6.86s/it, learning_rate=0, loss=0.000744, step=1039]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  85%|████████▍ | 4239/5015 [8:29:41<1:28:44,  6.86s/it, learning_rate=0, loss=0.000809, step=1059]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  86%|████████▌ | 4319/5015 [8:39:24<1:19:18,  6.84s/it, learning_rate=0, loss=0.429, step=1079]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  88%|████████▊ | 4399/5015 [8:49:00<1:10:22,  6.86s/it, learning_rate=0, loss=0.663, step=1099]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  89%|████████▉ | 4479/5015 [8:58:36<1:01:16,  6.86s/it, learning_rate=0, loss=0.00231, step=1119] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  91%|█████████ | 4559/5015 [9:08:10<52:03,  6.85s/it, learning_rate=0, loss=0.00349, step=1139]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  93%|█████████▎| 4639/5015 [9:17:44<42:54,  6.85s/it, learning_rate=0, loss=0.000704, step=1159] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  94%|█████████▍| 4719/5015 [9:27:18<33:54,  6.87s/it, learning_rate=0, loss=0.000955, step=1179]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  96%|█████████▌| 4799/5015 [9:36:53<24:51,  6.90s/it, learning_rate=0, loss=0.188, step=1199]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  97%|█████████▋| 4879/5015 [9:46:30<16:03,  7.08s/it, learning_rate=0, loss=0.504, step=1219]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  99%|█████████▉| 4959/5015 [9:56:04<06:25,  6.88s/it, learning_rate=0, loss=0.012, step=1239]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration: 100%|██████████| 5015/5015 [10:02:44<00:00,  5.94s/it, learning_rate=0, loss=0.0367, step=1253]  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A                       \n",
      "\n",
      "\u001b[A\u001b[A                                      \n",
      "\u001b[A                                         \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A                                   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A                          \n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A                                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration: 100%|██████████| 5015/5015 [10:02:44<00:00,  7.21s/it, learning_rate=0, loss=0.0367, step=1253]\n",
      "\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 5/500 [00:01<01:45,  4.70it/s]\u001b[A\n",
      "  2%|▏         | 11/500 [00:02<01:39,  4.91it/s]\u001b[A\n",
      "  3%|▎         | 17/500 [00:03<01:34,  5.12it/s]\u001b[A\n",
      "  5%|▍         | 24/500 [00:04<01:28,  5.35it/s]\u001b[A\n",
      "  6%|▌         | 30/500 [00:05<01:25,  5.53it/s]\u001b[A\n",
      "  7%|▋         | 36/500 [00:06<01:22,  5.66it/s]\u001b[A\n",
      "  9%|▊         | 43/500 [00:07<01:19,  5.78it/s]\u001b[A\n",
      " 10%|█         | 50/500 [00:08<01:16,  5.87it/s]\u001b[A\n",
      " 11%|█▏        | 57/500 [00:09<01:14,  5.96it/s]\u001b[A\n",
      " 13%|█▎        | 64/500 [00:10<01:12,  6.01it/s]\u001b[A\n",
      " 14%|█▍        | 71/500 [00:12<01:11,  6.02it/s]\u001b[A\n",
      " 15%|█▌        | 77/500 [00:13<01:10,  6.00it/s]\u001b[A\n",
      " 17%|█▋        | 84/500 [00:14<01:08,  6.05it/s]\u001b[A\n",
      " 18%|█▊        | 91/500 [00:15<01:07,  6.04it/s]\u001b[A\n",
      " 20%|█▉        | 98/500 [00:16<01:06,  6.09it/s]\u001b[A\n",
      " 21%|██        | 105/500 [00:17<01:04,  6.09it/s]\u001b[A\n",
      " 22%|██▏       | 112/500 [00:18<01:03,  6.11it/s]\u001b[A\n",
      " 24%|██▍       | 119/500 [00:19<01:02,  6.10it/s]\u001b[A\n",
      " 25%|██▌       | 126/500 [00:21<01:01,  6.09it/s]\u001b[A\n",
      " 27%|██▋       | 133/500 [00:22<01:00,  6.10it/s]\u001b[A\n",
      " 28%|██▊       | 140/500 [00:23<00:59,  6.10it/s]\u001b[A\n",
      " 29%|██▉       | 147/500 [00:24<00:57,  6.09it/s]\u001b[A\n",
      " 31%|███       | 154/500 [00:25<00:56,  6.12it/s]\u001b[A\n",
      " 32%|███▏      | 161/500 [00:26<00:55,  6.11it/s]\u001b[A\n",
      " 34%|███▎      | 168/500 [00:28<00:54,  6.12it/s]\u001b[A\n",
      " 35%|███▌      | 175/500 [00:29<00:53,  6.13it/s]\u001b[A\n",
      " 36%|███▋      | 182/500 [00:30<00:51,  6.15it/s]\u001b[A\n",
      " 38%|███▊      | 189/500 [00:31<00:50,  6.15it/s]\u001b[A\n",
      " 39%|███▉      | 196/500 [00:32<00:49,  6.14it/s]\u001b[A\n",
      " 41%|████      | 203/500 [00:33<00:48,  6.14it/s]\u001b[A\n",
      " 42%|████▏     | 210/500 [00:34<00:47,  6.14it/s]\u001b[A\n",
      " 43%|████▎     | 217/500 [00:35<00:46,  6.14it/s]\u001b[A\n",
      " 45%|████▍     | 224/500 [00:37<00:44,  6.15it/s]\u001b[A\n",
      " 46%|████▌     | 231/500 [00:38<00:43,  6.14it/s]\u001b[A\n",
      " 48%|████▊     | 238/500 [00:39<00:42,  6.12it/s]\u001b[A\n",
      " 49%|████▉     | 245/500 [00:40<00:41,  6.14it/s]\u001b[A\n",
      " 50%|█████     | 252/500 [00:41<00:40,  6.10it/s]\u001b[A\n",
      " 52%|█████▏    | 259/500 [00:42<00:39,  6.08it/s]\u001b[A\n",
      " 53%|█████▎    | 266/500 [00:44<00:38,  6.08it/s]\u001b[A\n",
      " 55%|█████▍    | 273/500 [00:45<00:37,  6.11it/s]\u001b[A\n",
      " 56%|█████▌    | 280/500 [00:46<00:35,  6.13it/s]\u001b[A\n",
      " 57%|█████▋    | 287/500 [00:47<00:34,  6.14it/s]\u001b[A\n",
      " 59%|█████▉    | 294/500 [00:48<00:36,  5.58it/s]\u001b[A\n",
      " 60%|██████    | 300/500 [00:50<00:35,  5.56it/s]\u001b[A\n",
      " 61%|██████    | 306/500 [00:51<00:34,  5.64it/s]\u001b[A\n",
      " 63%|██████▎   | 313/500 [00:52<00:32,  5.78it/s]\u001b[A\n",
      " 64%|██████▍   | 320/500 [00:53<00:30,  5.89it/s]\u001b[A\n",
      " 65%|██████▌   | 327/500 [00:54<00:28,  5.97it/s]\u001b[A\n",
      " 67%|██████▋   | 334/500 [00:55<00:27,  6.02it/s]\u001b[A\n",
      " 68%|██████▊   | 341/500 [00:56<00:26,  6.04it/s]\u001b[A\n",
      " 70%|██████▉   | 348/500 [00:57<00:25,  6.07it/s]\u001b[A\n",
      " 71%|███████   | 355/500 [00:59<00:23,  6.06it/s]\u001b[A\n",
      " 72%|███████▏  | 362/500 [01:00<00:22,  6.08it/s]\u001b[A\n",
      " 74%|███████▍  | 369/500 [01:01<00:21,  6.08it/s]\u001b[A\n",
      " 75%|███████▌  | 376/500 [01:02<00:20,  6.10it/s]\u001b[A\n",
      " 77%|███████▋  | 383/500 [01:03<00:19,  6.12it/s]\u001b[A\n",
      " 78%|███████▊  | 390/500 [01:04<00:18,  6.10it/s]\u001b[A\n",
      " 79%|███████▉  | 397/500 [01:05<00:16,  6.11it/s]\u001b[A\n",
      " 81%|████████  | 404/500 [01:07<00:15,  6.05it/s]\u001b[A\n",
      " 82%|████████▏ | 411/500 [01:08<00:14,  6.01it/s]\u001b[A\n",
      " 84%|████████▎ | 418/500 [01:09<00:13,  6.04it/s]\u001b[A\n",
      " 85%|████████▌ | 425/500 [01:10<00:12,  6.08it/s]\u001b[A\n",
      " 86%|████████▋ | 432/500 [01:11<00:11,  6.10it/s]\u001b[A\n",
      " 88%|████████▊ | 439/500 [01:12<00:09,  6.11it/s]\u001b[A\n",
      " 89%|████████▉ | 446/500 [01:14<00:08,  6.10it/s]\u001b[A\n",
      " 91%|█████████ | 453/500 [01:15<00:07,  6.12it/s]\u001b[A\n",
      " 92%|█████████▏| 460/500 [01:16<00:06,  6.13it/s]\u001b[A\n",
      " 93%|█████████▎| 467/500 [01:17<00:05,  6.15it/s]\u001b[A\n",
      " 95%|█████████▍| 474/500 [01:18<00:04,  6.15it/s]\u001b[A\n",
      " 96%|█████████▌| 481/500 [01:19<00:03,  6.13it/s]\u001b[A\n",
      " 98%|█████████▊| 488/500 [01:20<00:01,  6.13it/s]\u001b[A\n",
      " 99%|█████████▉| 495/500 [01:21<00:00,  6.13it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 500/500 [01:22<00:00,  6.04it/s]\n",
      "INFO:root:Results on eval: {'eval_f1_macro': 0.8659737308512468, 'eval_acc_macro': 0.866, 'eval_acc_overall': 0.866}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iteration:   1%|          | 27/5015 [03:11<9:32:18,  6.88s/it, learning_rate=0, loss=0.997, step=1259]  INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:   2%|▏         | 107/5015 [12:46<9:21:40,  6.87s/it, learning_rate=0, loss=0.00553, step=1279] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:   4%|▎         | 187/5015 [22:50<9:16:41,  6.92s/it, learning_rate=0, loss=0.000918, step=1299] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:   5%|▌         | 267/5015 [32:39<9:02:53,  6.86s/it, learning_rate=0, loss=0.0042, step=1319]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:   7%|▋         | 347/5015 [42:18<9:19:09,  7.19s/it, learning_rate=0, loss=0.766, step=1339]    INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:   9%|▊         | 427/5015 [51:54<8:46:13,  6.88s/it, learning_rate=0, loss=0.249, step=1359]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  10%|█         | 507/5015 [1:01:33<8:37:12,  6.88s/it, learning_rate=0, loss=0.000615, step=1379]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  12%|█▏        | 587/5015 [1:11:07<8:36:34,  7.00s/it, learning_rate=0, loss=0.000931, step=1399]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  13%|█▎        | 667/5015 [1:20:40<8:18:55,  6.88s/it, learning_rate=0, loss=0.00108, step=1419] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  15%|█▍        | 747/5015 [1:30:14<8:06:04,  6.83s/it, learning_rate=0, loss=0.000973, step=1439]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  16%|█▋        | 827/5015 [1:39:57<7:57:08,  6.84s/it, learning_rate=0, loss=1.3, step=1459]     INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  18%|█▊        | 907/5015 [1:49:38<7:50:49,  6.88s/it, learning_rate=0, loss=0.374, step=1479]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  20%|█▉        | 987/5015 [1:59:23<7:41:30,  6.87s/it, learning_rate=0, loss=0.0647, step=1499]  INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  21%|██▏       | 1067/5015 [2:08:58<7:31:01,  6.85s/it, learning_rate=0, loss=0.242, step=1519]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  23%|██▎       | 1147/5015 [2:18:34<7:21:19,  6.85s/it, learning_rate=0, loss=0.00493, step=1539] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  24%|██▍       | 1227/5015 [2:28:08<7:13:36,  6.87s/it, learning_rate=0, loss=0.117, step=1559]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  26%|██▌       | 1307/5015 [2:37:43<7:03:04,  6.85s/it, learning_rate=0, loss=0.000905, step=1579]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  28%|██▊       | 1387/5015 [2:47:22<6:56:00,  6.88s/it, learning_rate=0, loss=0.611, step=1599]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  29%|██▉       | 1467/5015 [2:56:59<6:45:39,  6.86s/it, learning_rate=0, loss=0.00287, step=1619] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  31%|███       | 1547/5015 [3:06:42<6:36:51,  6.87s/it, learning_rate=0, loss=0.0844, step=1639]  INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  32%|███▏      | 1627/5015 [3:16:19<6:28:51,  6.89s/it, learning_rate=0, loss=0.821, step=1659]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  34%|███▍      | 1707/5015 [3:25:54<6:18:46,  6.87s/it, learning_rate=0, loss=0.00111, step=1679] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  36%|███▌      | 1787/5015 [3:35:42<6:13:05,  6.93s/it, learning_rate=0, loss=0.00184, step=1699] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  37%|███▋      | 1867/5015 [3:45:19<6:02:10,  6.90s/it, learning_rate=0, loss=0.000743, step=1719]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  39%|███▉      | 1947/5015 [3:55:01<5:53:14,  6.91s/it, learning_rate=0, loss=1.09, step=1739]    INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  40%|████      | 2027/5015 [4:04:42<5:42:37,  6.88s/it, learning_rate=0, loss=0.0585, step=1759]  INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  42%|████▏     | 2107/5015 [4:14:17<5:33:00,  6.87s/it, learning_rate=0, loss=1.02, step=1779]    INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  44%|████▎     | 2187/5015 [4:23:53<5:23:42,  6.87s/it, learning_rate=0, loss=0.000854, step=1799]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  45%|████▌     | 2267/5015 [4:33:30<5:13:23,  6.84s/it, learning_rate=0, loss=0.00172, step=1819] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  47%|████▋     | 2347/5015 [4:43:08<5:07:03,  6.91s/it, learning_rate=0, loss=0.3, step=1839]     INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  48%|████▊     | 2427/5015 [4:52:44<4:56:17,  6.87s/it, learning_rate=0, loss=0.523, step=1859]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  50%|████▉     | 2507/5015 [5:02:23<4:46:42,  6.86s/it, learning_rate=0, loss=0.677, step=1879]   INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  52%|█████▏    | 2587/5015 [5:11:59<4:38:47,  6.89s/it, learning_rate=0, loss=0.00236, step=1899] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  53%|█████▎    | 2667/5015 [5:21:33<4:30:07,  6.90s/it, learning_rate=0, loss=0.0449, step=1919]  INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  55%|█████▍    | 2747/5015 [5:31:25<4:23:14,  6.96s/it, learning_rate=0, loss=0.00148, step=1939] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  56%|█████▋    | 2827/5015 [5:41:02<4:17:40,  7.07s/it, learning_rate=0, loss=0.0546, step=1959]  INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  58%|█████▊    | 2907/5015 [5:50:38<4:03:29,  6.93s/it, learning_rate=0, loss=0.00222, step=1979] INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  60%|█████▉    | 2987/5015 [6:00:15<3:53:24,  6.91s/it, learning_rate=0, loss=0.000791, step=1999]INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model2/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model2/pytorch_model.bin\n",
      "INFO:root:Saving model checkpoint to ./dbrd_model2/\n",
      "INFO:root:Saving optimizer and scheduler states to ./dbrd_model2/\n",
      "Iteration:  60%|█████▉    | 2991/5015 [6:01:03<4:29:29,  7.99s/it, learning_rate=0, loss=0.00273, step=2001] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A                                              \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Iteration:  60%|█████▉    | 2991/5015 [6:01:03<4:04:19,  7.24s/it, learning_rate=0, loss=0.00273, step=2001]\n",
      "Epoch:  50%|█████     | 1/2 [16:05:10<16:05:10, 57910.82s/it]\n"
     ]
    }
   ],
   "source": [
    "globalstep, trainloss, optimizer = Train.train(config, train_dataset, model, tokenizer, evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:putting model in eval mode\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "logging.info(\"putting model in eval mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2224 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/2224 [00:03<1:56:49,  3.15s/it]\u001b[A\n",
      "  0%|          | 2/2224 [00:04<1:34:01,  2.54s/it]\u001b[A\n",
      "  0%|          | 3/2224 [00:05<1:17:28,  2.09s/it]\u001b[A\n",
      "  0%|          | 4/2224 [00:06<1:05:35,  1.77s/it]\u001b[A\n",
      "  0%|          | 5/2224 [00:07<57:52,  1.56s/it]  \u001b[A\n",
      "  0%|          | 6/2224 [00:08<52:13,  1.41s/it]\u001b[A\n",
      "  0%|          | 7/2224 [00:09<47:48,  1.29s/it]\u001b[A\n",
      "  0%|          | 8/2224 [00:10<44:50,  1.21s/it]\u001b[A\n",
      "  0%|          | 9/2224 [00:11<43:16,  1.17s/it]\u001b[A\n",
      "  0%|          | 10/2224 [00:12<43:15,  1.17s/it]\u001b[A\n",
      "  0%|          | 11/2224 [00:13<42:27,  1.15s/it]\u001b[A\n",
      "  1%|          | 12/2224 [00:14<41:37,  1.13s/it]\u001b[A\n",
      "  1%|          | 13/2224 [00:15<40:44,  1.11s/it]\u001b[A\n",
      "  1%|          | 14/2224 [00:17<40:00,  1.09s/it]\u001b[A\n",
      "  1%|          | 15/2224 [00:18<39:14,  1.07s/it]\u001b[A\n",
      "  1%|          | 16/2224 [00:19<38:56,  1.06s/it]\u001b[A\n",
      "  1%|          | 17/2224 [00:20<38:44,  1.05s/it]\u001b[A\n",
      "  1%|          | 18/2224 [00:21<38:22,  1.04s/it]\u001b[A\n",
      "  1%|          | 19/2224 [00:22<38:59,  1.06s/it]\u001b[A\n",
      "  1%|          | 20/2224 [00:23<38:48,  1.06s/it]\u001b[A\n",
      "  1%|          | 21/2224 [00:24<38:48,  1.06s/it]\u001b[A\n",
      "  1%|          | 22/2224 [00:25<38:34,  1.05s/it]\u001b[A\n",
      "  1%|          | 23/2224 [00:26<38:19,  1.04s/it]\u001b[A\n",
      "  1%|          | 24/2224 [00:27<38:03,  1.04s/it]\u001b[A\n",
      "  1%|          | 25/2224 [00:28<37:50,  1.03s/it]\u001b[A\n",
      "  1%|          | 26/2224 [00:29<37:49,  1.03s/it]\u001b[A\n",
      "  1%|          | 27/2224 [00:30<37:48,  1.03s/it]\u001b[A\n",
      "  1%|▏         | 28/2224 [00:31<37:52,  1.04s/it]\u001b[A\n",
      "  1%|▏         | 29/2224 [00:32<37:48,  1.03s/it]\u001b[A\n",
      "  1%|▏         | 30/2224 [00:33<37:50,  1.03s/it]\u001b[A\n",
      "  1%|▏         | 31/2224 [00:34<37:49,  1.03s/it]\u001b[A\n",
      "  1%|▏         | 32/2224 [00:35<37:40,  1.03s/it]\u001b[A\n",
      "  1%|▏         | 33/2224 [00:36<37:32,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 34/2224 [00:37<37:32,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 35/2224 [00:38<37:36,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 36/2224 [00:39<37:30,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 37/2224 [00:40<37:26,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 38/2224 [00:41<37:26,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 39/2224 [00:42<37:22,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 40/2224 [00:43<37:19,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 41/2224 [00:44<37:20,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 42/2224 [00:46<37:39,  1.04s/it]\u001b[A\n",
      "  2%|▏         | 43/2224 [00:47<37:37,  1.04s/it]\u001b[A\n",
      "  2%|▏         | 44/2224 [00:48<37:30,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 45/2224 [00:49<37:28,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 46/2224 [00:50<37:33,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 47/2224 [00:51<37:26,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 48/2224 [00:52<37:20,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 49/2224 [00:53<37:18,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 50/2224 [00:54<37:18,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 51/2224 [00:55<37:16,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 52/2224 [00:56<37:16,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 53/2224 [00:57<37:12,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 54/2224 [00:58<37:09,  1.03s/it]\u001b[A\n",
      "  2%|▏         | 55/2224 [00:59<37:11,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 56/2224 [01:00<37:11,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 57/2224 [01:01<37:11,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 58/2224 [01:02<37:05,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 59/2224 [01:03<37:02,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 60/2224 [01:04<37:00,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 61/2224 [01:05<37:04,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 62/2224 [01:06<37:04,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 63/2224 [01:07<36:58,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 64/2224 [01:08<36:59,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 65/2224 [01:09<36:57,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 66/2224 [01:10<36:57,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 67/2224 [01:11<37:02,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 68/2224 [01:12<37:02,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 69/2224 [01:13<37:06,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 70/2224 [01:14<37:01,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 71/2224 [01:15<37:05,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 72/2224 [01:16<36:58,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 73/2224 [01:17<37:01,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 74/2224 [01:18<36:55,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 75/2224 [01:19<36:47,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 76/2224 [01:21<36:52,  1.03s/it]\u001b[A\n",
      "  3%|▎         | 77/2224 [01:22<36:54,  1.03s/it]\u001b[A\n",
      "  4%|▎         | 78/2224 [01:23<36:53,  1.03s/it]\u001b[A\n",
      "  4%|▎         | 79/2224 [01:24<37:02,  1.04s/it]\u001b[A\n",
      "  4%|▎         | 80/2224 [01:25<37:04,  1.04s/it]\u001b[A\n",
      "  4%|▎         | 81/2224 [01:26<36:59,  1.04s/it]\u001b[A\n",
      "  4%|▎         | 82/2224 [01:27<36:51,  1.03s/it]\u001b[A\n",
      "  4%|▎         | 83/2224 [01:28<36:54,  1.03s/it]\u001b[A\n",
      "  4%|▍         | 84/2224 [01:29<36:53,  1.03s/it]\u001b[A\n",
      "  4%|▍         | 85/2224 [01:30<36:49,  1.03s/it]\u001b[A\n",
      "  4%|▍         | 86/2224 [01:31<36:40,  1.03s/it]\u001b[A\n",
      "  4%|▍         | 87/2224 [01:32<36:48,  1.03s/it]\u001b[A\n",
      "  4%|▍         | 88/2224 [01:33<36:48,  1.03s/it]\u001b[A\n",
      "  4%|▍         | 89/2224 [01:34<36:46,  1.03s/it]\u001b[A\n",
      "  4%|▍         | 90/2224 [01:35<36:43,  1.03s/it]\u001b[A\n",
      "  4%|▍         | 91/2224 [01:36<36:43,  1.03s/it]\u001b[A\n",
      "  4%|▍         | 92/2224 [01:37<36:38,  1.03s/it]\u001b[A\n",
      "  4%|▍         | 93/2224 [01:38<37:28,  1.06s/it]\u001b[A\n",
      "  4%|▍         | 94/2224 [01:39<37:24,  1.05s/it]\u001b[A\n",
      "  4%|▍         | 95/2224 [01:40<37:34,  1.06s/it]\u001b[A\n",
      "  4%|▍         | 96/2224 [01:41<37:11,  1.05s/it]\u001b[A\n",
      "  4%|▍         | 97/2224 [01:42<37:04,  1.05s/it]\u001b[A\n",
      "  4%|▍         | 98/2224 [01:43<36:56,  1.04s/it]\u001b[A\n",
      "  4%|▍         | 99/2224 [01:44<36:56,  1.04s/it]\u001b[A\n",
      "  4%|▍         | 100/2224 [01:45<37:01,  1.05s/it]\u001b[A\n",
      "  5%|▍         | 101/2224 [01:46<36:50,  1.04s/it]\u001b[A\n",
      "  5%|▍         | 102/2224 [01:48<36:44,  1.04s/it]\u001b[A\n",
      "  5%|▍         | 103/2224 [01:49<36:45,  1.04s/it]\u001b[A\n",
      "  5%|▍         | 104/2224 [01:50<36:41,  1.04s/it]\u001b[A\n",
      "  5%|▍         | 105/2224 [01:51<36:32,  1.03s/it]\u001b[A\n",
      "  5%|▍         | 106/2224 [01:52<36:32,  1.04s/it]\u001b[A\n",
      "  5%|▍         | 107/2224 [01:53<36:26,  1.03s/it]\u001b[A\n",
      "  5%|▍         | 108/2224 [01:54<36:24,  1.03s/it]\u001b[A\n",
      "  5%|▍         | 109/2224 [01:55<36:19,  1.03s/it]\u001b[A\n",
      "  5%|▍         | 110/2224 [01:56<36:25,  1.03s/it]\u001b[A\n",
      "  5%|▍         | 111/2224 [01:57<36:30,  1.04s/it]\u001b[A\n",
      "  5%|▌         | 112/2224 [01:58<36:23,  1.03s/it]\u001b[A\n",
      "  5%|▌         | 113/2224 [01:59<36:19,  1.03s/it]\u001b[A\n",
      "  5%|▌         | 114/2224 [02:00<36:20,  1.03s/it]\u001b[A\n",
      "  5%|▌         | 115/2224 [02:01<36:18,  1.03s/it]\u001b[A\n",
      "  5%|▌         | 116/2224 [02:02<36:14,  1.03s/it]\u001b[A\n",
      "  5%|▌         | 117/2224 [02:03<36:07,  1.03s/it]\u001b[A\n",
      "  5%|▌         | 118/2224 [02:04<36:11,  1.03s/it]\u001b[A\n",
      "  5%|▌         | 119/2224 [02:05<36:09,  1.03s/it]\u001b[A\n",
      "  5%|▌         | 120/2224 [02:06<36:05,  1.03s/it]\u001b[A\n",
      "  5%|▌         | 121/2224 [02:07<36:06,  1.03s/it]\u001b[A\n",
      "  5%|▌         | 122/2224 [02:08<36:11,  1.03s/it]\u001b[A\n",
      "  6%|▌         | 123/2224 [02:09<36:17,  1.04s/it]\u001b[A\n",
      "  6%|▌         | 124/2224 [02:10<38:41,  1.11s/it]\u001b[A\n",
      "  6%|▌         | 125/2224 [02:12<44:02,  1.26s/it]\u001b[A\n",
      "  6%|▌         | 126/2224 [02:13<42:35,  1.22s/it]\u001b[A\n",
      "  6%|▌         | 127/2224 [02:14<42:01,  1.20s/it]\u001b[A\n",
      "  6%|▌         | 128/2224 [02:16<43:20,  1.24s/it]\u001b[A\n",
      "  6%|▌         | 129/2224 [02:17<45:06,  1.29s/it]\u001b[A\n",
      "  6%|▌         | 130/2224 [02:18<43:26,  1.24s/it]\u001b[A\n",
      "  6%|▌         | 131/2224 [02:20<45:10,  1.29s/it]\u001b[A\n",
      "  6%|▌         | 132/2224 [02:21<44:22,  1.27s/it]\u001b[A\n",
      "  6%|▌         | 133/2224 [02:22<43:10,  1.24s/it]\u001b[A\n",
      "  6%|▌         | 134/2224 [02:23<41:03,  1.18s/it]\u001b[A\n",
      "  6%|▌         | 135/2224 [02:24<39:29,  1.13s/it]\u001b[A\n",
      "  6%|▌         | 136/2224 [02:25<38:31,  1.11s/it]\u001b[A\n",
      "  6%|▌         | 137/2224 [02:26<37:47,  1.09s/it]\u001b[A\n",
      "  6%|▌         | 138/2224 [02:27<37:18,  1.07s/it]\u001b[A\n",
      "  6%|▋         | 139/2224 [02:28<36:50,  1.06s/it]\u001b[A\n",
      "  6%|▋         | 140/2224 [02:29<36:29,  1.05s/it]\u001b[A\n",
      "  6%|▋         | 141/2224 [02:30<36:33,  1.05s/it]\u001b[A\n",
      "  6%|▋         | 142/2224 [02:31<36:24,  1.05s/it]\u001b[A\n",
      "  6%|▋         | 143/2224 [02:32<36:14,  1.04s/it]\u001b[A\n",
      "  6%|▋         | 144/2224 [02:33<36:10,  1.04s/it]\u001b[A\n",
      "  7%|▋         | 145/2224 [02:35<36:16,  1.05s/it]\u001b[A\n",
      "  7%|▋         | 146/2224 [02:36<36:11,  1.04s/it]\u001b[A\n",
      "  7%|▋         | 147/2224 [02:37<36:02,  1.04s/it]\u001b[A\n",
      "  7%|▋         | 148/2224 [02:38<36:02,  1.04s/it]\u001b[A\n",
      "  7%|▋         | 149/2224 [02:39<35:57,  1.04s/it]\u001b[A\n",
      "  7%|▋         | 150/2224 [02:40<36:01,  1.04s/it]\u001b[A\n",
      "  7%|▋         | 151/2224 [02:41<35:59,  1.04s/it]\u001b[A\n",
      "  7%|▋         | 152/2224 [02:42<35:59,  1.04s/it]\u001b[A\n",
      "  7%|▋         | 153/2224 [02:43<36:00,  1.04s/it]\u001b[A\n",
      "  7%|▋         | 154/2224 [02:44<35:53,  1.04s/it]\u001b[A\n",
      "  7%|▋         | 155/2224 [02:45<35:38,  1.03s/it]\u001b[A\n",
      "  7%|▋         | 156/2224 [02:46<35:29,  1.03s/it]\u001b[A\n",
      "  7%|▋         | 157/2224 [02:47<35:28,  1.03s/it]\u001b[A\n",
      "  7%|▋         | 158/2224 [02:48<35:19,  1.03s/it]\u001b[A\n",
      "  7%|▋         | 159/2224 [02:49<35:19,  1.03s/it]\u001b[A\n",
      "  7%|▋         | 160/2224 [02:50<35:10,  1.02s/it]\u001b[A\n",
      "  7%|▋         | 161/2224 [02:51<35:11,  1.02s/it]\u001b[A\n",
      "  7%|▋         | 162/2224 [02:52<35:04,  1.02s/it]\u001b[A\n",
      "  7%|▋         | 163/2224 [02:53<35:01,  1.02s/it]\u001b[A\n",
      "  7%|▋         | 164/2224 [02:54<35:03,  1.02s/it]\u001b[A\n",
      "  7%|▋         | 165/2224 [02:55<35:05,  1.02s/it]\u001b[A\n",
      "  7%|▋         | 166/2224 [02:56<35:00,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 167/2224 [02:57<35:03,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 168/2224 [02:58<35:01,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 169/2224 [02:59<35:01,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 170/2224 [03:00<34:54,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 171/2224 [03:01<34:50,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 172/2224 [03:02<34:47,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 173/2224 [03:03<34:50,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 174/2224 [03:04<34:49,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 175/2224 [03:05<34:50,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 176/2224 [03:06<34:51,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 177/2224 [03:07<34:51,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 178/2224 [03:08<34:51,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 179/2224 [03:09<34:53,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 180/2224 [03:10<34:49,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 181/2224 [03:11<34:49,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 182/2224 [03:12<34:48,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 183/2224 [03:14<34:48,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 184/2224 [03:15<34:42,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 185/2224 [03:16<34:51,  1.03s/it]\u001b[A\n",
      "  8%|▊         | 186/2224 [03:17<34:46,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 187/2224 [03:18<34:41,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 188/2224 [03:19<34:43,  1.02s/it]\u001b[A\n",
      "  8%|▊         | 189/2224 [03:20<34:41,  1.02s/it]\u001b[A\n",
      "  9%|▊         | 190/2224 [03:21<34:42,  1.02s/it]\u001b[A\n",
      "  9%|▊         | 191/2224 [03:22<34:40,  1.02s/it]\u001b[A\n",
      "  9%|▊         | 192/2224 [03:23<34:37,  1.02s/it]\u001b[A\n",
      "  9%|▊         | 193/2224 [03:24<34:39,  1.02s/it]\u001b[A\n",
      "  9%|▊         | 194/2224 [03:25<34:39,  1.02s/it]\u001b[A\n",
      "  9%|▉         | 195/2224 [03:26<34:34,  1.02s/it]\u001b[A\n",
      "  9%|▉         | 196/2224 [03:27<34:35,  1.02s/it]\u001b[A\n",
      "  9%|▉         | 197/2224 [03:28<34:32,  1.02s/it]\u001b[A\n",
      "  9%|▉         | 198/2224 [03:29<34:31,  1.02s/it]\u001b[A\n",
      "  9%|▉         | 199/2224 [03:30<34:32,  1.02s/it]\u001b[A\n",
      "  9%|▉         | 200/2224 [03:31<34:35,  1.03s/it]\u001b[A\n",
      "  9%|▉         | 201/2224 [03:32<34:36,  1.03s/it]\u001b[A\n",
      "  9%|▉         | 202/2224 [03:33<34:30,  1.02s/it]\u001b[A\n",
      "  9%|▉         | 203/2224 [03:34<34:29,  1.02s/it]\u001b[A\n",
      "  9%|▉         | 204/2224 [03:35<34:32,  1.03s/it]\u001b[A\n",
      "  9%|▉         | 205/2224 [03:36<34:31,  1.03s/it]\u001b[A\n",
      "  9%|▉         | 206/2224 [03:37<34:35,  1.03s/it]\u001b[A\n",
      "  9%|▉         | 207/2224 [03:38<35:15,  1.05s/it]\u001b[A\n",
      "  9%|▉         | 208/2224 [03:39<35:09,  1.05s/it]\u001b[A\n",
      "  9%|▉         | 209/2224 [03:40<35:21,  1.05s/it]\u001b[A\n",
      "  9%|▉         | 210/2224 [03:41<34:58,  1.04s/it]\u001b[A\n",
      "  9%|▉         | 211/2224 [03:42<34:45,  1.04s/it]\u001b[A\n",
      " 10%|▉         | 212/2224 [03:43<34:39,  1.03s/it]\u001b[A\n",
      " 10%|▉         | 213/2224 [03:44<34:33,  1.03s/it]\u001b[A\n",
      " 10%|▉         | 214/2224 [03:45<34:38,  1.03s/it]\u001b[A\n",
      " 10%|▉         | 215/2224 [03:46<34:34,  1.03s/it]\u001b[A\n",
      " 10%|▉         | 216/2224 [03:48<35:19,  1.06s/it]\u001b[A\n",
      " 10%|▉         | 217/2224 [03:49<36:15,  1.08s/it]\u001b[A\n",
      " 10%|▉         | 218/2224 [03:50<36:35,  1.09s/it]\u001b[A\n",
      " 10%|▉         | 219/2224 [03:51<36:35,  1.10s/it]\u001b[A\n",
      " 10%|▉         | 220/2224 [03:52<35:52,  1.07s/it]\u001b[A\n",
      " 10%|▉         | 221/2224 [03:53<35:19,  1.06s/it]\u001b[A\n",
      " 10%|▉         | 222/2224 [03:54<34:57,  1.05s/it]\u001b[A\n",
      " 10%|█         | 223/2224 [03:55<34:42,  1.04s/it]\u001b[A\n",
      " 10%|█         | 224/2224 [03:56<34:30,  1.04s/it]\u001b[A\n",
      " 10%|█         | 225/2224 [03:57<34:22,  1.03s/it]\u001b[A\n",
      " 10%|█         | 226/2224 [03:58<34:17,  1.03s/it]\u001b[A\n",
      " 10%|█         | 227/2224 [03:59<34:15,  1.03s/it]\u001b[A\n",
      " 10%|█         | 228/2224 [04:00<34:16,  1.03s/it]\u001b[A\n",
      " 10%|█         | 229/2224 [04:01<34:13,  1.03s/it]\u001b[A\n",
      " 10%|█         | 230/2224 [04:02<34:09,  1.03s/it]\u001b[A\n",
      " 10%|█         | 231/2224 [04:03<34:08,  1.03s/it]\u001b[A\n",
      " 10%|█         | 232/2224 [04:04<34:05,  1.03s/it]\u001b[A\n",
      " 10%|█         | 233/2224 [04:05<34:05,  1.03s/it]\u001b[A\n",
      " 11%|█         | 234/2224 [04:06<34:10,  1.03s/it]\u001b[A\n",
      " 11%|█         | 235/2224 [04:07<34:10,  1.03s/it]\u001b[A\n",
      " 11%|█         | 236/2224 [04:08<34:09,  1.03s/it]\u001b[A\n",
      " 11%|█         | 237/2224 [04:09<34:03,  1.03s/it]\u001b[A\n",
      " 11%|█         | 238/2224 [04:10<34:02,  1.03s/it]\u001b[A\n",
      " 11%|█         | 239/2224 [04:11<34:03,  1.03s/it]\u001b[A\n",
      " 11%|█         | 240/2224 [04:12<33:55,  1.03s/it]\u001b[A\n",
      " 11%|█         | 241/2224 [04:14<33:53,  1.03s/it]\u001b[A\n",
      " 11%|█         | 242/2224 [04:15<34:00,  1.03s/it]\u001b[A\n",
      " 11%|█         | 243/2224 [04:16<34:03,  1.03s/it]\u001b[A\n",
      " 11%|█         | 244/2224 [04:17<34:00,  1.03s/it]\u001b[A\n",
      " 11%|█         | 245/2224 [04:18<33:59,  1.03s/it]\u001b[A\n",
      " 11%|█         | 246/2224 [04:19<33:59,  1.03s/it]\u001b[A\n",
      " 11%|█         | 247/2224 [04:20<33:57,  1.03s/it]\u001b[A\n",
      " 11%|█         | 248/2224 [04:21<36:16,  1.10s/it]\u001b[A\n",
      " 11%|█         | 249/2224 [04:22<36:47,  1.12s/it]\u001b[A\n",
      " 11%|█         | 250/2224 [04:23<37:26,  1.14s/it]\u001b[A\n",
      " 11%|█▏        | 251/2224 [04:24<36:22,  1.11s/it]\u001b[A\n",
      " 11%|█▏        | 252/2224 [04:25<35:40,  1.09s/it]\u001b[A\n",
      " 11%|█▏        | 253/2224 [04:26<35:04,  1.07s/it]\u001b[A\n",
      " 11%|█▏        | 254/2224 [04:27<34:48,  1.06s/it]\u001b[A\n",
      " 11%|█▏        | 255/2224 [04:28<34:34,  1.05s/it]\u001b[A\n",
      " 12%|█▏        | 256/2224 [04:30<34:20,  1.05s/it]\u001b[A\n",
      " 12%|█▏        | 257/2224 [04:31<34:11,  1.04s/it]\u001b[A\n",
      " 12%|█▏        | 258/2224 [04:32<34:06,  1.04s/it]\u001b[A\n",
      " 12%|█▏        | 259/2224 [04:33<34:16,  1.05s/it]\u001b[A\n",
      " 12%|█▏        | 260/2224 [04:34<34:04,  1.04s/it]\u001b[A\n",
      " 12%|█▏        | 261/2224 [04:35<34:01,  1.04s/it]\u001b[A\n",
      " 12%|█▏        | 262/2224 [04:36<33:48,  1.03s/it]\u001b[A\n",
      " 12%|█▏        | 263/2224 [04:37<33:43,  1.03s/it]\u001b[A\n",
      " 12%|█▏        | 264/2224 [04:38<33:41,  1.03s/it]\u001b[A\n",
      " 12%|█▏        | 265/2224 [04:39<33:43,  1.03s/it]\u001b[A\n",
      " 12%|█▏        | 266/2224 [04:40<33:37,  1.03s/it]\u001b[A\n",
      " 12%|█▏        | 267/2224 [04:41<33:54,  1.04s/it]\u001b[A\n",
      " 12%|█▏        | 268/2224 [04:42<33:50,  1.04s/it]\u001b[A\n",
      " 12%|█▏        | 269/2224 [04:43<33:50,  1.04s/it]\u001b[A\n",
      " 12%|█▏        | 270/2224 [04:44<33:56,  1.04s/it]\u001b[A\n",
      " 12%|█▏        | 271/2224 [04:45<34:22,  1.06s/it]\u001b[A\n",
      " 12%|█▏        | 272/2224 [04:46<36:08,  1.11s/it]\u001b[A\n",
      " 12%|█▏        | 273/2224 [04:48<37:36,  1.16s/it]\u001b[A\n",
      " 12%|█▏        | 274/2224 [04:49<38:29,  1.18s/it]\u001b[A\n",
      " 12%|█▏        | 275/2224 [04:50<37:12,  1.15s/it]\u001b[A\n",
      " 12%|█▏        | 276/2224 [04:52<41:32,  1.28s/it]\u001b[A\n",
      " 12%|█▏        | 277/2224 [04:53<41:07,  1.27s/it]\u001b[A\n",
      " 12%|█▎        | 278/2224 [04:54<39:21,  1.21s/it]\u001b[A\n",
      " 13%|█▎        | 279/2224 [04:55<37:31,  1.16s/it]\u001b[A\n",
      " 13%|█▎        | 280/2224 [04:56<36:19,  1.12s/it]\u001b[A\n",
      " 13%|█▎        | 281/2224 [04:57<35:25,  1.09s/it]\u001b[A\n",
      " 13%|█▎        | 282/2224 [04:58<34:51,  1.08s/it]\u001b[A\n",
      " 13%|█▎        | 283/2224 [04:59<34:28,  1.07s/it]\u001b[A\n",
      " 13%|█▎        | 284/2224 [05:00<34:10,  1.06s/it]\u001b[A\n",
      " 13%|█▎        | 285/2224 [05:01<33:54,  1.05s/it]\u001b[A\n",
      " 13%|█▎        | 286/2224 [05:02<33:56,  1.05s/it]\u001b[A\n",
      " 13%|█▎        | 287/2224 [05:03<33:50,  1.05s/it]\u001b[A\n",
      " 13%|█▎        | 288/2224 [05:04<33:47,  1.05s/it]\u001b[A\n",
      " 13%|█▎        | 289/2224 [05:05<33:44,  1.05s/it]\u001b[A\n",
      " 13%|█▎        | 290/2224 [05:06<33:32,  1.04s/it]\u001b[A\n",
      " 13%|█▎        | 291/2224 [05:07<33:33,  1.04s/it]\u001b[A\n",
      " 13%|█▎        | 292/2224 [05:08<33:31,  1.04s/it]\u001b[A\n",
      " 13%|█▎        | 293/2224 [05:09<33:24,  1.04s/it]\u001b[A\n",
      " 13%|█▎        | 294/2224 [05:10<33:21,  1.04s/it]\u001b[A\n",
      " 13%|█▎        | 295/2224 [05:12<33:26,  1.04s/it]\u001b[A\n",
      " 13%|█▎        | 296/2224 [05:13<33:50,  1.05s/it]\u001b[A\n",
      " 13%|█▎        | 297/2224 [05:14<34:02,  1.06s/it]\u001b[A\n",
      " 13%|█▎        | 298/2224 [05:15<33:58,  1.06s/it]\u001b[A\n",
      " 13%|█▎        | 299/2224 [05:16<33:51,  1.06s/it]\u001b[A\n",
      " 13%|█▎        | 300/2224 [05:17<33:46,  1.05s/it]\u001b[A\n",
      " 14%|█▎        | 301/2224 [05:18<33:43,  1.05s/it]\u001b[A\n",
      " 14%|█▎        | 302/2224 [05:19<33:33,  1.05s/it]\u001b[A\n",
      " 14%|█▎        | 303/2224 [05:20<33:27,  1.04s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 304/2224 [05:21<33:18,  1.04s/it]\u001b[A\n",
      " 14%|█▎        | 305/2224 [05:22<34:20,  1.07s/it]\u001b[A\n",
      " 14%|█▍        | 306/2224 [05:23<33:49,  1.06s/it]\u001b[A\n",
      " 14%|█▍        | 307/2224 [05:24<33:25,  1.05s/it]\u001b[A\n",
      " 14%|█▍        | 308/2224 [05:25<33:14,  1.04s/it]\u001b[A\n",
      " 14%|█▍        | 309/2224 [05:26<33:02,  1.04s/it]\u001b[A\n",
      " 14%|█▍        | 310/2224 [05:27<32:57,  1.03s/it]\u001b[A\n",
      " 14%|█▍        | 311/2224 [05:28<32:48,  1.03s/it]\u001b[A\n",
      " 14%|█▍        | 312/2224 [05:29<32:44,  1.03s/it]\u001b[A\n",
      " 14%|█▍        | 313/2224 [05:30<32:41,  1.03s/it]\u001b[A\n",
      " 14%|█▍        | 314/2224 [05:31<32:36,  1.02s/it]\u001b[A\n",
      " 14%|█▍        | 315/2224 [05:32<32:31,  1.02s/it]\u001b[A\n",
      " 14%|█▍        | 316/2224 [05:33<32:26,  1.02s/it]\u001b[A\n",
      " 14%|█▍        | 317/2224 [05:34<32:31,  1.02s/it]\u001b[A\n",
      " 14%|█▍        | 318/2224 [05:35<32:30,  1.02s/it]\u001b[A\n",
      " 14%|█▍        | 319/2224 [05:36<32:29,  1.02s/it]\u001b[A\n",
      " 14%|█▍        | 320/2224 [05:37<32:43,  1.03s/it]\u001b[A\n",
      " 14%|█▍        | 321/2224 [05:39<32:49,  1.03s/it]\u001b[A\n",
      " 14%|█▍        | 322/2224 [05:40<32:55,  1.04s/it]\u001b[A\n",
      " 15%|█▍        | 323/2224 [05:41<32:40,  1.03s/it]\u001b[A\n",
      " 15%|█▍        | 324/2224 [05:42<32:31,  1.03s/it]\u001b[A\n",
      " 15%|█▍        | 325/2224 [05:43<32:31,  1.03s/it]\u001b[A\n",
      " 15%|█▍        | 326/2224 [05:44<32:25,  1.03s/it]\u001b[A\n",
      " 15%|█▍        | 327/2224 [05:45<32:24,  1.02s/it]\u001b[A\n",
      " 15%|█▍        | 328/2224 [05:46<32:32,  1.03s/it]\u001b[A\n",
      " 15%|█▍        | 329/2224 [05:47<32:23,  1.03s/it]\u001b[A\n",
      " 15%|█▍        | 330/2224 [05:48<32:20,  1.02s/it]\u001b[A\n",
      " 15%|█▍        | 331/2224 [05:49<32:19,  1.02s/it]\u001b[A\n",
      " 15%|█▍        | 332/2224 [05:50<32:22,  1.03s/it]\u001b[A\n",
      " 15%|█▍        | 333/2224 [05:51<32:19,  1.03s/it]\u001b[A\n",
      " 15%|█▌        | 334/2224 [05:52<32:17,  1.02s/it]\u001b[A\n",
      " 15%|█▌        | 335/2224 [05:53<32:14,  1.02s/it]\u001b[A\n",
      " 15%|█▌        | 336/2224 [05:54<32:08,  1.02s/it]\u001b[A\n",
      " 15%|█▌        | 337/2224 [05:55<32:09,  1.02s/it]\u001b[A\n",
      " 15%|█▌        | 338/2224 [05:56<32:09,  1.02s/it]\u001b[A\n",
      " 15%|█▌        | 339/2224 [05:57<32:07,  1.02s/it]\u001b[A\n",
      " 15%|█▌        | 340/2224 [05:58<32:09,  1.02s/it]\u001b[A\n",
      " 15%|█▌        | 341/2224 [05:59<32:14,  1.03s/it]\u001b[A\n",
      " 15%|█▌        | 342/2224 [06:00<32:05,  1.02s/it]\u001b[A\n",
      " 15%|█▌        | 343/2224 [06:01<32:06,  1.02s/it]\u001b[A\n",
      " 15%|█▌        | 344/2224 [06:02<32:05,  1.02s/it]\u001b[A\n",
      " 16%|█▌        | 345/2224 [06:03<32:10,  1.03s/it]\u001b[A\n",
      " 16%|█▌        | 346/2224 [06:04<32:07,  1.03s/it]\u001b[A\n",
      " 16%|█▌        | 347/2224 [06:05<32:01,  1.02s/it]\u001b[A\n",
      " 16%|█▌        | 348/2224 [06:06<31:56,  1.02s/it]\u001b[A\n",
      " 16%|█▌        | 349/2224 [06:07<31:56,  1.02s/it]\u001b[A\n",
      " 16%|█▌        | 350/2224 [06:08<31:53,  1.02s/it]\u001b[A\n",
      " 16%|█▌        | 351/2224 [06:09<31:57,  1.02s/it]\u001b[A\n",
      " 16%|█▌        | 352/2224 [06:10<32:00,  1.03s/it]\u001b[A\n",
      " 16%|█▌        | 353/2224 [06:11<31:55,  1.02s/it]\u001b[A\n",
      " 16%|█▌        | 354/2224 [06:12<31:57,  1.03s/it]\u001b[A\n",
      " 16%|█▌        | 355/2224 [06:13<31:55,  1.03s/it]\u001b[A\n",
      " 16%|█▌        | 356/2224 [06:14<31:52,  1.02s/it]\u001b[A\n",
      " 16%|█▌        | 357/2224 [06:15<32:01,  1.03s/it]\u001b[A\n",
      " 16%|█▌        | 358/2224 [06:16<32:07,  1.03s/it]\u001b[A\n",
      " 16%|█▌        | 359/2224 [06:17<32:02,  1.03s/it]\u001b[A\n",
      " 16%|█▌        | 360/2224 [06:19<31:56,  1.03s/it]\u001b[A\n",
      " 16%|█▌        | 361/2224 [06:20<31:57,  1.03s/it]\u001b[A\n",
      " 16%|█▋        | 362/2224 [06:21<31:55,  1.03s/it]\u001b[A\n",
      " 16%|█▋        | 363/2224 [06:22<31:53,  1.03s/it]\u001b[A\n",
      " 16%|█▋        | 364/2224 [06:23<31:48,  1.03s/it]\u001b[A\n",
      " 16%|█▋        | 365/2224 [06:24<31:49,  1.03s/it]\u001b[A\n",
      " 16%|█▋        | 366/2224 [06:25<33:10,  1.07s/it]\u001b[A\n",
      " 17%|█▋        | 367/2224 [06:26<32:49,  1.06s/it]\u001b[A\n",
      " 17%|█▋        | 368/2224 [06:27<32:29,  1.05s/it]\u001b[A\n",
      " 17%|█▋        | 369/2224 [06:28<32:19,  1.05s/it]\u001b[A\n",
      " 17%|█▋        | 370/2224 [06:29<32:07,  1.04s/it]\u001b[A\n",
      " 17%|█▋        | 371/2224 [06:30<32:01,  1.04s/it]\u001b[A\n",
      " 17%|█▋        | 372/2224 [06:31<31:55,  1.03s/it]\u001b[A\n",
      " 17%|█▋        | 373/2224 [06:32<31:49,  1.03s/it]\u001b[A\n",
      " 17%|█▋        | 374/2224 [06:33<31:47,  1.03s/it]\u001b[A\n",
      " 17%|█▋        | 375/2224 [06:34<31:41,  1.03s/it]\u001b[A\n",
      " 17%|█▋        | 376/2224 [06:35<31:44,  1.03s/it]\u001b[A\n",
      " 17%|█▋        | 377/2224 [06:36<31:55,  1.04s/it]\u001b[A\n",
      " 17%|█▋        | 378/2224 [06:37<31:49,  1.03s/it]\u001b[A\n",
      " 17%|█▋        | 379/2224 [06:38<31:46,  1.03s/it]\u001b[A\n",
      " 17%|█▋        | 380/2224 [06:39<31:41,  1.03s/it]\u001b[A\n",
      " 17%|█▋        | 381/2224 [06:40<31:38,  1.03s/it]\u001b[A\n",
      " 17%|█▋        | 382/2224 [06:41<31:36,  1.03s/it]\u001b[A\n",
      " 17%|█▋        | 383/2224 [06:42<31:35,  1.03s/it]\u001b[A\n",
      " 17%|█▋        | 384/2224 [06:43<31:32,  1.03s/it]\u001b[A\n",
      " 17%|█▋        | 385/2224 [06:44<31:34,  1.03s/it]\u001b[A\n",
      " 17%|█▋        | 386/2224 [06:45<31:37,  1.03s/it]\u001b[A\n",
      " 17%|█▋        | 387/2224 [06:46<31:36,  1.03s/it]\u001b[A\n",
      " 17%|█▋        | 388/2224 [06:48<31:35,  1.03s/it]\u001b[A\n",
      " 17%|█▋        | 389/2224 [06:49<31:46,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 390/2224 [06:50<31:53,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 391/2224 [06:51<31:53,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 392/2224 [06:52<31:41,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 393/2224 [06:53<31:34,  1.03s/it]\u001b[A\n",
      " 18%|█▊        | 394/2224 [06:54<31:37,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 395/2224 [06:55<31:43,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 396/2224 [06:56<31:45,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 397/2224 [06:57<31:36,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 398/2224 [06:58<31:31,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 399/2224 [06:59<31:37,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 400/2224 [07:00<31:44,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 401/2224 [07:01<31:35,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 402/2224 [07:02<31:28,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 403/2224 [07:03<31:23,  1.03s/it]\u001b[A\n",
      " 18%|█▊        | 404/2224 [07:04<31:32,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 405/2224 [07:05<31:38,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 406/2224 [07:06<31:34,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 407/2224 [07:07<31:26,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 408/2224 [07:08<31:29,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 409/2224 [07:09<31:34,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 410/2224 [07:10<31:29,  1.04s/it]\u001b[A\n",
      " 18%|█▊        | 411/2224 [07:11<31:24,  1.04s/it]\u001b[A\n",
      " 19%|█▊        | 412/2224 [07:12<31:31,  1.04s/it]\u001b[A\n",
      " 19%|█▊        | 413/2224 [07:14<31:37,  1.05s/it]\u001b[A\n",
      " 19%|█▊        | 414/2224 [07:15<31:39,  1.05s/it]\u001b[A\n",
      " 19%|█▊        | 415/2224 [07:16<31:42,  1.05s/it]\u001b[A\n",
      " 19%|█▊        | 416/2224 [07:17<31:30,  1.05s/it]\u001b[A\n",
      " 19%|█▉        | 417/2224 [07:18<31:30,  1.05s/it]\u001b[A\n",
      " 19%|█▉        | 418/2224 [07:19<31:35,  1.05s/it]\u001b[A\n",
      " 19%|█▉        | 419/2224 [07:20<31:34,  1.05s/it]\u001b[A\n",
      " 19%|█▉        | 420/2224 [07:21<31:25,  1.05s/it]\u001b[A\n",
      " 19%|█▉        | 421/2224 [07:22<31:18,  1.04s/it]\u001b[A\n",
      " 19%|█▉        | 422/2224 [07:23<31:12,  1.04s/it]\u001b[A\n",
      " 19%|█▉        | 423/2224 [07:24<31:26,  1.05s/it]\u001b[A\n",
      " 19%|█▉        | 424/2224 [07:25<31:26,  1.05s/it]\u001b[A\n",
      " 19%|█▉        | 425/2224 [07:26<31:15,  1.04s/it]\u001b[A\n",
      " 19%|█▉        | 426/2224 [07:27<31:09,  1.04s/it]\u001b[A\n",
      " 19%|█▉        | 427/2224 [07:28<31:15,  1.04s/it]\u001b[A\n",
      " 19%|█▉        | 428/2224 [07:29<31:18,  1.05s/it]\u001b[A\n",
      " 19%|█▉        | 429/2224 [07:30<31:10,  1.04s/it]\u001b[A\n",
      " 19%|█▉        | 430/2224 [07:31<31:03,  1.04s/it]\u001b[A\n",
      " 19%|█▉        | 431/2224 [07:32<30:56,  1.04s/it]\u001b[A\n",
      " 19%|█▉        | 432/2224 [07:33<31:06,  1.04s/it]\u001b[A\n",
      " 19%|█▉        | 433/2224 [07:34<31:17,  1.05s/it]\u001b[A\n",
      " 20%|█▉        | 434/2224 [07:36<31:19,  1.05s/it]\u001b[A\n",
      " 20%|█▉        | 435/2224 [07:37<31:04,  1.04s/it]\u001b[A\n",
      " 20%|█▉        | 436/2224 [07:38<31:43,  1.06s/it]\u001b[A\n",
      " 20%|█▉        | 437/2224 [07:39<31:38,  1.06s/it]\u001b[A\n",
      " 20%|█▉        | 438/2224 [07:40<31:52,  1.07s/it]\u001b[A\n",
      " 20%|█▉        | 439/2224 [07:41<31:30,  1.06s/it]\u001b[A\n",
      " 20%|█▉        | 440/2224 [07:42<31:12,  1.05s/it]\u001b[A\n",
      " 20%|█▉        | 441/2224 [07:43<31:15,  1.05s/it]\u001b[A\n",
      " 20%|█▉        | 442/2224 [07:44<31:19,  1.05s/it]\u001b[A\n",
      " 20%|█▉        | 443/2224 [07:45<31:30,  1.06s/it]\u001b[A\n",
      " 20%|█▉        | 444/2224 [07:46<31:26,  1.06s/it]\u001b[A\n",
      " 20%|██        | 445/2224 [07:47<31:20,  1.06s/it]\u001b[A\n",
      " 20%|██        | 446/2224 [07:48<31:08,  1.05s/it]\u001b[A\n",
      " 20%|██        | 447/2224 [07:49<31:03,  1.05s/it]\u001b[A\n",
      " 20%|██        | 448/2224 [07:50<31:07,  1.05s/it]\u001b[A\n",
      " 20%|██        | 449/2224 [07:51<31:12,  1.06s/it]\u001b[A\n",
      " 20%|██        | 450/2224 [07:52<31:04,  1.05s/it]\u001b[A\n",
      " 20%|██        | 451/2224 [07:53<30:55,  1.05s/it]\u001b[A\n",
      " 20%|██        | 452/2224 [07:54<30:55,  1.05s/it]\u001b[A\n",
      " 20%|██        | 453/2224 [07:56<31:00,  1.05s/it]\u001b[A\n",
      " 20%|██        | 454/2224 [07:57<30:55,  1.05s/it]\u001b[A\n",
      " 20%|██        | 455/2224 [07:58<30:49,  1.05s/it]\u001b[A\n",
      " 21%|██        | 456/2224 [07:59<30:55,  1.05s/it]\u001b[A\n",
      " 21%|██        | 457/2224 [08:00<30:51,  1.05s/it]\u001b[A\n",
      " 21%|██        | 458/2224 [08:01<30:47,  1.05s/it]\u001b[A\n",
      " 21%|██        | 459/2224 [08:02<30:38,  1.04s/it]\u001b[A\n",
      " 21%|██        | 460/2224 [08:03<30:25,  1.03s/it]\u001b[A\n",
      " 21%|██        | 461/2224 [08:04<30:17,  1.03s/it]\u001b[A\n",
      " 21%|██        | 462/2224 [08:05<30:20,  1.03s/it]\u001b[A\n",
      " 21%|██        | 463/2224 [08:06<30:25,  1.04s/it]\u001b[A\n",
      " 21%|██        | 464/2224 [08:07<30:14,  1.03s/it]\u001b[A\n",
      " 21%|██        | 465/2224 [08:08<30:23,  1.04s/it]\u001b[A\n",
      " 21%|██        | 466/2224 [08:09<30:26,  1.04s/it]\u001b[A\n",
      " 21%|██        | 467/2224 [08:10<30:27,  1.04s/it]\u001b[A\n",
      " 21%|██        | 468/2224 [08:11<30:13,  1.03s/it]\u001b[A\n",
      " 21%|██        | 469/2224 [08:12<30:55,  1.06s/it]\u001b[A\n",
      " 21%|██        | 470/2224 [08:13<30:37,  1.05s/it]\u001b[A\n",
      " 21%|██        | 471/2224 [08:14<30:40,  1.05s/it]\u001b[A\n",
      " 21%|██        | 472/2224 [08:15<30:43,  1.05s/it]\u001b[A\n",
      " 21%|██▏       | 473/2224 [08:16<30:29,  1.04s/it]\u001b[A\n",
      " 21%|██▏       | 474/2224 [08:17<30:16,  1.04s/it]\u001b[A\n",
      " 21%|██▏       | 475/2224 [08:18<30:23,  1.04s/it]\u001b[A\n",
      " 21%|██▏       | 476/2224 [08:20<30:27,  1.05s/it]\u001b[A\n",
      " 21%|██▏       | 477/2224 [08:21<30:23,  1.04s/it]\u001b[A\n",
      " 21%|██▏       | 478/2224 [08:22<30:12,  1.04s/it]\u001b[A\n",
      " 22%|██▏       | 479/2224 [08:23<30:03,  1.03s/it]\u001b[A\n",
      " 22%|██▏       | 480/2224 [08:24<30:05,  1.04s/it]\u001b[A\n",
      " 22%|██▏       | 481/2224 [08:25<30:07,  1.04s/it]\u001b[A\n",
      " 22%|██▏       | 482/2224 [08:26<30:10,  1.04s/it]\u001b[A\n",
      " 22%|██▏       | 483/2224 [08:27<30:12,  1.04s/it]\u001b[A\n",
      " 22%|██▏       | 484/2224 [08:28<30:01,  1.04s/it]\u001b[A\n",
      " 22%|██▏       | 485/2224 [08:29<29:54,  1.03s/it]\u001b[A\n",
      " 22%|██▏       | 486/2224 [08:30<30:03,  1.04s/it]\u001b[A\n",
      " 22%|██▏       | 487/2224 [08:31<30:11,  1.04s/it]\u001b[A\n",
      " 22%|██▏       | 488/2224 [08:32<30:03,  1.04s/it]\u001b[A\n",
      " 22%|██▏       | 489/2224 [08:33<29:49,  1.03s/it]\u001b[A\n",
      " 22%|██▏       | 490/2224 [08:34<29:46,  1.03s/it]\u001b[A\n",
      " 22%|██▏       | 491/2224 [08:35<29:55,  1.04s/it]\u001b[A\n",
      " 22%|██▏       | 492/2224 [08:36<29:58,  1.04s/it]\u001b[A\n",
      " 22%|██▏       | 493/2224 [08:37<30:40,  1.06s/it]\u001b[A\n",
      " 22%|██▏       | 494/2224 [08:39<35:43,  1.24s/it]\u001b[A\n",
      " 22%|██▏       | 495/2224 [08:41<40:21,  1.40s/it]\u001b[A\n",
      " 22%|██▏       | 496/2224 [08:42<42:13,  1.47s/it]\u001b[A\n",
      " 22%|██▏       | 497/2224 [08:43<39:32,  1.37s/it]\u001b[A\n",
      " 22%|██▏       | 498/2224 [08:44<36:30,  1.27s/it]\u001b[A\n",
      " 22%|██▏       | 499/2224 [08:45<34:34,  1.20s/it]\u001b[A\n",
      " 22%|██▏       | 500/2224 [08:47<33:18,  1.16s/it]\u001b[A\n",
      " 23%|██▎       | 501/2224 [08:48<32:27,  1.13s/it]\u001b[A\n",
      " 23%|██▎       | 502/2224 [08:49<31:47,  1.11s/it]\u001b[A\n",
      " 23%|██▎       | 503/2224 [08:50<31:28,  1.10s/it]\u001b[A\n",
      " 23%|██▎       | 504/2224 [08:51<31:01,  1.08s/it]\u001b[A\n",
      " 23%|██▎       | 505/2224 [08:52<30:35,  1.07s/it]\u001b[A\n",
      " 23%|██▎       | 506/2224 [08:53<30:19,  1.06s/it]\u001b[A\n",
      " 23%|██▎       | 507/2224 [08:54<30:14,  1.06s/it]\u001b[A\n",
      " 23%|██▎       | 508/2224 [08:55<30:09,  1.05s/it]\u001b[A\n",
      " 23%|██▎       | 509/2224 [08:56<30:12,  1.06s/it]\u001b[A\n",
      " 23%|██▎       | 510/2224 [08:57<29:57,  1.05s/it]\u001b[A\n",
      " 23%|██▎       | 511/2224 [08:58<29:58,  1.05s/it]\u001b[A\n",
      " 23%|██▎       | 512/2224 [08:59<30:00,  1.05s/it]\u001b[A\n",
      " 23%|██▎       | 513/2224 [09:00<30:01,  1.05s/it]\u001b[A\n",
      " 23%|██▎       | 514/2224 [09:01<29:46,  1.04s/it]\u001b[A\n",
      " 23%|██▎       | 515/2224 [09:02<29:38,  1.04s/it]\u001b[A\n",
      " 23%|██▎       | 516/2224 [09:03<29:35,  1.04s/it]\u001b[A\n",
      " 23%|██▎       | 517/2224 [09:04<29:41,  1.04s/it]\u001b[A\n",
      " 23%|██▎       | 518/2224 [09:05<29:51,  1.05s/it]\u001b[A\n",
      " 23%|██▎       | 519/2224 [09:06<29:41,  1.04s/it]\u001b[A\n",
      " 23%|██▎       | 520/2224 [09:07<29:33,  1.04s/it]\u001b[A\n",
      " 23%|██▎       | 521/2224 [09:09<29:26,  1.04s/it]\u001b[A\n",
      " 23%|██▎       | 522/2224 [09:10<29:34,  1.04s/it]\u001b[A\n",
      " 24%|██▎       | 523/2224 [09:11<29:36,  1.04s/it]\u001b[A\n",
      " 24%|██▎       | 524/2224 [09:12<29:44,  1.05s/it]\u001b[A\n",
      " 24%|██▎       | 525/2224 [09:13<29:42,  1.05s/it]\u001b[A\n",
      " 24%|██▎       | 526/2224 [09:14<29:34,  1.04s/it]\u001b[A\n",
      " 24%|██▎       | 527/2224 [09:15<29:37,  1.05s/it]\u001b[A\n",
      " 24%|██▎       | 528/2224 [09:16<29:46,  1.05s/it]\u001b[A\n",
      " 24%|██▍       | 529/2224 [09:17<29:39,  1.05s/it]\u001b[A\n",
      " 24%|██▍       | 530/2224 [09:18<29:30,  1.05s/it]\u001b[A\n",
      " 24%|██▍       | 531/2224 [09:19<29:36,  1.05s/it]\u001b[A\n",
      " 24%|██▍       | 532/2224 [09:20<29:41,  1.05s/it]\u001b[A\n",
      " 24%|██▍       | 533/2224 [09:21<30:34,  1.08s/it]\u001b[A\n",
      " 24%|██▍       | 534/2224 [09:22<30:05,  1.07s/it]\u001b[A\n",
      " 24%|██▍       | 535/2224 [09:23<29:57,  1.06s/it]\u001b[A\n",
      " 24%|██▍       | 536/2224 [09:24<29:53,  1.06s/it]\u001b[A\n",
      " 24%|██▍       | 537/2224 [09:25<29:42,  1.06s/it]\u001b[A\n",
      " 24%|██▍       | 538/2224 [09:26<29:29,  1.05s/it]\u001b[A\n",
      " 24%|██▍       | 539/2224 [09:27<29:29,  1.05s/it]\u001b[A\n",
      " 24%|██▍       | 540/2224 [09:29<29:38,  1.06s/it]\u001b[A\n",
      " 24%|██▍       | 541/2224 [09:30<29:37,  1.06s/it]\u001b[A\n",
      " 24%|██▍       | 542/2224 [09:31<29:27,  1.05s/it]\u001b[A\n",
      " 24%|██▍       | 543/2224 [09:32<29:22,  1.05s/it]\u001b[A\n",
      " 24%|██▍       | 544/2224 [09:33<29:29,  1.05s/it]\u001b[A\n",
      " 25%|██▍       | 545/2224 [09:34<29:43,  1.06s/it]\u001b[A\n",
      " 25%|██▍       | 546/2224 [09:35<29:44,  1.06s/it]\u001b[A\n",
      " 25%|██▍       | 547/2224 [09:36<29:43,  1.06s/it]\u001b[A\n",
      " 25%|██▍       | 548/2224 [09:37<29:45,  1.07s/it]\u001b[A\n",
      " 25%|██▍       | 549/2224 [09:38<30:08,  1.08s/it]\u001b[A\n",
      " 25%|██▍       | 550/2224 [09:39<30:13,  1.08s/it]\u001b[A\n",
      " 25%|██▍       | 551/2224 [09:40<30:19,  1.09s/it]\u001b[A\n",
      " 25%|██▍       | 552/2224 [09:41<30:08,  1.08s/it]\u001b[A\n",
      " 25%|██▍       | 553/2224 [09:42<29:59,  1.08s/it]\u001b[A\n",
      " 25%|██▍       | 554/2224 [09:44<29:51,  1.07s/it]\u001b[A\n",
      " 25%|██▍       | 555/2224 [09:45<29:27,  1.06s/it]\u001b[A\n",
      " 25%|██▌       | 556/2224 [09:46<29:19,  1.05s/it]\u001b[A\n",
      " 25%|██▌       | 557/2224 [09:47<29:12,  1.05s/it]\u001b[A\n",
      " 25%|██▌       | 558/2224 [09:48<29:14,  1.05s/it]\u001b[A\n",
      " 25%|██▌       | 559/2224 [09:49<29:23,  1.06s/it]\u001b[A\n",
      " 25%|██▌       | 560/2224 [09:50<29:20,  1.06s/it]\u001b[A\n",
      " 25%|██▌       | 561/2224 [09:51<29:11,  1.05s/it]\u001b[A\n",
      " 25%|██▌       | 562/2224 [09:52<29:03,  1.05s/it]\u001b[A\n",
      " 25%|██▌       | 563/2224 [09:53<29:11,  1.05s/it]\u001b[A\n",
      " 25%|██▌       | 564/2224 [09:54<29:17,  1.06s/it]\u001b[A\n",
      " 25%|██▌       | 565/2224 [09:55<29:18,  1.06s/it]\u001b[A\n",
      " 25%|██▌       | 566/2224 [09:56<29:15,  1.06s/it]\u001b[A\n",
      " 25%|██▌       | 567/2224 [09:57<29:14,  1.06s/it]\u001b[A\n",
      " 26%|██▌       | 568/2224 [09:58<29:13,  1.06s/it]\u001b[A\n",
      " 26%|██▌       | 569/2224 [09:59<29:03,  1.05s/it]\u001b[A\n",
      " 26%|██▌       | 570/2224 [10:00<28:57,  1.05s/it]\u001b[A\n",
      " 26%|██▌       | 571/2224 [10:01<29:01,  1.05s/it]\u001b[A\n",
      " 26%|██▌       | 572/2224 [10:03<29:04,  1.06s/it]\u001b[A\n",
      " 26%|██▌       | 573/2224 [10:04<29:12,  1.06s/it]\u001b[A\n",
      " 26%|██▌       | 574/2224 [10:05<29:13,  1.06s/it]\u001b[A\n",
      " 26%|██▌       | 575/2224 [10:06<29:13,  1.06s/it]\u001b[A\n",
      " 26%|██▌       | 576/2224 [10:07<29:11,  1.06s/it]\u001b[A\n",
      " 26%|██▌       | 577/2224 [10:08<29:13,  1.06s/it]\u001b[A\n",
      " 26%|██▌       | 578/2224 [10:09<29:13,  1.07s/it]\u001b[A\n",
      " 26%|██▌       | 579/2224 [10:10<29:10,  1.06s/it]\u001b[A\n",
      " 26%|██▌       | 580/2224 [10:11<29:04,  1.06s/it]\u001b[A\n",
      " 26%|██▌       | 581/2224 [10:12<29:24,  1.07s/it]\u001b[A\n",
      " 26%|██▌       | 582/2224 [10:13<29:34,  1.08s/it]\u001b[A\n",
      " 26%|██▌       | 583/2224 [10:14<29:29,  1.08s/it]\u001b[A\n",
      " 26%|██▋       | 584/2224 [10:15<29:33,  1.08s/it]\u001b[A\n",
      " 26%|██▋       | 585/2224 [10:16<29:22,  1.08s/it]\u001b[A\n",
      " 26%|██▋       | 586/2224 [10:18<29:19,  1.07s/it]\u001b[A\n",
      " 26%|██▋       | 587/2224 [10:19<29:05,  1.07s/it]\u001b[A\n",
      " 26%|██▋       | 588/2224 [10:20<28:59,  1.06s/it]\u001b[A\n",
      " 26%|██▋       | 589/2224 [10:21<28:56,  1.06s/it]\u001b[A\n",
      " 27%|██▋       | 590/2224 [10:22<29:02,  1.07s/it]\u001b[A\n",
      " 27%|██▋       | 591/2224 [10:23<29:45,  1.09s/it]\u001b[A\n",
      " 27%|██▋       | 592/2224 [10:24<29:29,  1.08s/it]\u001b[A\n",
      " 27%|██▋       | 593/2224 [10:25<29:21,  1.08s/it]\u001b[A\n",
      " 27%|██▋       | 594/2224 [10:26<29:13,  1.08s/it]\u001b[A\n",
      " 27%|██▋       | 595/2224 [10:27<29:02,  1.07s/it]\u001b[A\n",
      " 27%|██▋       | 596/2224 [10:28<28:53,  1.06s/it]\u001b[A\n",
      " 27%|██▋       | 597/2224 [10:29<28:39,  1.06s/it]\u001b[A\n",
      " 27%|██▋       | 598/2224 [10:30<28:36,  1.06s/it]\u001b[A\n",
      " 27%|██▋       | 599/2224 [10:31<28:43,  1.06s/it]\u001b[A\n",
      " 27%|██▋       | 600/2224 [10:32<28:48,  1.06s/it]\u001b[A\n",
      " 27%|██▋       | 601/2224 [10:34<28:49,  1.07s/it]\u001b[A\n",
      " 27%|██▋       | 602/2224 [10:35<28:55,  1.07s/it]\u001b[A\n",
      " 27%|██▋       | 603/2224 [10:36<28:47,  1.07s/it]\u001b[A\n",
      " 27%|██▋       | 604/2224 [10:37<28:33,  1.06s/it]\u001b[A\n",
      " 27%|██▋       | 605/2224 [10:38<28:37,  1.06s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 606/2224 [10:39<28:40,  1.06s/it]\u001b[A\n",
      " 27%|██▋       | 607/2224 [10:40<28:49,  1.07s/it]\u001b[A\n",
      " 27%|██▋       | 608/2224 [10:41<28:35,  1.06s/it]\u001b[A\n",
      " 27%|██▋       | 609/2224 [10:42<28:25,  1.06s/it]\u001b[A\n",
      " 27%|██▋       | 610/2224 [10:43<28:10,  1.05s/it]\u001b[A\n",
      " 27%|██▋       | 611/2224 [10:44<27:55,  1.04s/it]\u001b[A\n",
      " 28%|██▊       | 612/2224 [10:45<27:59,  1.04s/it]\u001b[A\n",
      " 28%|██▊       | 613/2224 [10:46<28:01,  1.04s/it]\u001b[A\n",
      " 28%|██▊       | 614/2224 [10:47<28:01,  1.04s/it]\u001b[A\n",
      " 28%|██▊       | 615/2224 [10:48<27:54,  1.04s/it]\u001b[A\n",
      " 28%|██▊       | 616/2224 [10:49<27:46,  1.04s/it]\u001b[A\n",
      " 28%|██▊       | 617/2224 [10:50<27:47,  1.04s/it]\u001b[A\n",
      " 28%|██▊       | 618/2224 [10:51<27:45,  1.04s/it]\u001b[A\n",
      " 28%|██▊       | 619/2224 [10:52<27:42,  1.04s/it]\u001b[A\n",
      " 28%|██▊       | 620/2224 [10:53<27:32,  1.03s/it]\u001b[A\n",
      " 28%|██▊       | 621/2224 [10:54<27:32,  1.03s/it]\u001b[A\n",
      " 28%|██▊       | 622/2224 [10:55<27:40,  1.04s/it]\u001b[A\n",
      " 28%|██▊       | 623/2224 [10:57<27:45,  1.04s/it]\u001b[A\n",
      " 28%|██▊       | 624/2224 [10:58<27:46,  1.04s/it]\u001b[A\n",
      " 28%|██▊       | 625/2224 [10:59<27:47,  1.04s/it]\u001b[A\n",
      " 28%|██▊       | 626/2224 [11:00<27:38,  1.04s/it]\u001b[A\n",
      " 28%|██▊       | 627/2224 [11:01<27:26,  1.03s/it]\u001b[A\n",
      " 28%|██▊       | 628/2224 [11:02<27:17,  1.03s/it]\u001b[A\n",
      " 28%|██▊       | 629/2224 [11:03<27:23,  1.03s/it]\u001b[A\n",
      " 28%|██▊       | 630/2224 [11:04<27:27,  1.03s/it]\u001b[A\n",
      " 28%|██▊       | 631/2224 [11:05<27:30,  1.04s/it]\u001b[A\n",
      " 28%|██▊       | 632/2224 [11:06<27:35,  1.04s/it]\u001b[A\n",
      " 28%|██▊       | 633/2224 [11:07<27:39,  1.04s/it]\u001b[A\n",
      " 29%|██▊       | 634/2224 [11:08<27:39,  1.04s/it]\u001b[A\n",
      " 29%|██▊       | 635/2224 [11:09<27:28,  1.04s/it]\u001b[A\n",
      " 29%|██▊       | 636/2224 [11:10<27:22,  1.03s/it]\u001b[A\n",
      " 29%|██▊       | 637/2224 [11:11<27:23,  1.04s/it]\u001b[A\n",
      " 29%|██▊       | 638/2224 [11:12<27:32,  1.04s/it]\u001b[A\n",
      " 29%|██▊       | 639/2224 [11:13<27:32,  1.04s/it]\u001b[A\n",
      " 29%|██▉       | 640/2224 [11:14<27:24,  1.04s/it]\u001b[A\n",
      " 29%|██▉       | 641/2224 [11:15<27:21,  1.04s/it]\u001b[A\n",
      " 29%|██▉       | 642/2224 [11:16<27:28,  1.04s/it]\u001b[A\n",
      " 29%|██▉       | 643/2224 [11:17<27:33,  1.05s/it]\u001b[A\n",
      " 29%|██▉       | 644/2224 [11:18<27:31,  1.05s/it]\u001b[A\n",
      " 29%|██▉       | 645/2224 [11:19<27:26,  1.04s/it]\u001b[A\n",
      " 29%|██▉       | 646/2224 [11:20<27:13,  1.04s/it]\u001b[A\n",
      " 29%|██▉       | 647/2224 [11:21<27:08,  1.03s/it]\u001b[A\n",
      " 29%|██▉       | 648/2224 [11:22<27:14,  1.04s/it]\u001b[A\n",
      " 29%|██▉       | 649/2224 [11:24<27:16,  1.04s/it]\u001b[A\n",
      " 29%|██▉       | 650/2224 [11:25<27:18,  1.04s/it]\u001b[A\n",
      " 29%|██▉       | 651/2224 [11:26<27:18,  1.04s/it]\u001b[A\n",
      " 29%|██▉       | 652/2224 [11:27<27:24,  1.05s/it]\u001b[A\n",
      " 29%|██▉       | 653/2224 [11:28<27:23,  1.05s/it]\u001b[A\n",
      " 29%|██▉       | 654/2224 [11:29<27:22,  1.05s/it]\u001b[A\n",
      " 29%|██▉       | 655/2224 [11:30<27:24,  1.05s/it]\u001b[A\n",
      " 29%|██▉       | 656/2224 [11:31<27:22,  1.05s/it]\u001b[A\n",
      " 30%|██▉       | 657/2224 [11:32<27:12,  1.04s/it]\u001b[A\n",
      " 30%|██▉       | 658/2224 [11:33<27:09,  1.04s/it]\u001b[A\n",
      " 30%|██▉       | 659/2224 [11:34<27:09,  1.04s/it]\u001b[A\n",
      " 30%|██▉       | 660/2224 [11:35<27:16,  1.05s/it]\u001b[A\n",
      " 30%|██▉       | 661/2224 [11:36<27:12,  1.04s/it]\u001b[A\n",
      " 30%|██▉       | 662/2224 [11:37<27:12,  1.04s/it]\u001b[A\n",
      " 30%|██▉       | 663/2224 [11:38<27:49,  1.07s/it]\u001b[A\n",
      " 30%|██▉       | 664/2224 [11:39<27:28,  1.06s/it]\u001b[A\n",
      " 30%|██▉       | 665/2224 [11:40<27:30,  1.06s/it]\u001b[A\n",
      " 30%|██▉       | 666/2224 [11:41<27:23,  1.05s/it]\u001b[A\n",
      " 30%|██▉       | 667/2224 [11:42<27:13,  1.05s/it]\u001b[A\n",
      " 30%|███       | 668/2224 [11:43<27:08,  1.05s/it]\u001b[A\n",
      " 30%|███       | 669/2224 [11:44<27:04,  1.04s/it]\u001b[A\n",
      " 30%|███       | 670/2224 [11:46<27:03,  1.04s/it]\u001b[A\n",
      " 30%|███       | 671/2224 [11:47<26:55,  1.04s/it]\u001b[A\n",
      " 30%|███       | 672/2224 [11:48<26:58,  1.04s/it]\u001b[A\n",
      " 30%|███       | 673/2224 [11:49<26:58,  1.04s/it]\u001b[A\n",
      " 30%|███       | 674/2224 [11:50<26:51,  1.04s/it]\u001b[A\n",
      " 30%|███       | 675/2224 [11:51<26:44,  1.04s/it]\u001b[A\n",
      " 30%|███       | 676/2224 [11:52<26:46,  1.04s/it]\u001b[A\n",
      " 30%|███       | 677/2224 [11:53<26:49,  1.04s/it]\u001b[A\n",
      " 30%|███       | 678/2224 [11:54<26:53,  1.04s/it]\u001b[A\n",
      " 31%|███       | 679/2224 [11:55<26:45,  1.04s/it]\u001b[A\n",
      " 31%|███       | 680/2224 [11:56<26:44,  1.04s/it]\u001b[A\n",
      " 31%|███       | 681/2224 [11:57<26:49,  1.04s/it]\u001b[A\n",
      " 31%|███       | 682/2224 [11:58<26:54,  1.05s/it]\u001b[A\n",
      " 31%|███       | 683/2224 [11:59<26:53,  1.05s/it]\u001b[A\n",
      " 31%|███       | 684/2224 [12:00<26:55,  1.05s/it]\u001b[A\n",
      " 31%|███       | 685/2224 [12:01<26:45,  1.04s/it]\u001b[A\n",
      " 31%|███       | 686/2224 [12:02<26:42,  1.04s/it]\u001b[A\n",
      " 31%|███       | 687/2224 [12:03<26:44,  1.04s/it]\u001b[A\n",
      " 31%|███       | 688/2224 [12:04<26:45,  1.05s/it]\u001b[A\n",
      " 31%|███       | 689/2224 [12:05<26:48,  1.05s/it]\u001b[A\n",
      " 31%|███       | 690/2224 [12:06<26:46,  1.05s/it]\u001b[A\n",
      " 31%|███       | 691/2224 [12:07<26:47,  1.05s/it]\u001b[A\n",
      " 31%|███       | 692/2224 [12:08<26:35,  1.04s/it]\u001b[A\n",
      " 31%|███       | 693/2224 [12:10<26:35,  1.04s/it]\u001b[A\n",
      " 31%|███       | 694/2224 [12:11<26:39,  1.05s/it]\u001b[A\n",
      " 31%|███▏      | 695/2224 [12:12<26:43,  1.05s/it]\u001b[A\n",
      " 31%|███▏      | 696/2224 [12:13<26:40,  1.05s/it]\u001b[A\n",
      " 31%|███▏      | 697/2224 [12:14<26:40,  1.05s/it]\u001b[A\n",
      " 31%|███▏      | 698/2224 [12:15<26:25,  1.04s/it]\u001b[A\n",
      " 31%|███▏      | 699/2224 [12:16<26:37,  1.05s/it]\u001b[A\n",
      " 31%|███▏      | 700/2224 [12:17<26:40,  1.05s/it]\u001b[A\n",
      " 32%|███▏      | 701/2224 [12:18<26:38,  1.05s/it]\u001b[A\n",
      " 32%|███▏      | 702/2224 [12:19<26:37,  1.05s/it]\u001b[A\n",
      " 32%|███▏      | 703/2224 [12:20<26:51,  1.06s/it]\u001b[A\n",
      " 32%|███▏      | 704/2224 [12:21<26:43,  1.05s/it]\u001b[A\n",
      " 32%|███▏      | 705/2224 [12:22<26:43,  1.06s/it]\u001b[A\n",
      " 32%|███▏      | 706/2224 [12:23<26:41,  1.05s/it]\u001b[A\n",
      " 32%|███▏      | 707/2224 [12:24<26:43,  1.06s/it]\u001b[A\n",
      " 32%|███▏      | 708/2224 [12:25<26:27,  1.05s/it]\u001b[A\n",
      " 32%|███▏      | 709/2224 [12:26<26:18,  1.04s/it]\u001b[A\n",
      " 32%|███▏      | 710/2224 [12:27<26:22,  1.05s/it]\u001b[A\n",
      " 32%|███▏      | 711/2224 [12:28<26:26,  1.05s/it]\u001b[A\n",
      " 32%|███▏      | 712/2224 [12:29<26:25,  1.05s/it]\u001b[A\n",
      " 32%|███▏      | 713/2224 [12:31<26:27,  1.05s/it]\u001b[A\n",
      " 32%|███▏      | 714/2224 [12:32<26:14,  1.04s/it]\u001b[A\n",
      " 32%|███▏      | 715/2224 [12:33<26:13,  1.04s/it]\u001b[A\n",
      " 32%|███▏      | 716/2224 [12:34<26:11,  1.04s/it]\u001b[A\n",
      " 32%|███▏      | 717/2224 [12:35<26:20,  1.05s/it]\u001b[A\n",
      " 32%|███▏      | 718/2224 [12:36<26:18,  1.05s/it]\u001b[A\n",
      " 32%|███▏      | 719/2224 [12:37<26:08,  1.04s/it]\u001b[A\n",
      " 32%|███▏      | 720/2224 [12:38<26:08,  1.04s/it]\u001b[A\n",
      " 32%|███▏      | 721/2224 [12:39<26:13,  1.05s/it]\u001b[A\n",
      " 32%|███▏      | 722/2224 [12:40<26:17,  1.05s/it]\u001b[A\n",
      " 33%|███▎      | 723/2224 [12:41<26:15,  1.05s/it]\u001b[A\n",
      " 33%|███▎      | 724/2224 [12:42<26:17,  1.05s/it]\u001b[A\n",
      " 33%|███▎      | 725/2224 [12:43<26:15,  1.05s/it]\u001b[A\n",
      " 33%|███▎      | 726/2224 [12:44<26:10,  1.05s/it]\u001b[A\n",
      " 33%|███▎      | 727/2224 [12:45<26:05,  1.05s/it]\u001b[A\n",
      " 33%|███▎      | 728/2224 [12:46<26:03,  1.05s/it]\u001b[A\n",
      " 33%|███▎      | 729/2224 [12:47<26:15,  1.05s/it]\u001b[A\n",
      " 33%|███▎      | 730/2224 [12:48<26:13,  1.05s/it]\u001b[A\n",
      " 33%|███▎      | 731/2224 [12:49<26:10,  1.05s/it]\u001b[A\n",
      " 33%|███▎      | 732/2224 [12:50<26:31,  1.07s/it]\u001b[A\n",
      " 33%|███▎      | 733/2224 [12:52<26:45,  1.08s/it]\u001b[A\n",
      " 33%|███▎      | 734/2224 [12:53<26:34,  1.07s/it]\u001b[A\n",
      " 33%|███▎      | 735/2224 [12:54<26:29,  1.07s/it]\u001b[A\n",
      " 33%|███▎      | 736/2224 [12:55<26:25,  1.07s/it]\u001b[A\n",
      " 33%|███▎      | 737/2224 [12:56<26:10,  1.06s/it]\u001b[A\n",
      " 33%|███▎      | 738/2224 [12:57<25:56,  1.05s/it]\u001b[A\n",
      " 33%|███▎      | 739/2224 [12:58<25:52,  1.05s/it]\u001b[A\n",
      " 33%|███▎      | 740/2224 [12:59<25:53,  1.05s/it]\u001b[A\n",
      " 33%|███▎      | 741/2224 [13:00<25:54,  1.05s/it]\u001b[A\n",
      " 33%|███▎      | 742/2224 [13:01<25:47,  1.04s/it]\u001b[A\n",
      " 33%|███▎      | 743/2224 [13:02<25:46,  1.04s/it]\u001b[A\n",
      " 33%|███▎      | 744/2224 [13:03<25:49,  1.05s/it]\u001b[A\n",
      " 33%|███▎      | 745/2224 [13:04<25:47,  1.05s/it]\u001b[A\n",
      " 34%|███▎      | 746/2224 [13:05<25:59,  1.06s/it]\u001b[A\n",
      " 34%|███▎      | 747/2224 [13:06<26:09,  1.06s/it]\u001b[A\n",
      " 34%|███▎      | 748/2224 [13:07<26:06,  1.06s/it]\u001b[A\n",
      " 34%|███▎      | 749/2224 [13:08<26:06,  1.06s/it]\u001b[A\n",
      " 34%|███▎      | 750/2224 [13:09<25:50,  1.05s/it]\u001b[A\n",
      " 34%|███▍      | 751/2224 [13:10<25:43,  1.05s/it]\u001b[A\n",
      " 34%|███▍      | 752/2224 [13:12<25:45,  1.05s/it]\u001b[A\n",
      " 34%|███▍      | 753/2224 [13:13<25:53,  1.06s/it]\u001b[A\n",
      " 34%|███▍      | 754/2224 [13:14<25:52,  1.06s/it]\u001b[A\n",
      " 34%|███▍      | 755/2224 [13:15<25:47,  1.05s/it]\u001b[A\n",
      " 34%|███▍      | 756/2224 [13:16<25:57,  1.06s/it]\u001b[A\n",
      " 34%|███▍      | 757/2224 [13:17<25:50,  1.06s/it]\u001b[A\n",
      " 34%|███▍      | 758/2224 [13:18<25:43,  1.05s/it]\u001b[A\n",
      " 34%|███▍      | 759/2224 [13:19<25:35,  1.05s/it]\u001b[A\n",
      " 34%|███▍      | 760/2224 [13:20<25:33,  1.05s/it]\u001b[A\n",
      " 34%|███▍      | 761/2224 [13:21<25:31,  1.05s/it]\u001b[A\n",
      " 34%|███▍      | 762/2224 [13:22<25:27,  1.04s/it]\u001b[A\n",
      " 34%|███▍      | 763/2224 [13:23<25:27,  1.05s/it]\u001b[A\n",
      " 34%|███▍      | 764/2224 [13:24<25:23,  1.04s/it]\u001b[A\n",
      " 34%|███▍      | 765/2224 [13:25<25:10,  1.04s/it]\u001b[A\n",
      " 34%|███▍      | 766/2224 [13:26<25:06,  1.03s/it]\u001b[A\n",
      " 34%|███▍      | 767/2224 [13:27<25:10,  1.04s/it]\u001b[A\n",
      " 35%|███▍      | 768/2224 [13:28<25:11,  1.04s/it]\u001b[A\n",
      " 35%|███▍      | 769/2224 [13:29<25:17,  1.04s/it]\u001b[A\n",
      " 35%|███▍      | 770/2224 [13:30<25:12,  1.04s/it]\u001b[A\n",
      " 35%|███▍      | 771/2224 [13:31<25:09,  1.04s/it]\u001b[A\n",
      " 35%|███▍      | 772/2224 [13:32<25:08,  1.04s/it]\u001b[A\n",
      " 35%|███▍      | 773/2224 [13:33<25:08,  1.04s/it]\u001b[A\n",
      " 35%|███▍      | 774/2224 [13:35<25:14,  1.04s/it]\u001b[A\n",
      " 35%|███▍      | 775/2224 [13:36<25:16,  1.05s/it]\u001b[A\n",
      " 35%|███▍      | 776/2224 [13:37<25:14,  1.05s/it]\u001b[A\n",
      " 35%|███▍      | 777/2224 [13:38<25:38,  1.06s/it]\u001b[A\n",
      " 35%|███▍      | 778/2224 [13:39<25:39,  1.06s/it]\u001b[A\n",
      " 35%|███▌      | 779/2224 [13:40<25:47,  1.07s/it]\u001b[A\n",
      " 35%|███▌      | 780/2224 [13:41<25:40,  1.07s/it]\u001b[A\n",
      " 35%|███▌      | 781/2224 [13:42<25:28,  1.06s/it]\u001b[A\n",
      " 35%|███▌      | 782/2224 [13:43<25:17,  1.05s/it]\u001b[A\n",
      " 35%|███▌      | 783/2224 [13:44<25:16,  1.05s/it]\u001b[A\n",
      " 35%|███▌      | 784/2224 [13:45<25:35,  1.07s/it]\u001b[A\n",
      " 35%|███▌      | 785/2224 [13:46<26:53,  1.12s/it]\u001b[A\n",
      " 35%|███▌      | 786/2224 [13:48<27:18,  1.14s/it]\u001b[A\n",
      " 35%|███▌      | 787/2224 [13:49<27:50,  1.16s/it]\u001b[A\n",
      " 35%|███▌      | 788/2224 [13:50<28:18,  1.18s/it]\u001b[A\n",
      " 35%|███▌      | 789/2224 [13:51<27:51,  1.16s/it]\u001b[A\n",
      " 36%|███▌      | 790/2224 [13:52<26:55,  1.13s/it]\u001b[A\n",
      " 36%|███▌      | 791/2224 [13:53<26:10,  1.10s/it]\u001b[A\n",
      " 36%|███▌      | 792/2224 [13:54<25:49,  1.08s/it]\u001b[A\n",
      " 36%|███▌      | 793/2224 [13:55<25:30,  1.07s/it]\u001b[A\n",
      " 36%|███▌      | 794/2224 [13:56<25:20,  1.06s/it]\u001b[A\n",
      " 36%|███▌      | 795/2224 [13:57<25:20,  1.06s/it]\u001b[A\n",
      " 36%|███▌      | 796/2224 [13:58<25:12,  1.06s/it]\u001b[A\n",
      " 36%|███▌      | 797/2224 [14:00<25:05,  1.06s/it]\u001b[A\n",
      " 36%|███▌      | 798/2224 [14:01<25:10,  1.06s/it]\u001b[A\n",
      " 36%|███▌      | 799/2224 [14:02<25:16,  1.06s/it]\u001b[A\n",
      " 36%|███▌      | 800/2224 [14:03<25:04,  1.06s/it]\u001b[A\n",
      " 36%|███▌      | 801/2224 [14:04<25:09,  1.06s/it]\u001b[A\n",
      " 36%|███▌      | 802/2224 [14:05<25:01,  1.06s/it]\u001b[A\n",
      " 36%|███▌      | 803/2224 [14:06<24:55,  1.05s/it]\u001b[A\n",
      " 36%|███▌      | 804/2224 [14:07<25:00,  1.06s/it]\u001b[A\n",
      " 36%|███▌      | 805/2224 [14:08<24:59,  1.06s/it]\u001b[A\n",
      " 36%|███▌      | 806/2224 [14:09<24:56,  1.06s/it]\u001b[A\n",
      " 36%|███▋      | 807/2224 [14:10<24:53,  1.05s/it]\u001b[A\n",
      " 36%|███▋      | 808/2224 [14:11<24:49,  1.05s/it]\u001b[A\n",
      " 36%|███▋      | 809/2224 [14:12<24:44,  1.05s/it]\u001b[A\n",
      " 36%|███▋      | 810/2224 [14:13<24:30,  1.04s/it]\u001b[A\n",
      " 36%|███▋      | 811/2224 [14:14<24:24,  1.04s/it]\u001b[A\n",
      " 37%|███▋      | 812/2224 [14:15<24:37,  1.05s/it]\u001b[A\n",
      " 37%|███▋      | 813/2224 [14:16<24:41,  1.05s/it]\u001b[A\n",
      " 37%|███▋      | 814/2224 [14:17<24:42,  1.05s/it]\u001b[A\n",
      " 37%|███▋      | 815/2224 [14:18<24:39,  1.05s/it]\u001b[A\n",
      " 37%|███▋      | 816/2224 [14:19<24:24,  1.04s/it]\u001b[A\n",
      " 37%|███▋      | 817/2224 [14:21<25:35,  1.09s/it]\u001b[A\n",
      " 37%|███▋      | 818/2224 [14:22<25:29,  1.09s/it]\u001b[A\n",
      " 37%|███▋      | 819/2224 [14:23<25:09,  1.07s/it]\u001b[A\n",
      " 37%|███▋      | 820/2224 [14:24<24:56,  1.07s/it]\u001b[A\n",
      " 37%|███▋      | 821/2224 [14:25<24:46,  1.06s/it]\u001b[A\n",
      " 37%|███▋      | 822/2224 [14:26<24:37,  1.05s/it]\u001b[A\n",
      " 37%|███▋      | 823/2224 [14:27<24:33,  1.05s/it]\u001b[A\n",
      " 37%|███▋      | 824/2224 [14:28<24:31,  1.05s/it]\u001b[A\n",
      " 37%|███▋      | 825/2224 [14:29<24:31,  1.05s/it]\u001b[A\n",
      " 37%|███▋      | 826/2224 [14:30<24:33,  1.05s/it]\u001b[A\n",
      " 37%|███▋      | 827/2224 [14:31<25:22,  1.09s/it]\u001b[A\n",
      " 37%|███▋      | 828/2224 [14:32<25:00,  1.08s/it]\u001b[A\n",
      " 37%|███▋      | 829/2224 [14:33<24:36,  1.06s/it]\u001b[A\n",
      " 37%|███▋      | 830/2224 [14:34<24:33,  1.06s/it]\u001b[A\n",
      " 37%|███▋      | 831/2224 [14:35<24:26,  1.05s/it]\u001b[A\n",
      " 37%|███▋      | 832/2224 [14:37<24:55,  1.07s/it]\u001b[A\n",
      " 37%|███▋      | 833/2224 [14:38<24:57,  1.08s/it]\u001b[A\n",
      " 38%|███▊      | 834/2224 [14:39<24:58,  1.08s/it]\u001b[A\n",
      " 38%|███▊      | 835/2224 [14:40<26:20,  1.14s/it]\u001b[A\n",
      " 38%|███▊      | 836/2224 [14:41<27:39,  1.20s/it]\u001b[A\n",
      " 38%|███▊      | 837/2224 [14:43<27:31,  1.19s/it]\u001b[A\n",
      " 38%|███▊      | 838/2224 [14:44<28:19,  1.23s/it]\u001b[A\n",
      " 38%|███▊      | 839/2224 [14:45<29:03,  1.26s/it]\u001b[A\n",
      " 38%|███▊      | 840/2224 [14:47<29:27,  1.28s/it]\u001b[A\n",
      " 38%|███▊      | 841/2224 [14:48<29:18,  1.27s/it]\u001b[A\n",
      " 38%|███▊      | 842/2224 [14:49<27:51,  1.21s/it]\u001b[A\n",
      " 38%|███▊      | 843/2224 [14:50<26:48,  1.16s/it]\u001b[A\n",
      " 38%|███▊      | 844/2224 [14:51<26:52,  1.17s/it]\u001b[A\n",
      " 38%|███▊      | 845/2224 [14:52<28:24,  1.24s/it]\u001b[A\n",
      " 38%|███▊      | 846/2224 [14:55<38:04,  1.66s/it]\u001b[A\n",
      " 38%|███▊      | 847/2224 [14:57<38:02,  1.66s/it]\u001b[A\n",
      " 38%|███▊      | 848/2224 [14:59<40:11,  1.75s/it]\u001b[A\n",
      " 38%|███▊      | 849/2224 [15:00<35:27,  1.55s/it]\u001b[A\n",
      " 38%|███▊      | 850/2224 [15:01<32:00,  1.40s/it]\u001b[A\n",
      " 38%|███▊      | 851/2224 [15:02<29:36,  1.29s/it]\u001b[A\n",
      " 38%|███▊      | 852/2224 [15:03<27:52,  1.22s/it]\u001b[A\n",
      " 38%|███▊      | 853/2224 [15:04<26:41,  1.17s/it]\u001b[A\n",
      " 38%|███▊      | 854/2224 [15:05<25:53,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 855/2224 [15:06<25:14,  1.11s/it]\u001b[A\n",
      " 38%|███▊      | 856/2224 [15:07<24:46,  1.09s/it]\u001b[A\n",
      " 39%|███▊      | 857/2224 [15:08<24:26,  1.07s/it]\u001b[A\n",
      " 39%|███▊      | 858/2224 [15:09<24:13,  1.06s/it]\u001b[A\n",
      " 39%|███▊      | 859/2224 [15:10<24:15,  1.07s/it]\u001b[A\n",
      " 39%|███▊      | 860/2224 [15:11<24:20,  1.07s/it]\u001b[A\n",
      " 39%|███▊      | 861/2224 [15:12<24:31,  1.08s/it]\u001b[A\n",
      " 39%|███▉      | 862/2224 [15:14<24:29,  1.08s/it]\u001b[A\n",
      " 39%|███▉      | 863/2224 [15:15<24:29,  1.08s/it]\u001b[A\n",
      " 39%|███▉      | 864/2224 [15:16<24:22,  1.08s/it]\u001b[A\n",
      " 39%|███▉      | 865/2224 [15:17<24:08,  1.07s/it]\u001b[A\n",
      " 39%|███▉      | 866/2224 [15:18<24:03,  1.06s/it]\u001b[A\n",
      " 39%|███▉      | 867/2224 [15:19<24:01,  1.06s/it]\u001b[A\n",
      " 39%|███▉      | 868/2224 [15:20<24:04,  1.06s/it]\u001b[A\n",
      " 39%|███▉      | 869/2224 [15:21<23:55,  1.06s/it]\u001b[A\n",
      " 39%|███▉      | 870/2224 [15:22<23:47,  1.05s/it]\u001b[A\n",
      " 39%|███▉      | 871/2224 [15:23<24:19,  1.08s/it]\u001b[A\n",
      " 39%|███▉      | 872/2224 [15:24<24:04,  1.07s/it]\u001b[A\n",
      " 39%|███▉      | 873/2224 [15:25<23:51,  1.06s/it]\u001b[A\n",
      " 39%|███▉      | 874/2224 [15:26<23:41,  1.05s/it]\u001b[A\n",
      " 39%|███▉      | 875/2224 [15:27<23:47,  1.06s/it]\u001b[A\n",
      " 39%|███▉      | 876/2224 [15:28<23:45,  1.06s/it]\u001b[A\n",
      " 39%|███▉      | 877/2224 [15:29<23:38,  1.05s/it]\u001b[A\n",
      " 39%|███▉      | 878/2224 [15:31<23:39,  1.05s/it]\u001b[A\n",
      " 40%|███▉      | 879/2224 [15:32<23:36,  1.05s/it]\u001b[A\n",
      " 40%|███▉      | 880/2224 [15:33<23:30,  1.05s/it]\u001b[A\n",
      " 40%|███▉      | 881/2224 [15:34<23:27,  1.05s/it]\u001b[A\n",
      " 40%|███▉      | 882/2224 [15:35<23:26,  1.05s/it]\u001b[A\n",
      " 40%|███▉      | 883/2224 [15:36<23:23,  1.05s/it]\u001b[A\n",
      " 40%|███▉      | 884/2224 [15:37<23:19,  1.04s/it]\u001b[A\n",
      " 40%|███▉      | 885/2224 [15:38<23:52,  1.07s/it]\u001b[A\n",
      " 40%|███▉      | 886/2224 [15:39<23:57,  1.07s/it]\u001b[A\n",
      " 40%|███▉      | 887/2224 [15:40<24:12,  1.09s/it]\u001b[A\n",
      " 40%|███▉      | 888/2224 [15:41<23:56,  1.08s/it]\u001b[A\n",
      " 40%|███▉      | 889/2224 [15:42<23:44,  1.07s/it]\u001b[A\n",
      " 40%|████      | 890/2224 [15:43<23:37,  1.06s/it]\u001b[A\n",
      " 40%|████      | 891/2224 [15:44<23:30,  1.06s/it]\u001b[A\n",
      " 40%|████      | 892/2224 [15:45<23:35,  1.06s/it]\u001b[A\n",
      " 40%|████      | 893/2224 [15:46<23:39,  1.07s/it]\u001b[A\n",
      " 40%|████      | 894/2224 [15:48<23:37,  1.07s/it]\u001b[A\n",
      " 40%|████      | 895/2224 [15:49<23:36,  1.07s/it]\u001b[A\n",
      " 40%|████      | 896/2224 [15:50<23:28,  1.06s/it]\u001b[A\n",
      " 40%|████      | 897/2224 [15:51<23:22,  1.06s/it]\u001b[A\n",
      " 40%|████      | 898/2224 [15:52<23:19,  1.06s/it]\u001b[A\n",
      " 40%|████      | 899/2224 [15:53<23:15,  1.05s/it]\u001b[A\n",
      " 40%|████      | 900/2224 [15:54<23:13,  1.05s/it]\u001b[A\n",
      " 41%|████      | 901/2224 [15:55<23:45,  1.08s/it]\u001b[A\n",
      " 41%|████      | 902/2224 [15:56<23:35,  1.07s/it]\u001b[A\n",
      " 41%|████      | 903/2224 [15:57<23:32,  1.07s/it]\u001b[A\n",
      " 41%|████      | 904/2224 [15:58<23:34,  1.07s/it]\u001b[A\n",
      " 41%|████      | 905/2224 [15:59<23:29,  1.07s/it]\u001b[A\n",
      " 41%|████      | 906/2224 [16:00<23:21,  1.06s/it]\u001b[A\n",
      " 41%|████      | 907/2224 [16:01<23:19,  1.06s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 908/2224 [16:02<23:13,  1.06s/it]\u001b[A\n",
      " 41%|████      | 909/2224 [16:04<23:30,  1.07s/it]\u001b[A\n",
      " 41%|████      | 910/2224 [16:05<23:27,  1.07s/it]\u001b[A\n",
      " 41%|████      | 911/2224 [16:06<23:11,  1.06s/it]\u001b[A\n",
      " 41%|████      | 912/2224 [16:07<23:00,  1.05s/it]\u001b[A\n",
      " 41%|████      | 913/2224 [16:08<22:50,  1.05s/it]\u001b[A\n",
      " 41%|████      | 914/2224 [16:09<22:46,  1.04s/it]\u001b[A\n",
      " 41%|████      | 915/2224 [16:10<22:45,  1.04s/it]\u001b[A\n",
      " 41%|████      | 916/2224 [16:11<22:40,  1.04s/it]\u001b[A\n",
      " 41%|████      | 917/2224 [16:12<22:38,  1.04s/it]\u001b[A\n",
      " 41%|████▏     | 918/2224 [16:13<22:35,  1.04s/it]\u001b[A\n",
      " 41%|████▏     | 919/2224 [16:14<22:41,  1.04s/it]\u001b[A\n",
      " 41%|████▏     | 920/2224 [16:15<22:47,  1.05s/it]\u001b[A\n",
      " 41%|████▏     | 921/2224 [16:16<22:51,  1.05s/it]\u001b[A\n",
      " 41%|████▏     | 922/2224 [16:17<22:42,  1.05s/it]\u001b[A\n",
      " 42%|████▏     | 923/2224 [16:18<22:41,  1.05s/it]\u001b[A\n",
      " 42%|████▏     | 924/2224 [16:19<22:36,  1.04s/it]\u001b[A\n",
      " 42%|████▏     | 925/2224 [16:20<22:33,  1.04s/it]\u001b[A\n",
      " 42%|████▏     | 926/2224 [16:21<22:31,  1.04s/it]\u001b[A\n",
      " 42%|████▏     | 927/2224 [16:22<22:27,  1.04s/it]\u001b[A\n",
      " 42%|████▏     | 928/2224 [16:23<23:30,  1.09s/it]\u001b[A\n",
      " 42%|████▏     | 929/2224 [16:25<23:12,  1.08s/it]\u001b[A\n",
      " 42%|████▏     | 930/2224 [16:26<22:58,  1.07s/it]\u001b[A\n",
      " 42%|████▏     | 931/2224 [16:27<22:48,  1.06s/it]\u001b[A\n",
      " 42%|████▏     | 932/2224 [16:28<22:39,  1.05s/it]\u001b[A\n",
      " 42%|████▏     | 933/2224 [16:29<22:33,  1.05s/it]\u001b[A\n",
      " 42%|████▏     | 934/2224 [16:30<22:30,  1.05s/it]\u001b[A\n",
      " 42%|████▏     | 935/2224 [16:31<22:29,  1.05s/it]\u001b[A\n",
      " 42%|████▏     | 936/2224 [16:32<22:32,  1.05s/it]\u001b[A\n",
      " 42%|████▏     | 937/2224 [16:33<22:26,  1.05s/it]\u001b[A\n",
      " 42%|████▏     | 938/2224 [16:34<22:21,  1.04s/it]\u001b[A\n",
      " 42%|████▏     | 939/2224 [16:35<22:10,  1.04s/it]\u001b[A\n",
      " 42%|████▏     | 940/2224 [16:36<22:09,  1.04s/it]\u001b[A\n",
      " 42%|████▏     | 941/2224 [16:37<22:13,  1.04s/it]\u001b[A\n",
      " 42%|████▏     | 942/2224 [16:38<22:22,  1.05s/it]\u001b[A\n",
      " 42%|████▏     | 943/2224 [16:39<22:31,  1.05s/it]\u001b[A\n",
      " 42%|████▏     | 944/2224 [16:40<22:22,  1.05s/it]\u001b[A\n",
      " 42%|████▏     | 945/2224 [16:41<22:11,  1.04s/it]\u001b[A\n",
      " 43%|████▎     | 946/2224 [16:42<21:59,  1.03s/it]\u001b[A\n",
      " 43%|████▎     | 947/2224 [16:43<21:59,  1.03s/it]\u001b[A\n",
      " 43%|████▎     | 948/2224 [16:44<22:09,  1.04s/it]\u001b[A\n",
      " 43%|████▎     | 949/2224 [16:45<22:20,  1.05s/it]\u001b[A\n",
      " 43%|████▎     | 950/2224 [16:46<22:14,  1.05s/it]\u001b[A\n",
      " 43%|████▎     | 951/2224 [16:47<22:12,  1.05s/it]\u001b[A\n",
      " 43%|████▎     | 952/2224 [16:48<22:05,  1.04s/it]\u001b[A\n",
      " 43%|████▎     | 953/2224 [16:50<22:00,  1.04s/it]\u001b[A\n",
      " 43%|████▎     | 954/2224 [16:51<21:58,  1.04s/it]\u001b[A\n",
      " 43%|████▎     | 955/2224 [16:52<21:48,  1.03s/it]\u001b[A\n",
      " 43%|████▎     | 956/2224 [16:53<21:49,  1.03s/it]\u001b[A\n",
      " 43%|████▎     | 957/2224 [16:54<21:55,  1.04s/it]\u001b[A\n",
      " 43%|████▎     | 958/2224 [16:55<22:05,  1.05s/it]\u001b[A\n",
      " 43%|████▎     | 959/2224 [16:56<22:00,  1.04s/it]\u001b[A\n",
      " 43%|████▎     | 960/2224 [16:57<21:58,  1.04s/it]\u001b[A\n",
      " 43%|████▎     | 961/2224 [16:58<21:58,  1.04s/it]\u001b[A\n",
      " 43%|████▎     | 962/2224 [16:59<21:55,  1.04s/it]\u001b[A\n",
      " 43%|████▎     | 963/2224 [17:00<21:56,  1.04s/it]\u001b[A\n",
      " 43%|████▎     | 964/2224 [17:01<21:52,  1.04s/it]\u001b[A\n",
      " 43%|████▎     | 965/2224 [17:02<21:59,  1.05s/it]\u001b[A\n",
      " 43%|████▎     | 966/2224 [17:03<22:03,  1.05s/it]\u001b[A\n",
      " 43%|████▎     | 967/2224 [17:04<21:58,  1.05s/it]\u001b[A\n",
      " 44%|████▎     | 968/2224 [17:05<21:55,  1.05s/it]\u001b[A\n",
      " 44%|████▎     | 969/2224 [17:06<21:50,  1.04s/it]\u001b[A\n",
      " 44%|████▎     | 970/2224 [17:07<21:48,  1.04s/it]\u001b[A\n",
      " 44%|████▎     | 971/2224 [17:08<21:48,  1.04s/it]\u001b[A\n",
      " 44%|████▎     | 972/2224 [17:09<21:46,  1.04s/it]\u001b[A\n",
      " 44%|████▍     | 973/2224 [17:10<21:45,  1.04s/it]\u001b[A\n",
      " 44%|████▍     | 974/2224 [17:11<21:44,  1.04s/it]\u001b[A\n",
      " 44%|████▍     | 975/2224 [17:12<21:42,  1.04s/it]\u001b[A\n",
      " 44%|████▍     | 976/2224 [17:14<21:41,  1.04s/it]\u001b[A\n",
      " 44%|████▍     | 977/2224 [17:15<21:47,  1.05s/it]\u001b[A\n",
      " 44%|████▍     | 978/2224 [17:16<21:57,  1.06s/it]\u001b[A\n",
      " 44%|████▍     | 979/2224 [17:17<21:47,  1.05s/it]\u001b[A\n",
      " 44%|████▍     | 980/2224 [17:18<21:43,  1.05s/it]\u001b[A\n",
      " 44%|████▍     | 981/2224 [17:19<21:38,  1.04s/it]\u001b[A\n",
      " 44%|████▍     | 982/2224 [17:20<21:34,  1.04s/it]\u001b[A\n",
      " 44%|████▍     | 983/2224 [17:21<21:31,  1.04s/it]\u001b[A\n",
      " 44%|████▍     | 984/2224 [17:22<21:33,  1.04s/it]\u001b[A\n",
      " 44%|████▍     | 985/2224 [17:23<21:30,  1.04s/it]\u001b[A\n",
      " 44%|████▍     | 986/2224 [17:24<21:29,  1.04s/it]\u001b[A\n",
      " 44%|████▍     | 987/2224 [17:25<21:27,  1.04s/it]\u001b[A\n",
      " 44%|████▍     | 988/2224 [17:26<21:22,  1.04s/it]\u001b[A\n",
      " 44%|████▍     | 989/2224 [17:27<21:23,  1.04s/it]\u001b[A\n",
      " 45%|████▍     | 990/2224 [17:28<21:24,  1.04s/it]\u001b[A\n",
      " 45%|████▍     | 991/2224 [17:29<21:23,  1.04s/it]\u001b[A\n",
      " 45%|████▍     | 992/2224 [17:30<21:22,  1.04s/it]\u001b[A\n",
      " 45%|████▍     | 993/2224 [17:31<21:18,  1.04s/it]\u001b[A\n",
      " 45%|████▍     | 994/2224 [17:32<21:09,  1.03s/it]\u001b[A\n",
      " 45%|████▍     | 995/2224 [17:33<21:10,  1.03s/it]\u001b[A\n",
      " 45%|████▍     | 996/2224 [17:34<21:14,  1.04s/it]\u001b[A\n",
      " 45%|████▍     | 997/2224 [17:35<21:16,  1.04s/it]\u001b[A\n",
      " 45%|████▍     | 998/2224 [17:36<21:12,  1.04s/it]\u001b[A\n",
      " 45%|████▍     | 999/2224 [17:38<21:28,  1.05s/it]\u001b[A\n",
      " 45%|████▍     | 1000/2224 [17:39<21:31,  1.05s/it]\u001b[A\n",
      " 45%|████▌     | 1001/2224 [17:40<21:39,  1.06s/it]\u001b[A\n",
      " 45%|████▌     | 1002/2224 [17:41<21:29,  1.06s/it]\u001b[A\n",
      " 45%|████▌     | 1003/2224 [17:42<21:24,  1.05s/it]\u001b[A\n",
      " 45%|████▌     | 1004/2224 [17:43<21:17,  1.05s/it]\u001b[A\n",
      " 45%|████▌     | 1005/2224 [17:44<21:14,  1.05s/it]\u001b[A\n",
      " 45%|████▌     | 1006/2224 [17:45<21:11,  1.04s/it]\u001b[A\n",
      " 45%|████▌     | 1007/2224 [17:46<21:12,  1.05s/it]\u001b[A\n",
      " 45%|████▌     | 1008/2224 [17:47<21:12,  1.05s/it]\u001b[A\n",
      " 45%|████▌     | 1009/2224 [17:48<21:14,  1.05s/it]\u001b[A\n",
      " 45%|████▌     | 1010/2224 [17:49<21:09,  1.05s/it]\u001b[A\n",
      " 45%|████▌     | 1011/2224 [17:50<21:05,  1.04s/it]\u001b[A\n",
      " 46%|████▌     | 1012/2224 [17:51<21:06,  1.04s/it]\u001b[A\n",
      " 46%|████▌     | 1013/2224 [17:52<21:04,  1.04s/it]\u001b[A\n",
      " 46%|████▌     | 1014/2224 [17:53<21:01,  1.04s/it]\u001b[A\n",
      " 46%|████▌     | 1015/2224 [17:54<21:04,  1.05s/it]\u001b[A\n",
      " 46%|████▌     | 1016/2224 [17:55<21:00,  1.04s/it]\u001b[A\n",
      " 46%|████▌     | 1017/2224 [17:56<21:00,  1.04s/it]\u001b[A\n",
      " 46%|████▌     | 1018/2224 [17:57<20:56,  1.04s/it]\u001b[A\n",
      " 46%|████▌     | 1019/2224 [17:58<20:55,  1.04s/it]\u001b[A\n",
      " 46%|████▌     | 1020/2224 [17:59<20:55,  1.04s/it]\u001b[A\n",
      " 46%|████▌     | 1021/2224 [18:01<20:54,  1.04s/it]\u001b[A\n",
      " 46%|████▌     | 1022/2224 [18:02<20:57,  1.05s/it]\u001b[A\n",
      " 46%|████▌     | 1023/2224 [18:03<20:56,  1.05s/it]\u001b[A\n",
      " 46%|████▌     | 1024/2224 [18:04<20:48,  1.04s/it]\u001b[A\n",
      " 46%|████▌     | 1025/2224 [18:05<20:43,  1.04s/it]\u001b[A\n",
      " 46%|████▌     | 1026/2224 [18:06<20:42,  1.04s/it]\u001b[A\n",
      " 46%|████▌     | 1027/2224 [18:07<20:45,  1.04s/it]\u001b[A\n",
      " 46%|████▌     | 1028/2224 [18:08<20:44,  1.04s/it]\u001b[A\n",
      " 46%|████▋     | 1029/2224 [18:09<20:46,  1.04s/it]\u001b[A\n",
      " 46%|████▋     | 1030/2224 [18:10<20:50,  1.05s/it]\u001b[A\n",
      " 46%|████▋     | 1031/2224 [18:11<20:49,  1.05s/it]\u001b[A\n",
      " 46%|████▋     | 1032/2224 [18:12<20:48,  1.05s/it]\u001b[A\n",
      " 46%|████▋     | 1033/2224 [18:13<20:47,  1.05s/it]\u001b[A\n",
      " 46%|████▋     | 1034/2224 [18:14<20:46,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1035/2224 [18:15<20:47,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1036/2224 [18:16<20:43,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1037/2224 [18:17<20:42,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1038/2224 [18:18<20:41,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1039/2224 [18:19<20:43,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1040/2224 [18:20<20:42,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1041/2224 [18:21<20:41,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1042/2224 [18:22<20:38,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1043/2224 [18:24<20:36,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1044/2224 [18:25<20:34,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1045/2224 [18:26<20:33,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1046/2224 [18:27<20:34,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1047/2224 [18:28<20:33,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1048/2224 [18:29<20:32,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1049/2224 [18:30<20:29,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1050/2224 [18:31<20:32,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1051/2224 [18:32<20:29,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1052/2224 [18:33<20:31,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1053/2224 [18:34<20:29,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1054/2224 [18:35<20:27,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1055/2224 [18:36<20:24,  1.05s/it]\u001b[A\n",
      " 47%|████▋     | 1056/2224 [18:37<20:22,  1.05s/it]\u001b[A\n",
      " 48%|████▊     | 1057/2224 [18:38<20:16,  1.04s/it]\u001b[A\n",
      " 48%|████▊     | 1058/2224 [18:39<20:11,  1.04s/it]\u001b[A\n",
      " 48%|████▊     | 1059/2224 [18:40<20:10,  1.04s/it]\u001b[A\n",
      " 48%|████▊     | 1060/2224 [18:41<20:05,  1.04s/it]\u001b[A\n",
      " 48%|████▊     | 1061/2224 [18:42<20:05,  1.04s/it]\u001b[A\n",
      " 48%|████▊     | 1062/2224 [18:43<20:04,  1.04s/it]\u001b[A\n",
      " 48%|████▊     | 1063/2224 [18:44<20:13,  1.05s/it]\u001b[A\n",
      " 48%|████▊     | 1064/2224 [18:46<20:25,  1.06s/it]\u001b[A\n",
      " 48%|████▊     | 1065/2224 [18:47<20:17,  1.05s/it]\u001b[A\n",
      " 48%|████▊     | 1066/2224 [18:48<20:11,  1.05s/it]\u001b[A\n",
      " 48%|████▊     | 1067/2224 [18:49<20:06,  1.04s/it]\u001b[A\n",
      " 48%|████▊     | 1068/2224 [18:50<20:04,  1.04s/it]\u001b[A\n",
      " 48%|████▊     | 1069/2224 [18:51<20:23,  1.06s/it]\u001b[A\n",
      " 48%|████▊     | 1070/2224 [18:52<20:15,  1.05s/it]\u001b[A\n",
      " 48%|████▊     | 1071/2224 [18:53<20:13,  1.05s/it]\u001b[A\n",
      " 48%|████▊     | 1072/2224 [18:54<20:05,  1.05s/it]\u001b[A\n",
      " 48%|████▊     | 1073/2224 [18:55<19:59,  1.04s/it]\u001b[A\n",
      " 48%|████▊     | 1074/2224 [18:56<19:56,  1.04s/it]\u001b[A\n",
      " 48%|████▊     | 1075/2224 [18:57<19:53,  1.04s/it]\u001b[A\n",
      " 48%|████▊     | 1076/2224 [18:58<19:53,  1.04s/it]\u001b[A\n",
      " 48%|████▊     | 1077/2224 [18:59<19:53,  1.04s/it]\u001b[A\n",
      " 48%|████▊     | 1078/2224 [19:00<19:52,  1.04s/it]\u001b[A\n",
      " 49%|████▊     | 1079/2224 [19:01<19:50,  1.04s/it]\u001b[A\n",
      " 49%|████▊     | 1080/2224 [19:02<19:48,  1.04s/it]\u001b[A\n",
      " 49%|████▊     | 1081/2224 [19:03<19:44,  1.04s/it]\u001b[A\n",
      " 49%|████▊     | 1082/2224 [19:04<19:43,  1.04s/it]\u001b[A\n",
      " 49%|████▊     | 1083/2224 [19:05<19:44,  1.04s/it]\u001b[A\n",
      " 49%|████▊     | 1084/2224 [19:06<19:41,  1.04s/it]\u001b[A\n",
      " 49%|████▉     | 1085/2224 [19:07<19:34,  1.03s/it]\u001b[A\n",
      " 49%|████▉     | 1086/2224 [19:08<19:38,  1.04s/it]\u001b[A\n",
      " 49%|████▉     | 1087/2224 [19:09<19:38,  1.04s/it]\u001b[A\n",
      " 49%|████▉     | 1088/2224 [19:10<19:40,  1.04s/it]\u001b[A\n",
      " 49%|████▉     | 1089/2224 [19:12<19:38,  1.04s/it]\u001b[A\n",
      " 49%|████▉     | 1090/2224 [19:13<19:36,  1.04s/it]\u001b[A\n",
      " 49%|████▉     | 1091/2224 [19:14<19:33,  1.04s/it]\u001b[A\n",
      " 49%|████▉     | 1092/2224 [19:15<19:34,  1.04s/it]\u001b[A\n",
      " 49%|████▉     | 1093/2224 [19:16<19:41,  1.04s/it]\u001b[A\n",
      " 49%|████▉     | 1094/2224 [19:17<19:38,  1.04s/it]\u001b[A\n",
      " 49%|████▉     | 1095/2224 [19:18<19:35,  1.04s/it]\u001b[A\n",
      " 49%|████▉     | 1096/2224 [19:19<19:26,  1.03s/it]\u001b[A\n",
      " 49%|████▉     | 1097/2224 [19:20<19:24,  1.03s/it]\u001b[A\n",
      " 49%|████▉     | 1098/2224 [19:21<21:00,  1.12s/it]\u001b[A\n",
      " 49%|████▉     | 1099/2224 [19:22<20:37,  1.10s/it]\u001b[A\n",
      " 49%|████▉     | 1100/2224 [19:23<20:15,  1.08s/it]\u001b[A\n",
      " 50%|████▉     | 1101/2224 [19:24<19:54,  1.06s/it]\u001b[A\n",
      " 50%|████▉     | 1102/2224 [19:25<19:38,  1.05s/it]\u001b[A\n",
      " 50%|████▉     | 1103/2224 [19:26<19:35,  1.05s/it]\u001b[A\n",
      " 50%|████▉     | 1104/2224 [19:27<19:31,  1.05s/it]\u001b[A\n",
      " 50%|████▉     | 1105/2224 [19:28<19:41,  1.06s/it]\u001b[A\n",
      " 50%|████▉     | 1106/2224 [19:29<19:36,  1.05s/it]\u001b[A\n",
      " 50%|████▉     | 1107/2224 [19:31<19:33,  1.05s/it]\u001b[A\n",
      " 50%|████▉     | 1108/2224 [19:32<19:21,  1.04s/it]\u001b[A\n",
      " 50%|████▉     | 1109/2224 [19:33<19:12,  1.03s/it]\u001b[A\n",
      " 50%|████▉     | 1110/2224 [19:34<19:13,  1.04s/it]\u001b[A\n",
      " 50%|████▉     | 1111/2224 [19:35<19:18,  1.04s/it]\u001b[A\n",
      " 50%|█████     | 1112/2224 [19:36<19:17,  1.04s/it]\u001b[A\n",
      " 50%|█████     | 1113/2224 [19:37<19:21,  1.05s/it]\u001b[A\n",
      " 50%|█████     | 1114/2224 [19:38<19:41,  1.06s/it]\u001b[A\n",
      " 50%|█████     | 1115/2224 [19:39<19:41,  1.07s/it]\u001b[A\n",
      " 50%|█████     | 1116/2224 [19:40<19:53,  1.08s/it]\u001b[A\n",
      " 50%|█████     | 1117/2224 [19:41<19:44,  1.07s/it]\u001b[A\n",
      " 50%|█████     | 1118/2224 [19:42<19:34,  1.06s/it]\u001b[A\n",
      " 50%|█████     | 1119/2224 [19:43<19:27,  1.06s/it]\u001b[A\n",
      " 50%|█████     | 1120/2224 [19:44<19:18,  1.05s/it]\u001b[A\n",
      " 50%|█████     | 1121/2224 [19:45<19:18,  1.05s/it]\u001b[A\n",
      " 50%|█████     | 1122/2224 [19:46<19:13,  1.05s/it]\u001b[A\n",
      " 50%|█████     | 1123/2224 [19:47<19:11,  1.05s/it]\u001b[A\n",
      " 51%|█████     | 1124/2224 [19:48<19:09,  1.04s/it]\u001b[A\n",
      " 51%|█████     | 1125/2224 [19:49<19:05,  1.04s/it]\u001b[A\n",
      " 51%|█████     | 1126/2224 [19:50<19:03,  1.04s/it]\u001b[A\n",
      " 51%|█████     | 1127/2224 [19:51<19:06,  1.05s/it]\u001b[A\n",
      " 51%|█████     | 1128/2224 [19:53<19:03,  1.04s/it]\u001b[A\n",
      " 51%|█████     | 1129/2224 [19:54<19:00,  1.04s/it]\u001b[A\n",
      " 51%|█████     | 1130/2224 [19:55<18:50,  1.03s/it]\u001b[A\n",
      " 51%|█████     | 1131/2224 [19:56<18:52,  1.04s/it]\u001b[A\n",
      " 51%|█████     | 1132/2224 [19:57<18:52,  1.04s/it]\u001b[A\n",
      " 51%|█████     | 1133/2224 [19:58<18:56,  1.04s/it]\u001b[A\n",
      " 51%|█████     | 1134/2224 [19:59<18:54,  1.04s/it]\u001b[A\n",
      " 51%|█████     | 1135/2224 [20:00<19:03,  1.05s/it]\u001b[A\n",
      " 51%|█████     | 1136/2224 [20:01<19:13,  1.06s/it]\u001b[A\n",
      " 51%|█████     | 1137/2224 [20:02<19:07,  1.06s/it]\u001b[A\n",
      " 51%|█████     | 1138/2224 [20:03<19:02,  1.05s/it]\u001b[A\n",
      " 51%|█████     | 1139/2224 [20:04<19:07,  1.06s/it]\u001b[A\n",
      " 51%|█████▏    | 1140/2224 [20:05<19:03,  1.06s/it]\u001b[A\n",
      " 51%|█████▏    | 1141/2224 [20:06<18:57,  1.05s/it]\u001b[A\n",
      " 51%|█████▏    | 1142/2224 [20:07<18:53,  1.05s/it]\u001b[A\n",
      " 51%|█████▏    | 1143/2224 [20:08<18:44,  1.04s/it]\u001b[A\n",
      " 51%|█████▏    | 1144/2224 [20:09<18:40,  1.04s/it]\u001b[A\n",
      " 51%|█████▏    | 1145/2224 [20:10<18:43,  1.04s/it]\u001b[A\n",
      " 52%|█████▏    | 1146/2224 [20:11<18:44,  1.04s/it]\u001b[A\n",
      " 52%|█████▏    | 1147/2224 [20:12<18:59,  1.06s/it]\u001b[A\n",
      " 52%|█████▏    | 1148/2224 [20:14<19:14,  1.07s/it]\u001b[A\n",
      " 52%|█████▏    | 1149/2224 [20:15<19:14,  1.07s/it]\u001b[A\n",
      " 52%|█████▏    | 1150/2224 [20:16<19:20,  1.08s/it]\u001b[A\n",
      " 52%|█████▏    | 1151/2224 [20:17<19:10,  1.07s/it]\u001b[A\n",
      " 52%|█████▏    | 1152/2224 [20:18<19:14,  1.08s/it]\u001b[A\n",
      " 52%|█████▏    | 1153/2224 [20:20<22:22,  1.25s/it]\u001b[A\n",
      " 52%|█████▏    | 1154/2224 [20:21<25:10,  1.41s/it]\u001b[A\n",
      " 52%|█████▏    | 1155/2224 [20:23<27:07,  1.52s/it]\u001b[A\n",
      " 52%|█████▏    | 1156/2224 [20:25<28:10,  1.58s/it]\u001b[A\n",
      " 52%|█████▏    | 1157/2224 [20:26<27:05,  1.52s/it]\u001b[A\n",
      " 52%|█████▏    | 1158/2224 [20:27<24:49,  1.40s/it]\u001b[A\n",
      " 52%|█████▏    | 1159/2224 [20:28<22:58,  1.29s/it]\u001b[A\n",
      " 52%|█████▏    | 1160/2224 [20:29<21:43,  1.23s/it]\u001b[A\n",
      " 52%|█████▏    | 1161/2224 [20:30<20:48,  1.17s/it]\u001b[A\n",
      " 52%|█████▏    | 1162/2224 [20:32<20:07,  1.14s/it]\u001b[A\n",
      " 52%|█████▏    | 1163/2224 [20:33<19:42,  1.11s/it]\u001b[A\n",
      " 52%|█████▏    | 1164/2224 [20:34<19:22,  1.10s/it]\u001b[A\n",
      " 52%|█████▏    | 1165/2224 [20:35<19:10,  1.09s/it]\u001b[A\n",
      " 52%|█████▏    | 1166/2224 [20:36<18:59,  1.08s/it]\u001b[A\n",
      " 52%|█████▏    | 1167/2224 [20:37<18:53,  1.07s/it]\u001b[A\n",
      " 53%|█████▎    | 1168/2224 [20:38<18:39,  1.06s/it]\u001b[A\n",
      " 53%|█████▎    | 1169/2224 [20:39<18:28,  1.05s/it]\u001b[A\n",
      " 53%|█████▎    | 1170/2224 [20:40<18:27,  1.05s/it]\u001b[A\n",
      " 53%|█████▎    | 1171/2224 [20:41<18:29,  1.05s/it]\u001b[A\n",
      " 53%|█████▎    | 1172/2224 [20:42<18:28,  1.05s/it]\u001b[A\n",
      " 53%|█████▎    | 1173/2224 [20:43<18:35,  1.06s/it]\u001b[A\n",
      " 53%|█████▎    | 1174/2224 [20:44<18:39,  1.07s/it]\u001b[A\n",
      " 53%|█████▎    | 1175/2224 [20:45<18:37,  1.07s/it]\u001b[A\n",
      " 53%|█████▎    | 1176/2224 [20:46<18:34,  1.06s/it]\u001b[A\n",
      " 53%|█████▎    | 1177/2224 [20:47<18:32,  1.06s/it]\u001b[A\n",
      " 53%|█████▎    | 1178/2224 [20:48<18:32,  1.06s/it]\u001b[A\n",
      " 53%|█████▎    | 1179/2224 [20:50<18:30,  1.06s/it]\u001b[A\n",
      " 53%|█████▎    | 1180/2224 [20:51<18:27,  1.06s/it]\u001b[A\n",
      " 53%|█████▎    | 1181/2224 [20:52<18:35,  1.07s/it]\u001b[A\n",
      " 53%|█████▎    | 1182/2224 [20:53<18:36,  1.07s/it]\u001b[A\n",
      " 53%|█████▎    | 1183/2224 [20:54<18:30,  1.07s/it]\u001b[A\n",
      " 53%|█████▎    | 1184/2224 [20:55<18:25,  1.06s/it]\u001b[A\n",
      " 53%|█████▎    | 1185/2224 [20:56<18:19,  1.06s/it]\u001b[A\n",
      " 53%|█████▎    | 1186/2224 [20:57<18:18,  1.06s/it]\u001b[A\n",
      " 53%|█████▎    | 1187/2224 [20:58<18:16,  1.06s/it]\u001b[A\n",
      " 53%|█████▎    | 1188/2224 [20:59<18:10,  1.05s/it]\u001b[A\n",
      " 53%|█████▎    | 1189/2224 [21:00<18:04,  1.05s/it]\u001b[A\n",
      " 54%|█████▎    | 1190/2224 [21:01<18:10,  1.05s/it]\u001b[A\n",
      " 54%|█████▎    | 1191/2224 [21:02<18:13,  1.06s/it]\u001b[A\n",
      " 54%|█████▎    | 1192/2224 [21:03<18:20,  1.07s/it]\u001b[A\n",
      " 54%|█████▎    | 1193/2224 [21:04<18:24,  1.07s/it]\u001b[A\n",
      " 54%|█████▎    | 1194/2224 [21:05<18:19,  1.07s/it]\u001b[A\n",
      " 54%|█████▎    | 1195/2224 [21:07<18:18,  1.07s/it]\u001b[A\n",
      " 54%|█████▍    | 1196/2224 [21:08<18:15,  1.07s/it]\u001b[A\n",
      " 54%|█████▍    | 1197/2224 [21:09<18:12,  1.06s/it]\u001b[A\n",
      " 54%|█████▍    | 1198/2224 [21:10<18:08,  1.06s/it]\u001b[A\n",
      " 54%|█████▍    | 1199/2224 [21:11<18:07,  1.06s/it]\u001b[A\n",
      " 54%|█████▍    | 1200/2224 [21:12<18:06,  1.06s/it]\u001b[A\n",
      " 54%|█████▍    | 1201/2224 [21:13<17:56,  1.05s/it]\u001b[A\n",
      " 54%|█████▍    | 1202/2224 [21:14<17:59,  1.06s/it]\u001b[A\n",
      " 54%|█████▍    | 1203/2224 [21:15<18:05,  1.06s/it]\u001b[A\n",
      " 54%|█████▍    | 1204/2224 [21:16<18:10,  1.07s/it]\u001b[A\n",
      " 54%|█████▍    | 1205/2224 [21:17<18:11,  1.07s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 1206/2224 [21:18<18:05,  1.07s/it]\u001b[A\n",
      " 54%|█████▍    | 1207/2224 [21:19<18:09,  1.07s/it]\u001b[A\n",
      " 54%|█████▍    | 1208/2224 [21:20<18:04,  1.07s/it]\u001b[A\n",
      " 54%|█████▍    | 1209/2224 [21:21<17:52,  1.06s/it]\u001b[A\n",
      " 54%|█████▍    | 1210/2224 [21:22<17:46,  1.05s/it]\u001b[A\n",
      " 54%|█████▍    | 1211/2224 [21:23<17:39,  1.05s/it]\u001b[A\n",
      " 54%|█████▍    | 1212/2224 [21:24<17:35,  1.04s/it]\u001b[A\n",
      " 55%|█████▍    | 1213/2224 [21:26<17:35,  1.04s/it]\u001b[A\n",
      " 55%|█████▍    | 1214/2224 [21:27<17:30,  1.04s/it]\u001b[A\n",
      " 55%|█████▍    | 1215/2224 [21:28<17:27,  1.04s/it]\u001b[A\n",
      " 55%|█████▍    | 1216/2224 [21:29<17:25,  1.04s/it]\u001b[A\n",
      " 55%|█████▍    | 1217/2224 [21:30<17:23,  1.04s/it]\u001b[A\n",
      " 55%|█████▍    | 1218/2224 [21:31<17:25,  1.04s/it]\u001b[A\n",
      " 55%|█████▍    | 1219/2224 [21:32<17:23,  1.04s/it]\u001b[A\n",
      " 55%|█████▍    | 1220/2224 [21:33<17:23,  1.04s/it]\u001b[A\n",
      " 55%|█████▍    | 1221/2224 [21:34<17:31,  1.05s/it]\u001b[A\n",
      " 55%|█████▍    | 1222/2224 [21:35<17:32,  1.05s/it]\u001b[A\n",
      " 55%|█████▍    | 1223/2224 [21:36<17:27,  1.05s/it]\u001b[A\n",
      " 55%|█████▌    | 1224/2224 [21:37<17:24,  1.04s/it]\u001b[A\n",
      " 55%|█████▌    | 1225/2224 [21:38<17:43,  1.07s/it]\u001b[A\n",
      " 55%|█████▌    | 1226/2224 [21:39<17:38,  1.06s/it]\u001b[A\n",
      " 55%|█████▌    | 1227/2224 [21:40<17:42,  1.07s/it]\u001b[A\n",
      " 55%|█████▌    | 1228/2224 [21:41<17:33,  1.06s/it]\u001b[A\n",
      " 55%|█████▌    | 1229/2224 [21:42<17:26,  1.05s/it]\u001b[A\n",
      " 55%|█████▌    | 1230/2224 [21:43<17:20,  1.05s/it]\u001b[A\n",
      " 55%|█████▌    | 1231/2224 [21:44<17:17,  1.04s/it]\u001b[A\n",
      " 55%|█████▌    | 1232/2224 [21:45<17:21,  1.05s/it]\u001b[A\n",
      " 55%|█████▌    | 1233/2224 [21:46<17:15,  1.04s/it]\u001b[A\n",
      " 55%|█████▌    | 1234/2224 [21:48<17:11,  1.04s/it]\u001b[A\n",
      " 56%|█████▌    | 1235/2224 [21:49<17:17,  1.05s/it]\u001b[A\n",
      " 56%|█████▌    | 1236/2224 [21:50<17:16,  1.05s/it]\u001b[A\n",
      " 56%|█████▌    | 1237/2224 [21:51<17:14,  1.05s/it]\u001b[A\n",
      " 56%|█████▌    | 1238/2224 [21:52<17:09,  1.04s/it]\u001b[A\n",
      " 56%|█████▌    | 1239/2224 [21:53<17:05,  1.04s/it]\u001b[A\n",
      " 56%|█████▌    | 1240/2224 [21:54<17:02,  1.04s/it]\u001b[A\n",
      " 56%|█████▌    | 1241/2224 [21:55<17:03,  1.04s/it]\u001b[A\n",
      " 56%|█████▌    | 1242/2224 [21:56<17:07,  1.05s/it]\u001b[A\n",
      " 56%|█████▌    | 1243/2224 [21:57<17:09,  1.05s/it]\u001b[A\n",
      " 56%|█████▌    | 1244/2224 [21:58<17:04,  1.05s/it]\u001b[A\n",
      " 56%|█████▌    | 1245/2224 [21:59<17:00,  1.04s/it]\u001b[A\n",
      " 56%|█████▌    | 1246/2224 [22:00<16:57,  1.04s/it]\u001b[A\n",
      " 56%|█████▌    | 1247/2224 [22:01<16:57,  1.04s/it]\u001b[A\n",
      " 56%|█████▌    | 1248/2224 [22:02<16:55,  1.04s/it]\u001b[A\n",
      " 56%|█████▌    | 1249/2224 [22:03<16:53,  1.04s/it]\u001b[A\n",
      " 56%|█████▌    | 1250/2224 [22:04<16:54,  1.04s/it]\u001b[A\n",
      " 56%|█████▋    | 1251/2224 [22:05<16:54,  1.04s/it]\u001b[A\n",
      " 56%|█████▋    | 1252/2224 [22:06<16:52,  1.04s/it]\u001b[A\n",
      " 56%|█████▋    | 1253/2224 [22:07<16:51,  1.04s/it]\u001b[A\n",
      " 56%|█████▋    | 1254/2224 [22:08<16:55,  1.05s/it]\u001b[A\n",
      " 56%|█████▋    | 1255/2224 [22:09<17:00,  1.05s/it]\u001b[A\n",
      " 56%|█████▋    | 1256/2224 [22:11<16:56,  1.05s/it]\u001b[A\n",
      " 57%|█████▋    | 1257/2224 [22:12<16:51,  1.05s/it]\u001b[A\n",
      " 57%|█████▋    | 1258/2224 [22:13<16:48,  1.04s/it]\u001b[A\n",
      " 57%|█████▋    | 1259/2224 [22:14<16:49,  1.05s/it]\u001b[A\n",
      " 57%|█████▋    | 1260/2224 [22:15<16:48,  1.05s/it]\u001b[A\n",
      " 57%|█████▋    | 1261/2224 [22:16<16:48,  1.05s/it]\u001b[A\n",
      " 57%|█████▋    | 1262/2224 [22:17<16:50,  1.05s/it]\u001b[A\n",
      " 57%|█████▋    | 1263/2224 [22:18<16:54,  1.06s/it]\u001b[A\n",
      " 57%|█████▋    | 1264/2224 [22:19<16:50,  1.05s/it]\u001b[A\n",
      " 57%|█████▋    | 1265/2224 [22:20<16:46,  1.05s/it]\u001b[A\n",
      " 57%|█████▋    | 1266/2224 [22:21<16:38,  1.04s/it]\u001b[A\n",
      " 57%|█████▋    | 1267/2224 [22:22<16:34,  1.04s/it]\u001b[A\n",
      " 57%|█████▋    | 1268/2224 [22:23<16:34,  1.04s/it]\u001b[A\n",
      " 57%|█████▋    | 1269/2224 [22:24<16:31,  1.04s/it]\u001b[A\n",
      " 57%|█████▋    | 1270/2224 [22:25<16:36,  1.04s/it]\u001b[A\n",
      " 57%|█████▋    | 1271/2224 [22:26<16:39,  1.05s/it]\u001b[A\n",
      " 57%|█████▋    | 1272/2224 [22:27<16:37,  1.05s/it]\u001b[A\n",
      " 57%|█████▋    | 1273/2224 [22:28<16:33,  1.05s/it]\u001b[A\n",
      " 57%|█████▋    | 1274/2224 [22:29<16:32,  1.05s/it]\u001b[A\n",
      " 57%|█████▋    | 1275/2224 [22:30<16:32,  1.05s/it]\u001b[A\n",
      " 57%|█████▋    | 1276/2224 [22:31<16:28,  1.04s/it]\u001b[A\n",
      " 57%|█████▋    | 1277/2224 [22:32<16:32,  1.05s/it]\u001b[A\n",
      " 57%|█████▋    | 1278/2224 [22:34<16:31,  1.05s/it]\u001b[A\n",
      " 58%|█████▊    | 1279/2224 [22:35<16:32,  1.05s/it]\u001b[A\n",
      " 58%|█████▊    | 1280/2224 [22:36<16:30,  1.05s/it]\u001b[A\n",
      " 58%|█████▊    | 1281/2224 [22:37<16:29,  1.05s/it]\u001b[A\n",
      " 58%|█████▊    | 1282/2224 [22:38<16:27,  1.05s/it]\u001b[A\n",
      " 58%|█████▊    | 1283/2224 [22:39<16:25,  1.05s/it]\u001b[A\n",
      " 58%|█████▊    | 1284/2224 [22:40<16:23,  1.05s/it]\u001b[A\n",
      " 58%|█████▊    | 1285/2224 [22:41<16:27,  1.05s/it]\u001b[A\n",
      " 58%|█████▊    | 1286/2224 [22:42<16:31,  1.06s/it]\u001b[A\n",
      " 58%|█████▊    | 1287/2224 [22:43<16:26,  1.05s/it]\u001b[A\n",
      " 58%|█████▊    | 1288/2224 [22:44<16:21,  1.05s/it]\u001b[A\n",
      " 58%|█████▊    | 1289/2224 [22:45<16:25,  1.05s/it]\u001b[A\n",
      " 58%|█████▊    | 1290/2224 [22:46<16:20,  1.05s/it]\u001b[A\n",
      " 58%|█████▊    | 1291/2224 [22:47<16:21,  1.05s/it]\u001b[A\n",
      " 58%|█████▊    | 1292/2224 [22:48<16:17,  1.05s/it]\u001b[A\n",
      " 58%|█████▊    | 1293/2224 [22:49<16:14,  1.05s/it]\u001b[A\n",
      " 58%|█████▊    | 1294/2224 [22:50<16:10,  1.04s/it]\u001b[A\n",
      " 58%|█████▊    | 1295/2224 [22:51<16:09,  1.04s/it]\u001b[A\n",
      " 58%|█████▊    | 1296/2224 [22:52<16:05,  1.04s/it]\u001b[A\n",
      " 58%|█████▊    | 1297/2224 [22:53<16:06,  1.04s/it]\u001b[A\n",
      " 58%|█████▊    | 1298/2224 [22:54<16:04,  1.04s/it]\u001b[A\n",
      " 58%|█████▊    | 1299/2224 [22:56<16:06,  1.05s/it]\u001b[A\n",
      " 58%|█████▊    | 1300/2224 [22:57<16:03,  1.04s/it]\u001b[A\n",
      " 58%|█████▊    | 1301/2224 [22:58<16:02,  1.04s/it]\u001b[A\n",
      " 59%|█████▊    | 1302/2224 [22:59<16:02,  1.04s/it]\u001b[A\n",
      " 59%|█████▊    | 1303/2224 [23:00<16:01,  1.04s/it]\u001b[A\n",
      " 59%|█████▊    | 1304/2224 [23:01<16:01,  1.04s/it]\u001b[A\n",
      " 59%|█████▊    | 1305/2224 [23:02<16:02,  1.05s/it]\u001b[A\n",
      " 59%|█████▊    | 1306/2224 [23:03<15:57,  1.04s/it]\u001b[A\n",
      " 59%|█████▉    | 1307/2224 [23:04<15:52,  1.04s/it]\u001b[A\n",
      " 59%|█████▉    | 1308/2224 [23:05<15:51,  1.04s/it]\u001b[A\n",
      " 59%|█████▉    | 1309/2224 [23:06<15:52,  1.04s/it]\u001b[A\n",
      " 59%|█████▉    | 1310/2224 [23:07<15:52,  1.04s/it]\u001b[A\n",
      " 59%|█████▉    | 1311/2224 [23:08<15:59,  1.05s/it]\u001b[A\n",
      " 59%|█████▉    | 1312/2224 [23:09<15:54,  1.05s/it]\u001b[A\n",
      " 59%|█████▉    | 1313/2224 [23:10<15:46,  1.04s/it]\u001b[A\n",
      " 59%|█████▉    | 1314/2224 [23:11<15:42,  1.04s/it]\u001b[A\n",
      " 59%|█████▉    | 1315/2224 [23:12<15:44,  1.04s/it]\u001b[A\n",
      " 59%|█████▉    | 1316/2224 [23:13<15:46,  1.04s/it]\u001b[A\n",
      " 59%|█████▉    | 1317/2224 [23:14<15:42,  1.04s/it]\u001b[A\n",
      " 59%|█████▉    | 1318/2224 [23:15<15:42,  1.04s/it]\u001b[A\n",
      " 59%|█████▉    | 1319/2224 [23:16<15:42,  1.04s/it]\u001b[A\n",
      " 59%|█████▉    | 1320/2224 [23:17<15:42,  1.04s/it]\u001b[A\n",
      " 59%|█████▉    | 1321/2224 [23:18<15:43,  1.04s/it]\u001b[A\n",
      " 59%|█████▉    | 1322/2224 [23:19<15:40,  1.04s/it]\u001b[A\n",
      " 59%|█████▉    | 1323/2224 [23:21<15:40,  1.04s/it]\u001b[A\n",
      " 60%|█████▉    | 1324/2224 [23:22<15:37,  1.04s/it]\u001b[A\n",
      " 60%|█████▉    | 1325/2224 [23:23<15:37,  1.04s/it]\u001b[A\n",
      " 60%|█████▉    | 1326/2224 [23:24<15:38,  1.05s/it]\u001b[A\n",
      " 60%|█████▉    | 1327/2224 [23:25<15:29,  1.04s/it]\u001b[A\n",
      " 60%|█████▉    | 1328/2224 [23:26<15:30,  1.04s/it]\u001b[A\n",
      " 60%|█████▉    | 1329/2224 [23:27<15:31,  1.04s/it]\u001b[A\n",
      " 60%|█████▉    | 1330/2224 [23:28<15:40,  1.05s/it]\u001b[A\n",
      " 60%|█████▉    | 1331/2224 [23:29<15:37,  1.05s/it]\u001b[A\n",
      " 60%|█████▉    | 1332/2224 [23:30<15:37,  1.05s/it]\u001b[A\n",
      " 60%|█████▉    | 1333/2224 [23:31<15:35,  1.05s/it]\u001b[A\n",
      " 60%|█████▉    | 1334/2224 [23:32<15:34,  1.05s/it]\u001b[A\n",
      " 60%|██████    | 1335/2224 [23:33<15:33,  1.05s/it]\u001b[A\n",
      " 60%|██████    | 1336/2224 [23:34<15:33,  1.05s/it]\u001b[A\n",
      " 60%|██████    | 1337/2224 [23:35<15:32,  1.05s/it]\u001b[A\n",
      " 60%|██████    | 1338/2224 [23:36<15:30,  1.05s/it]\u001b[A\n",
      " 60%|██████    | 1339/2224 [23:37<15:27,  1.05s/it]\u001b[A\n",
      " 60%|██████    | 1340/2224 [23:38<15:44,  1.07s/it]\u001b[A\n",
      " 60%|██████    | 1341/2224 [23:39<15:38,  1.06s/it]\u001b[A\n",
      " 60%|██████    | 1342/2224 [23:41<15:43,  1.07s/it]\u001b[A\n",
      " 60%|██████    | 1343/2224 [23:42<15:34,  1.06s/it]\u001b[A\n",
      " 60%|██████    | 1344/2224 [23:43<15:30,  1.06s/it]\u001b[A\n",
      " 60%|██████    | 1345/2224 [23:44<15:27,  1.06s/it]\u001b[A\n",
      " 61%|██████    | 1346/2224 [23:45<15:21,  1.05s/it]\u001b[A\n",
      " 61%|██████    | 1347/2224 [23:46<15:20,  1.05s/it]\u001b[A\n",
      " 61%|██████    | 1348/2224 [23:47<15:17,  1.05s/it]\u001b[A\n",
      " 61%|██████    | 1349/2224 [23:48<15:18,  1.05s/it]\u001b[A\n",
      " 61%|██████    | 1350/2224 [23:49<15:18,  1.05s/it]\u001b[A\n",
      " 61%|██████    | 1351/2224 [23:50<15:16,  1.05s/it]\u001b[A\n",
      " 61%|██████    | 1352/2224 [23:51<15:20,  1.06s/it]\u001b[A\n",
      " 61%|██████    | 1353/2224 [23:52<15:24,  1.06s/it]\u001b[A\n",
      " 61%|██████    | 1354/2224 [23:53<15:17,  1.05s/it]\u001b[A\n",
      " 61%|██████    | 1355/2224 [23:54<15:13,  1.05s/it]\u001b[A\n",
      " 61%|██████    | 1356/2224 [23:55<15:06,  1.04s/it]\u001b[A\n",
      " 61%|██████    | 1357/2224 [23:56<15:02,  1.04s/it]\u001b[A\n",
      " 61%|██████    | 1358/2224 [23:57<14:59,  1.04s/it]\u001b[A\n",
      " 61%|██████    | 1359/2224 [23:58<14:56,  1.04s/it]\u001b[A\n",
      " 61%|██████    | 1360/2224 [23:59<14:54,  1.04s/it]\u001b[A\n",
      " 61%|██████    | 1361/2224 [24:00<14:54,  1.04s/it]\u001b[A\n",
      " 61%|██████    | 1362/2224 [24:01<14:51,  1.03s/it]\u001b[A\n",
      " 61%|██████▏   | 1363/2224 [24:02<14:49,  1.03s/it]\u001b[A\n",
      " 61%|██████▏   | 1364/2224 [24:04<14:51,  1.04s/it]\u001b[A\n",
      " 61%|██████▏   | 1365/2224 [24:05<14:45,  1.03s/it]\u001b[A\n",
      " 61%|██████▏   | 1366/2224 [24:06<14:41,  1.03s/it]\u001b[A\n",
      " 61%|██████▏   | 1367/2224 [24:07<14:42,  1.03s/it]\u001b[A\n",
      " 62%|██████▏   | 1368/2224 [24:08<14:42,  1.03s/it]\u001b[A\n",
      " 62%|██████▏   | 1369/2224 [24:09<14:49,  1.04s/it]\u001b[A\n",
      " 62%|██████▏   | 1370/2224 [24:10<15:10,  1.07s/it]\u001b[A\n",
      " 62%|██████▏   | 1371/2224 [24:11<14:56,  1.05s/it]\u001b[A\n",
      " 62%|██████▏   | 1372/2224 [24:12<14:46,  1.04s/it]\u001b[A\n",
      " 62%|██████▏   | 1373/2224 [24:13<14:44,  1.04s/it]\u001b[A\n",
      " 62%|██████▏   | 1374/2224 [24:14<14:44,  1.04s/it]\u001b[A\n",
      " 62%|██████▏   | 1375/2224 [24:15<14:46,  1.04s/it]\u001b[A\n",
      " 62%|██████▏   | 1376/2224 [24:16<14:45,  1.04s/it]\u001b[A\n",
      " 62%|██████▏   | 1377/2224 [24:17<14:41,  1.04s/it]\u001b[A\n",
      " 62%|██████▏   | 1378/2224 [24:18<14:35,  1.03s/it]\u001b[A\n",
      " 62%|██████▏   | 1379/2224 [24:19<14:35,  1.04s/it]\u001b[A\n",
      " 62%|██████▏   | 1380/2224 [24:20<14:52,  1.06s/it]\u001b[A\n",
      " 62%|██████▏   | 1381/2224 [24:22<16:02,  1.14s/it]\u001b[A\n",
      " 62%|██████▏   | 1382/2224 [24:23<15:59,  1.14s/it]\u001b[A\n",
      " 62%|██████▏   | 1383/2224 [24:24<16:03,  1.15s/it]\u001b[A\n",
      " 62%|██████▏   | 1384/2224 [24:25<16:26,  1.17s/it]\u001b[A\n",
      " 62%|██████▏   | 1385/2224 [24:26<15:50,  1.13s/it]\u001b[A\n",
      " 62%|██████▏   | 1386/2224 [24:27<15:26,  1.11s/it]\u001b[A\n",
      " 62%|██████▏   | 1387/2224 [24:28<15:07,  1.08s/it]\u001b[A\n",
      " 62%|██████▏   | 1388/2224 [24:29<14:53,  1.07s/it]\u001b[A\n",
      " 62%|██████▏   | 1389/2224 [24:30<14:46,  1.06s/it]\u001b[A\n",
      " 62%|██████▎   | 1390/2224 [24:31<14:45,  1.06s/it]\u001b[A\n",
      " 63%|██████▎   | 1391/2224 [24:32<14:45,  1.06s/it]\u001b[A\n",
      " 63%|██████▎   | 1392/2224 [24:33<14:38,  1.06s/it]\u001b[A\n",
      " 63%|██████▎   | 1393/2224 [24:34<14:36,  1.06s/it]\u001b[A\n",
      " 63%|██████▎   | 1394/2224 [24:36<14:33,  1.05s/it]\u001b[A\n",
      " 63%|██████▎   | 1395/2224 [24:37<14:28,  1.05s/it]\u001b[A\n",
      " 63%|██████▎   | 1396/2224 [24:38<14:26,  1.05s/it]\u001b[A\n",
      " 63%|██████▎   | 1397/2224 [24:39<14:24,  1.04s/it]\u001b[A\n",
      " 63%|██████▎   | 1398/2224 [24:40<14:20,  1.04s/it]\u001b[A\n",
      " 63%|██████▎   | 1399/2224 [24:41<14:21,  1.04s/it]\u001b[A\n",
      " 63%|██████▎   | 1400/2224 [24:42<14:21,  1.04s/it]\u001b[A\n",
      " 63%|██████▎   | 1401/2224 [24:43<14:21,  1.05s/it]\u001b[A\n",
      " 63%|██████▎   | 1402/2224 [24:44<14:20,  1.05s/it]\u001b[A\n",
      " 63%|██████▎   | 1403/2224 [24:45<14:20,  1.05s/it]\u001b[A\n",
      " 63%|██████▎   | 1404/2224 [24:46<14:18,  1.05s/it]\u001b[A\n",
      " 63%|██████▎   | 1405/2224 [24:47<14:14,  1.04s/it]\u001b[A\n",
      " 63%|██████▎   | 1406/2224 [24:48<14:13,  1.04s/it]\u001b[A\n",
      " 63%|██████▎   | 1407/2224 [24:49<14:13,  1.04s/it]\u001b[A\n",
      " 63%|██████▎   | 1408/2224 [24:50<14:10,  1.04s/it]\u001b[A\n",
      " 63%|██████▎   | 1409/2224 [24:51<14:10,  1.04s/it]\u001b[A\n",
      " 63%|██████▎   | 1410/2224 [24:52<14:14,  1.05s/it]\u001b[A\n",
      " 63%|██████▎   | 1411/2224 [24:53<14:13,  1.05s/it]\u001b[A\n",
      " 63%|██████▎   | 1412/2224 [24:54<14:09,  1.05s/it]\u001b[A\n",
      " 64%|██████▎   | 1413/2224 [24:55<14:15,  1.05s/it]\u001b[A\n",
      " 64%|██████▎   | 1414/2224 [24:57<15:13,  1.13s/it]\u001b[A\n",
      " 64%|██████▎   | 1415/2224 [24:58<16:08,  1.20s/it]\u001b[A\n",
      " 64%|██████▎   | 1416/2224 [24:59<15:47,  1.17s/it]\u001b[A\n",
      " 64%|██████▎   | 1417/2224 [25:00<15:14,  1.13s/it]\u001b[A\n",
      " 64%|██████▍   | 1418/2224 [25:01<14:48,  1.10s/it]\u001b[A\n",
      " 64%|██████▍   | 1419/2224 [25:02<14:28,  1.08s/it]\u001b[A\n",
      " 64%|██████▍   | 1420/2224 [25:03<14:20,  1.07s/it]\u001b[A\n",
      " 64%|██████▍   | 1421/2224 [25:04<14:12,  1.06s/it]\u001b[A\n",
      " 64%|██████▍   | 1422/2224 [25:05<14:12,  1.06s/it]\u001b[A\n",
      " 64%|██████▍   | 1423/2224 [25:07<14:12,  1.06s/it]\u001b[A\n",
      " 64%|██████▍   | 1424/2224 [25:08<14:05,  1.06s/it]\u001b[A\n",
      " 64%|██████▍   | 1425/2224 [25:09<13:59,  1.05s/it]\u001b[A\n",
      " 64%|██████▍   | 1426/2224 [25:10<13:55,  1.05s/it]\u001b[A\n",
      " 64%|██████▍   | 1427/2224 [25:11<13:53,  1.05s/it]\u001b[A\n",
      " 64%|██████▍   | 1428/2224 [25:12<13:51,  1.04s/it]\u001b[A\n",
      " 64%|██████▍   | 1429/2224 [25:13<13:57,  1.05s/it]\u001b[A\n",
      " 64%|██████▍   | 1430/2224 [25:14<14:01,  1.06s/it]\u001b[A\n",
      " 64%|██████▍   | 1431/2224 [25:15<14:03,  1.06s/it]\u001b[A\n",
      " 64%|██████▍   | 1432/2224 [25:16<13:57,  1.06s/it]\u001b[A\n",
      " 64%|██████▍   | 1433/2224 [25:17<13:48,  1.05s/it]\u001b[A\n",
      " 64%|██████▍   | 1434/2224 [25:18<13:44,  1.04s/it]\u001b[A\n",
      " 65%|██████▍   | 1435/2224 [25:19<13:45,  1.05s/it]\u001b[A\n",
      " 65%|██████▍   | 1436/2224 [25:20<13:49,  1.05s/it]\u001b[A\n",
      " 65%|██████▍   | 1437/2224 [25:21<13:44,  1.05s/it]\u001b[A\n",
      " 65%|██████▍   | 1438/2224 [25:22<13:43,  1.05s/it]\u001b[A\n",
      " 65%|██████▍   | 1439/2224 [25:23<14:00,  1.07s/it]\u001b[A\n",
      " 65%|██████▍   | 1440/2224 [25:24<13:53,  1.06s/it]\u001b[A\n",
      " 65%|██████▍   | 1441/2224 [25:25<13:46,  1.06s/it]\u001b[A\n",
      " 65%|██████▍   | 1442/2224 [25:27<13:45,  1.06s/it]\u001b[A\n",
      " 65%|██████▍   | 1443/2224 [25:28<13:36,  1.05s/it]\u001b[A\n",
      " 65%|██████▍   | 1444/2224 [25:29<13:31,  1.04s/it]\u001b[A\n",
      " 65%|██████▍   | 1445/2224 [25:30<13:29,  1.04s/it]\u001b[A\n",
      " 65%|██████▌   | 1446/2224 [25:31<13:28,  1.04s/it]\u001b[A\n",
      " 65%|██████▌   | 1447/2224 [25:32<13:29,  1.04s/it]\u001b[A\n",
      " 65%|██████▌   | 1448/2224 [25:33<13:33,  1.05s/it]\u001b[A\n",
      " 65%|██████▌   | 1449/2224 [25:34<13:34,  1.05s/it]\u001b[A\n",
      " 65%|██████▌   | 1450/2224 [25:35<13:33,  1.05s/it]\u001b[A\n",
      " 65%|██████▌   | 1451/2224 [25:36<13:29,  1.05s/it]\u001b[A\n",
      " 65%|██████▌   | 1452/2224 [25:37<13:27,  1.05s/it]\u001b[A\n",
      " 65%|██████▌   | 1453/2224 [25:38<13:47,  1.07s/it]\u001b[A\n",
      " 65%|██████▌   | 1454/2224 [25:39<13:43,  1.07s/it]\u001b[A\n",
      " 65%|██████▌   | 1455/2224 [25:40<13:45,  1.07s/it]\u001b[A\n",
      " 65%|██████▌   | 1456/2224 [25:41<13:43,  1.07s/it]\u001b[A\n",
      " 66%|██████▌   | 1457/2224 [25:42<13:36,  1.06s/it]\u001b[A\n",
      " 66%|██████▌   | 1458/2224 [25:43<13:30,  1.06s/it]\u001b[A\n",
      " 66%|██████▌   | 1459/2224 [25:44<13:24,  1.05s/it]\u001b[A\n",
      " 66%|██████▌   | 1460/2224 [25:45<13:24,  1.05s/it]\u001b[A\n",
      " 66%|██████▌   | 1461/2224 [25:46<13:14,  1.04s/it]\u001b[A\n",
      " 66%|██████▌   | 1462/2224 [25:48<13:15,  1.04s/it]\u001b[A\n",
      " 66%|██████▌   | 1463/2224 [25:49<13:14,  1.04s/it]\u001b[A\n",
      " 66%|██████▌   | 1464/2224 [25:50<13:12,  1.04s/it]\u001b[A\n",
      " 66%|██████▌   | 1465/2224 [25:51<13:10,  1.04s/it]\u001b[A\n",
      " 66%|██████▌   | 1466/2224 [25:52<13:11,  1.04s/it]\u001b[A\n",
      " 66%|██████▌   | 1467/2224 [25:53<13:13,  1.05s/it]\u001b[A\n",
      " 66%|██████▌   | 1468/2224 [25:54<13:11,  1.05s/it]\u001b[A\n",
      " 66%|██████▌   | 1469/2224 [25:55<13:09,  1.05s/it]\u001b[A\n",
      " 66%|██████▌   | 1470/2224 [25:56<13:06,  1.04s/it]\u001b[A\n",
      " 66%|██████▌   | 1471/2224 [25:57<13:04,  1.04s/it]\u001b[A\n",
      " 66%|██████▌   | 1472/2224 [25:58<13:01,  1.04s/it]\u001b[A\n",
      " 66%|██████▌   | 1473/2224 [25:59<13:04,  1.04s/it]\u001b[A\n",
      " 66%|██████▋   | 1474/2224 [26:00<13:02,  1.04s/it]\u001b[A\n",
      " 66%|██████▋   | 1475/2224 [26:01<13:04,  1.05s/it]\u001b[A\n",
      " 66%|██████▋   | 1476/2224 [26:02<13:05,  1.05s/it]\u001b[A\n",
      " 66%|██████▋   | 1477/2224 [26:03<13:05,  1.05s/it]\u001b[A\n",
      " 66%|██████▋   | 1478/2224 [26:04<13:05,  1.05s/it]\u001b[A\n",
      " 67%|██████▋   | 1479/2224 [26:05<13:04,  1.05s/it]\u001b[A\n",
      " 67%|██████▋   | 1480/2224 [26:06<13:00,  1.05s/it]\u001b[A\n",
      " 67%|██████▋   | 1481/2224 [26:07<13:00,  1.05s/it]\u001b[A\n",
      " 67%|██████▋   | 1482/2224 [26:08<12:56,  1.05s/it]\u001b[A\n",
      " 67%|██████▋   | 1483/2224 [26:10<12:57,  1.05s/it]\u001b[A\n",
      " 67%|██████▋   | 1484/2224 [26:11<12:54,  1.05s/it]\u001b[A\n",
      " 67%|██████▋   | 1485/2224 [26:12<12:49,  1.04s/it]\u001b[A\n",
      " 67%|██████▋   | 1486/2224 [26:13<12:50,  1.04s/it]\u001b[A\n",
      " 67%|██████▋   | 1487/2224 [26:14<12:49,  1.04s/it]\u001b[A\n",
      " 67%|██████▋   | 1488/2224 [26:15<12:49,  1.05s/it]\u001b[A\n",
      " 67%|██████▋   | 1489/2224 [26:16<12:51,  1.05s/it]\u001b[A\n",
      " 67%|██████▋   | 1490/2224 [26:17<12:50,  1.05s/it]\u001b[A\n",
      " 67%|██████▋   | 1491/2224 [26:18<12:48,  1.05s/it]\u001b[A\n",
      " 67%|██████▋   | 1492/2224 [26:19<12:47,  1.05s/it]\u001b[A\n",
      " 67%|██████▋   | 1493/2224 [26:20<12:45,  1.05s/it]\u001b[A\n",
      " 67%|██████▋   | 1494/2224 [26:21<12:40,  1.04s/it]\u001b[A\n",
      " 67%|██████▋   | 1495/2224 [26:22<12:40,  1.04s/it]\u001b[A\n",
      " 67%|██████▋   | 1496/2224 [26:23<12:41,  1.05s/it]\u001b[A\n",
      " 67%|██████▋   | 1497/2224 [26:24<12:41,  1.05s/it]\u001b[A\n",
      " 67%|██████▋   | 1498/2224 [26:25<12:40,  1.05s/it]\u001b[A\n",
      " 67%|██████▋   | 1499/2224 [26:26<12:39,  1.05s/it]\u001b[A\n",
      " 67%|██████▋   | 1500/2224 [26:27<12:36,  1.04s/it]\u001b[A\n",
      " 67%|██████▋   | 1501/2224 [26:28<12:39,  1.05s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1502/2224 [26:29<12:36,  1.05s/it]\u001b[A\n",
      " 68%|██████▊   | 1503/2224 [26:30<12:34,  1.05s/it]\u001b[A\n",
      " 68%|██████▊   | 1504/2224 [26:31<12:36,  1.05s/it]\u001b[A\n",
      " 68%|██████▊   | 1505/2224 [26:33<12:33,  1.05s/it]\u001b[A\n",
      " 68%|██████▊   | 1506/2224 [26:34<12:28,  1.04s/it]\u001b[A\n",
      " 68%|██████▊   | 1507/2224 [26:35<12:28,  1.04s/it]\u001b[A\n",
      " 68%|██████▊   | 1508/2224 [26:36<12:25,  1.04s/it]\u001b[A\n",
      " 68%|██████▊   | 1509/2224 [26:37<12:22,  1.04s/it]\u001b[A\n",
      " 68%|██████▊   | 1510/2224 [26:38<12:21,  1.04s/it]\u001b[A\n",
      " 68%|██████▊   | 1511/2224 [26:39<12:18,  1.04s/it]\u001b[A\n",
      " 68%|██████▊   | 1512/2224 [26:40<12:17,  1.04s/it]\u001b[A\n",
      " 68%|██████▊   | 1513/2224 [26:41<12:20,  1.04s/it]\u001b[A\n",
      " 68%|██████▊   | 1514/2224 [26:42<12:22,  1.05s/it]\u001b[A\n",
      " 68%|██████▊   | 1515/2224 [26:43<12:20,  1.04s/it]\u001b[A\n",
      " 68%|██████▊   | 1516/2224 [26:44<12:14,  1.04s/it]\u001b[A\n",
      " 68%|██████▊   | 1517/2224 [26:45<12:06,  1.03s/it]\u001b[A\n",
      " 68%|██████▊   | 1518/2224 [26:46<12:09,  1.03s/it]\u001b[A\n",
      " 68%|██████▊   | 1519/2224 [26:47<12:08,  1.03s/it]\u001b[A\n",
      " 68%|██████▊   | 1520/2224 [26:48<12:07,  1.03s/it]\u001b[A\n",
      " 68%|██████▊   | 1521/2224 [26:49<12:06,  1.03s/it]\u001b[A\n",
      " 68%|██████▊   | 1522/2224 [26:50<12:05,  1.03s/it]\u001b[A\n",
      " 68%|██████▊   | 1523/2224 [26:51<12:09,  1.04s/it]\u001b[A\n",
      " 69%|██████▊   | 1524/2224 [26:52<12:15,  1.05s/it]\u001b[A\n",
      " 69%|██████▊   | 1525/2224 [26:53<12:21,  1.06s/it]\u001b[A\n",
      " 69%|██████▊   | 1526/2224 [26:54<12:17,  1.06s/it]\u001b[A\n",
      " 69%|██████▊   | 1527/2224 [26:55<12:16,  1.06s/it]\u001b[A\n",
      " 69%|██████▊   | 1528/2224 [26:56<12:10,  1.05s/it]\u001b[A\n",
      " 69%|██████▉   | 1529/2224 [26:58<12:07,  1.05s/it]\u001b[A\n",
      " 69%|██████▉   | 1530/2224 [26:59<12:05,  1.05s/it]\u001b[A\n",
      " 69%|██████▉   | 1531/2224 [27:00<12:02,  1.04s/it]\u001b[A\n",
      " 69%|██████▉   | 1532/2224 [27:01<12:01,  1.04s/it]\u001b[A\n",
      " 69%|██████▉   | 1533/2224 [27:02<11:59,  1.04s/it]\u001b[A\n",
      " 69%|██████▉   | 1534/2224 [27:03<11:58,  1.04s/it]\u001b[A\n",
      " 69%|██████▉   | 1535/2224 [27:04<11:57,  1.04s/it]\u001b[A\n",
      " 69%|██████▉   | 1536/2224 [27:05<11:55,  1.04s/it]\u001b[A\n",
      " 69%|██████▉   | 1537/2224 [27:06<11:57,  1.04s/it]\u001b[A\n",
      " 69%|██████▉   | 1538/2224 [27:07<11:59,  1.05s/it]\u001b[A\n",
      " 69%|██████▉   | 1539/2224 [27:08<11:57,  1.05s/it]\u001b[A\n",
      " 69%|██████▉   | 1540/2224 [27:09<11:54,  1.04s/it]\u001b[A\n",
      " 69%|██████▉   | 1541/2224 [27:10<11:51,  1.04s/it]\u001b[A\n",
      " 69%|██████▉   | 1542/2224 [27:11<11:49,  1.04s/it]\u001b[A\n",
      " 69%|██████▉   | 1543/2224 [27:12<11:47,  1.04s/it]\u001b[A\n",
      " 69%|██████▉   | 1544/2224 [27:13<11:43,  1.03s/it]\u001b[A\n",
      " 69%|██████▉   | 1545/2224 [27:14<11:44,  1.04s/it]\u001b[A\n",
      " 70%|██████▉   | 1546/2224 [27:15<11:52,  1.05s/it]\u001b[A\n",
      " 70%|██████▉   | 1547/2224 [27:16<11:54,  1.06s/it]\u001b[A\n",
      " 70%|██████▉   | 1548/2224 [27:17<11:48,  1.05s/it]\u001b[A\n",
      " 70%|██████▉   | 1549/2224 [27:18<11:45,  1.05s/it]\u001b[A\n",
      " 70%|██████▉   | 1550/2224 [27:19<11:44,  1.04s/it]\u001b[A\n",
      " 70%|██████▉   | 1551/2224 [27:20<11:40,  1.04s/it]\u001b[A\n",
      " 70%|██████▉   | 1552/2224 [27:22<11:38,  1.04s/it]\u001b[A\n",
      " 70%|██████▉   | 1553/2224 [27:23<11:36,  1.04s/it]\u001b[A\n",
      " 70%|██████▉   | 1554/2224 [27:24<11:33,  1.03s/it]\u001b[A\n",
      " 70%|██████▉   | 1555/2224 [27:25<11:28,  1.03s/it]\u001b[A\n",
      " 70%|██████▉   | 1556/2224 [27:26<11:30,  1.03s/it]\u001b[A\n",
      " 70%|███████   | 1557/2224 [27:27<11:36,  1.04s/it]\u001b[A\n",
      " 70%|███████   | 1558/2224 [27:28<11:35,  1.04s/it]\u001b[A\n",
      " 70%|███████   | 1559/2224 [27:29<11:33,  1.04s/it]\u001b[A\n",
      " 70%|███████   | 1560/2224 [27:30<11:31,  1.04s/it]\u001b[A\n",
      " 70%|███████   | 1561/2224 [27:31<11:30,  1.04s/it]\u001b[A\n",
      " 70%|███████   | 1562/2224 [27:32<11:29,  1.04s/it]\u001b[A\n",
      " 70%|███████   | 1563/2224 [27:33<11:26,  1.04s/it]\u001b[A\n",
      " 70%|███████   | 1564/2224 [27:34<11:26,  1.04s/it]\u001b[A\n",
      " 70%|███████   | 1565/2224 [27:35<11:27,  1.04s/it]\u001b[A\n",
      " 70%|███████   | 1566/2224 [27:36<11:25,  1.04s/it]\u001b[A\n",
      " 70%|███████   | 1567/2224 [27:37<11:24,  1.04s/it]\u001b[A\n",
      " 71%|███████   | 1568/2224 [27:38<11:39,  1.07s/it]\u001b[A\n",
      " 71%|███████   | 1569/2224 [27:39<11:34,  1.06s/it]\u001b[A\n",
      " 71%|███████   | 1570/2224 [27:40<11:36,  1.06s/it]\u001b[A\n",
      " 71%|███████   | 1571/2224 [27:41<11:30,  1.06s/it]\u001b[A\n",
      " 71%|███████   | 1572/2224 [27:42<11:25,  1.05s/it]\u001b[A\n",
      " 71%|███████   | 1573/2224 [27:43<11:24,  1.05s/it]\u001b[A\n",
      " 71%|███████   | 1574/2224 [27:45<11:24,  1.05s/it]\u001b[A\n",
      " 71%|███████   | 1575/2224 [27:46<11:24,  1.05s/it]\u001b[A\n",
      " 71%|███████   | 1576/2224 [27:47<11:19,  1.05s/it]\u001b[A\n",
      " 71%|███████   | 1577/2224 [27:48<11:16,  1.05s/it]\u001b[A\n",
      " 71%|███████   | 1578/2224 [27:49<11:16,  1.05s/it]\u001b[A\n",
      " 71%|███████   | 1579/2224 [27:50<11:14,  1.05s/it]\u001b[A\n",
      " 71%|███████   | 1580/2224 [27:51<11:15,  1.05s/it]\u001b[A\n",
      " 71%|███████   | 1581/2224 [27:52<11:17,  1.05s/it]\u001b[A\n",
      " 71%|███████   | 1582/2224 [27:53<11:15,  1.05s/it]\u001b[A\n",
      " 71%|███████   | 1583/2224 [27:54<11:12,  1.05s/it]\u001b[A\n",
      " 71%|███████   | 1584/2224 [27:55<11:10,  1.05s/it]\u001b[A\n",
      " 71%|███████▏  | 1585/2224 [27:56<11:08,  1.05s/it]\u001b[A\n",
      " 71%|███████▏  | 1586/2224 [27:57<11:05,  1.04s/it]\u001b[A\n",
      " 71%|███████▏  | 1587/2224 [27:58<11:05,  1.04s/it]\u001b[A\n",
      " 71%|███████▏  | 1588/2224 [27:59<11:09,  1.05s/it]\u001b[A\n",
      " 71%|███████▏  | 1589/2224 [28:00<11:10,  1.06s/it]\u001b[A\n",
      " 71%|███████▏  | 1590/2224 [28:01<11:06,  1.05s/it]\u001b[A\n",
      " 72%|███████▏  | 1591/2224 [28:02<11:04,  1.05s/it]\u001b[A\n",
      " 72%|███████▏  | 1592/2224 [28:03<11:01,  1.05s/it]\u001b[A\n",
      " 72%|███████▏  | 1593/2224 [28:04<11:00,  1.05s/it]\u001b[A\n",
      " 72%|███████▏  | 1594/2224 [28:06<10:58,  1.04s/it]\u001b[A\n",
      " 72%|███████▏  | 1595/2224 [28:07<11:00,  1.05s/it]\u001b[A\n",
      " 72%|███████▏  | 1596/2224 [28:08<11:03,  1.06s/it]\u001b[A\n",
      " 72%|███████▏  | 1597/2224 [28:09<11:05,  1.06s/it]\u001b[A\n",
      " 72%|███████▏  | 1598/2224 [28:10<10:58,  1.05s/it]\u001b[A\n",
      " 72%|███████▏  | 1599/2224 [28:11<10:55,  1.05s/it]\u001b[A\n",
      " 72%|███████▏  | 1600/2224 [28:12<10:52,  1.05s/it]\u001b[A\n",
      " 72%|███████▏  | 1601/2224 [28:13<10:59,  1.06s/it]\u001b[A\n",
      " 72%|███████▏  | 1602/2224 [28:14<11:00,  1.06s/it]\u001b[A\n",
      " 72%|███████▏  | 1603/2224 [28:15<11:00,  1.06s/it]\u001b[A\n",
      " 72%|███████▏  | 1604/2224 [28:16<10:55,  1.06s/it]\u001b[A\n",
      " 72%|███████▏  | 1605/2224 [28:17<10:51,  1.05s/it]\u001b[A\n",
      " 72%|███████▏  | 1606/2224 [28:18<10:54,  1.06s/it]\u001b[A\n",
      " 72%|███████▏  | 1607/2224 [28:19<10:52,  1.06s/it]\u001b[A\n",
      " 72%|███████▏  | 1608/2224 [28:20<10:49,  1.05s/it]\u001b[A\n",
      " 72%|███████▏  | 1609/2224 [28:21<10:46,  1.05s/it]\u001b[A\n",
      " 72%|███████▏  | 1610/2224 [28:22<10:43,  1.05s/it]\u001b[A\n",
      " 72%|███████▏  | 1611/2224 [28:23<10:41,  1.05s/it]\u001b[A\n",
      " 72%|███████▏  | 1612/2224 [28:24<10:39,  1.04s/it]\u001b[A\n",
      " 73%|███████▎  | 1613/2224 [28:26<10:41,  1.05s/it]\u001b[A\n",
      " 73%|███████▎  | 1614/2224 [28:27<10:44,  1.06s/it]\u001b[A\n",
      " 73%|███████▎  | 1615/2224 [28:28<10:42,  1.06s/it]\u001b[A\n",
      " 73%|███████▎  | 1616/2224 [28:29<10:38,  1.05s/it]\u001b[A\n",
      " 73%|███████▎  | 1617/2224 [28:30<10:38,  1.05s/it]\u001b[A\n",
      " 73%|███████▎  | 1618/2224 [28:31<10:35,  1.05s/it]\u001b[A\n",
      " 73%|███████▎  | 1619/2224 [28:32<10:35,  1.05s/it]\u001b[A\n",
      " 73%|███████▎  | 1620/2224 [28:33<10:39,  1.06s/it]\u001b[A\n",
      " 73%|███████▎  | 1621/2224 [28:34<10:37,  1.06s/it]\u001b[A\n",
      " 73%|███████▎  | 1622/2224 [28:35<10:34,  1.05s/it]\u001b[A\n",
      " 73%|███████▎  | 1623/2224 [28:36<10:33,  1.05s/it]\u001b[A\n",
      " 73%|███████▎  | 1624/2224 [28:37<10:30,  1.05s/it]\u001b[A\n",
      " 73%|███████▎  | 1625/2224 [28:38<10:28,  1.05s/it]\u001b[A\n",
      " 73%|███████▎  | 1626/2224 [28:39<10:26,  1.05s/it]\u001b[A\n",
      " 73%|███████▎  | 1627/2224 [28:40<10:27,  1.05s/it]\u001b[A\n",
      " 73%|███████▎  | 1628/2224 [28:41<10:29,  1.06s/it]\u001b[A\n",
      " 73%|███████▎  | 1629/2224 [28:42<10:27,  1.05s/it]\u001b[A\n",
      " 73%|███████▎  | 1630/2224 [28:43<10:22,  1.05s/it]\u001b[A\n",
      " 73%|███████▎  | 1631/2224 [28:44<10:17,  1.04s/it]\u001b[A\n",
      " 73%|███████▎  | 1632/2224 [28:46<10:19,  1.05s/it]\u001b[A\n",
      " 73%|███████▎  | 1633/2224 [28:47<10:19,  1.05s/it]\u001b[A\n",
      " 73%|███████▎  | 1634/2224 [28:48<10:19,  1.05s/it]\u001b[A\n",
      " 74%|███████▎  | 1635/2224 [28:49<10:18,  1.05s/it]\u001b[A\n",
      " 74%|███████▎  | 1636/2224 [28:50<10:17,  1.05s/it]\u001b[A\n",
      " 74%|███████▎  | 1637/2224 [28:51<10:17,  1.05s/it]\u001b[A\n",
      " 74%|███████▎  | 1638/2224 [28:52<10:20,  1.06s/it]\u001b[A\n",
      " 74%|███████▎  | 1639/2224 [28:53<10:19,  1.06s/it]\u001b[A\n",
      " 74%|███████▎  | 1640/2224 [28:54<10:13,  1.05s/it]\u001b[A\n",
      " 74%|███████▍  | 1641/2224 [28:55<10:08,  1.04s/it]\u001b[A\n",
      " 74%|███████▍  | 1642/2224 [28:56<10:05,  1.04s/it]\u001b[A\n",
      " 74%|███████▍  | 1643/2224 [28:57<10:04,  1.04s/it]\u001b[A\n",
      " 74%|███████▍  | 1644/2224 [28:58<10:03,  1.04s/it]\u001b[A\n",
      " 74%|███████▍  | 1645/2224 [28:59<10:03,  1.04s/it]\u001b[A\n",
      " 74%|███████▍  | 1646/2224 [29:00<10:08,  1.05s/it]\u001b[A\n",
      " 74%|███████▍  | 1647/2224 [29:01<10:09,  1.06s/it]\u001b[A\n",
      " 74%|███████▍  | 1648/2224 [29:02<10:06,  1.05s/it]\u001b[A\n",
      " 74%|███████▍  | 1649/2224 [29:03<10:05,  1.05s/it]\u001b[A\n",
      " 74%|███████▍  | 1650/2224 [29:04<10:03,  1.05s/it]\u001b[A\n",
      " 74%|███████▍  | 1651/2224 [29:05<10:02,  1.05s/it]\u001b[A\n",
      " 74%|███████▍  | 1652/2224 [29:07<10:02,  1.05s/it]\u001b[A\n",
      " 74%|███████▍  | 1653/2224 [29:08<09:57,  1.05s/it]\u001b[A\n",
      " 74%|███████▍  | 1654/2224 [29:09<09:54,  1.04s/it]\u001b[A\n",
      " 74%|███████▍  | 1655/2224 [29:10<09:51,  1.04s/it]\u001b[A\n",
      " 74%|███████▍  | 1656/2224 [29:11<09:49,  1.04s/it]\u001b[A\n",
      " 75%|███████▍  | 1657/2224 [29:12<09:48,  1.04s/it]\u001b[A\n",
      " 75%|███████▍  | 1658/2224 [29:13<09:49,  1.04s/it]\u001b[A\n",
      " 75%|███████▍  | 1659/2224 [29:14<09:48,  1.04s/it]\u001b[A\n",
      " 75%|███████▍  | 1660/2224 [29:15<09:49,  1.05s/it]\u001b[A\n",
      " 75%|███████▍  | 1661/2224 [29:16<09:49,  1.05s/it]\u001b[A\n",
      " 75%|███████▍  | 1662/2224 [29:17<09:46,  1.04s/it]\u001b[A\n",
      " 75%|███████▍  | 1663/2224 [29:18<09:43,  1.04s/it]\u001b[A\n",
      " 75%|███████▍  | 1664/2224 [29:19<09:41,  1.04s/it]\u001b[A\n",
      " 75%|███████▍  | 1665/2224 [29:20<09:40,  1.04s/it]\u001b[A\n",
      " 75%|███████▍  | 1666/2224 [29:21<10:00,  1.08s/it]\u001b[A\n",
      " 75%|███████▍  | 1667/2224 [29:22<09:55,  1.07s/it]\u001b[A\n",
      " 75%|███████▌  | 1668/2224 [29:23<09:48,  1.06s/it]\u001b[A\n",
      " 75%|███████▌  | 1669/2224 [29:24<09:44,  1.05s/it]\u001b[A\n",
      " 75%|███████▌  | 1670/2224 [29:25<09:41,  1.05s/it]\u001b[A\n",
      " 75%|███████▌  | 1671/2224 [29:26<09:38,  1.05s/it]\u001b[A\n",
      " 75%|███████▌  | 1672/2224 [29:27<09:37,  1.05s/it]\u001b[A\n",
      " 75%|███████▌  | 1673/2224 [29:28<09:35,  1.04s/it]\u001b[A\n",
      " 75%|███████▌  | 1674/2224 [29:30<09:33,  1.04s/it]\u001b[A\n",
      " 75%|███████▌  | 1675/2224 [29:31<09:31,  1.04s/it]\u001b[A\n",
      " 75%|███████▌  | 1676/2224 [29:32<09:32,  1.04s/it]\u001b[A\n",
      " 75%|███████▌  | 1677/2224 [29:33<09:35,  1.05s/it]\u001b[A\n",
      " 75%|███████▌  | 1678/2224 [29:34<09:34,  1.05s/it]\u001b[A\n",
      " 75%|███████▌  | 1679/2224 [29:35<09:37,  1.06s/it]\u001b[A\n",
      " 76%|███████▌  | 1680/2224 [29:36<09:33,  1.05s/it]\u001b[A\n",
      " 76%|███████▌  | 1681/2224 [29:37<09:28,  1.05s/it]\u001b[A\n",
      " 76%|███████▌  | 1682/2224 [29:38<09:38,  1.07s/it]\u001b[A\n",
      " 76%|███████▌  | 1683/2224 [29:39<09:35,  1.06s/it]\u001b[A\n",
      " 76%|███████▌  | 1684/2224 [29:40<09:36,  1.07s/it]\u001b[A\n",
      " 76%|███████▌  | 1685/2224 [29:41<09:31,  1.06s/it]\u001b[A\n",
      " 76%|███████▌  | 1686/2224 [29:42<09:26,  1.05s/it]\u001b[A\n",
      " 76%|███████▌  | 1687/2224 [29:43<09:19,  1.04s/it]\u001b[A\n",
      " 76%|███████▌  | 1688/2224 [29:44<09:14,  1.03s/it]\u001b[A\n",
      " 76%|███████▌  | 1689/2224 [29:45<09:17,  1.04s/it]\u001b[A\n",
      " 76%|███████▌  | 1690/2224 [29:46<09:14,  1.04s/it]\u001b[A\n",
      " 76%|███████▌  | 1691/2224 [29:47<09:13,  1.04s/it]\u001b[A\n",
      " 76%|███████▌  | 1692/2224 [29:48<09:12,  1.04s/it]\u001b[A\n",
      " 76%|███████▌  | 1693/2224 [29:49<09:11,  1.04s/it]\u001b[A\n",
      " 76%|███████▌  | 1694/2224 [29:50<09:11,  1.04s/it]\u001b[A\n",
      " 76%|███████▌  | 1695/2224 [29:52<09:10,  1.04s/it]\u001b[A\n",
      " 76%|███████▋  | 1696/2224 [29:53<09:08,  1.04s/it]\u001b[A\n",
      " 76%|███████▋  | 1697/2224 [29:54<09:06,  1.04s/it]\u001b[A\n",
      " 76%|███████▋  | 1698/2224 [29:55<09:05,  1.04s/it]\u001b[A\n",
      " 76%|███████▋  | 1699/2224 [29:56<09:00,  1.03s/it]\u001b[A\n",
      " 76%|███████▋  | 1700/2224 [29:57<08:57,  1.03s/it]\u001b[A\n",
      " 76%|███████▋  | 1701/2224 [29:58<08:57,  1.03s/it]\u001b[A\n",
      " 77%|███████▋  | 1702/2224 [29:59<08:57,  1.03s/it]\u001b[A\n",
      " 77%|███████▋  | 1703/2224 [30:00<08:58,  1.03s/it]\u001b[A\n",
      " 77%|███████▋  | 1704/2224 [30:01<08:58,  1.03s/it]\u001b[A\n",
      " 77%|███████▋  | 1705/2224 [30:02<08:57,  1.04s/it]\u001b[A\n",
      " 77%|███████▋  | 1706/2224 [30:03<08:56,  1.04s/it]\u001b[A\n",
      " 77%|███████▋  | 1707/2224 [30:04<08:57,  1.04s/it]\u001b[A\n",
      " 77%|███████▋  | 1708/2224 [30:05<08:55,  1.04s/it]\u001b[A\n",
      " 77%|███████▋  | 1709/2224 [30:06<08:55,  1.04s/it]\u001b[A\n",
      " 77%|███████▋  | 1710/2224 [30:07<08:53,  1.04s/it]\u001b[A\n",
      " 77%|███████▋  | 1711/2224 [30:08<08:52,  1.04s/it]\u001b[A\n",
      " 77%|███████▋  | 1712/2224 [30:09<08:51,  1.04s/it]\u001b[A\n",
      " 77%|███████▋  | 1713/2224 [30:10<08:49,  1.04s/it]\u001b[A\n",
      " 77%|███████▋  | 1714/2224 [30:11<08:49,  1.04s/it]\u001b[A\n",
      " 77%|███████▋  | 1715/2224 [30:12<08:49,  1.04s/it]\u001b[A\n",
      " 77%|███████▋  | 1716/2224 [30:13<08:56,  1.06s/it]\u001b[A\n",
      " 77%|███████▋  | 1717/2224 [30:14<08:55,  1.06s/it]\u001b[A\n",
      " 77%|███████▋  | 1718/2224 [30:15<08:53,  1.05s/it]\u001b[A\n",
      " 77%|███████▋  | 1719/2224 [30:16<08:48,  1.05s/it]\u001b[A\n",
      " 77%|███████▋  | 1720/2224 [30:18<08:47,  1.05s/it]\u001b[A\n",
      " 77%|███████▋  | 1721/2224 [30:19<08:50,  1.06s/it]\u001b[A\n",
      " 77%|███████▋  | 1722/2224 [30:20<08:54,  1.06s/it]\u001b[A\n",
      " 77%|███████▋  | 1723/2224 [30:21<08:49,  1.06s/it]\u001b[A\n",
      " 78%|███████▊  | 1724/2224 [30:22<08:45,  1.05s/it]\u001b[A\n",
      " 78%|███████▊  | 1725/2224 [30:23<08:40,  1.04s/it]\u001b[A\n",
      " 78%|███████▊  | 1726/2224 [30:24<08:47,  1.06s/it]\u001b[A\n",
      " 78%|███████▊  | 1727/2224 [30:25<08:42,  1.05s/it]\u001b[A\n",
      " 78%|███████▊  | 1728/2224 [30:26<08:39,  1.05s/it]\u001b[A\n",
      " 78%|███████▊  | 1729/2224 [30:27<08:38,  1.05s/it]\u001b[A\n",
      " 78%|███████▊  | 1730/2224 [30:28<08:35,  1.04s/it]\u001b[A\n",
      " 78%|███████▊  | 1731/2224 [30:29<08:34,  1.04s/it]\u001b[A\n",
      " 78%|███████▊  | 1732/2224 [30:30<08:33,  1.04s/it]\u001b[A\n",
      " 78%|███████▊  | 1733/2224 [30:31<08:32,  1.04s/it]\u001b[A\n",
      " 78%|███████▊  | 1734/2224 [30:32<08:28,  1.04s/it]\u001b[A\n",
      " 78%|███████▊  | 1735/2224 [30:33<08:29,  1.04s/it]\u001b[A\n",
      " 78%|███████▊  | 1736/2224 [30:34<08:29,  1.04s/it]\u001b[A\n",
      " 78%|███████▊  | 1737/2224 [30:35<08:27,  1.04s/it]\u001b[A\n",
      " 78%|███████▊  | 1738/2224 [30:36<08:27,  1.04s/it]\u001b[A\n",
      " 78%|███████▊  | 1739/2224 [30:37<08:26,  1.05s/it]\u001b[A\n",
      " 78%|███████▊  | 1740/2224 [30:38<08:22,  1.04s/it]\u001b[A\n",
      " 78%|███████▊  | 1741/2224 [30:39<08:18,  1.03s/it]\u001b[A\n",
      " 78%|███████▊  | 1742/2224 [30:41<08:19,  1.04s/it]\u001b[A\n",
      " 78%|███████▊  | 1743/2224 [30:42<08:25,  1.05s/it]\u001b[A\n",
      " 78%|███████▊  | 1744/2224 [30:43<08:24,  1.05s/it]\u001b[A\n",
      " 78%|███████▊  | 1745/2224 [30:44<08:22,  1.05s/it]\u001b[A\n",
      " 79%|███████▊  | 1746/2224 [30:45<08:16,  1.04s/it]\u001b[A\n",
      " 79%|███████▊  | 1747/2224 [30:46<08:18,  1.05s/it]\u001b[A\n",
      " 79%|███████▊  | 1748/2224 [30:47<08:17,  1.05s/it]\u001b[A\n",
      " 79%|███████▊  | 1749/2224 [30:48<08:16,  1.05s/it]\u001b[A\n",
      " 79%|███████▊  | 1750/2224 [30:49<08:12,  1.04s/it]\u001b[A\n",
      " 79%|███████▊  | 1751/2224 [30:50<08:08,  1.03s/it]\u001b[A\n",
      " 79%|███████▉  | 1752/2224 [30:51<08:07,  1.03s/it]\u001b[A\n",
      " 79%|███████▉  | 1753/2224 [30:52<08:08,  1.04s/it]\u001b[A\n",
      " 79%|███████▉  | 1754/2224 [30:53<08:08,  1.04s/it]\u001b[A\n",
      " 79%|███████▉  | 1755/2224 [30:54<08:07,  1.04s/it]\u001b[A\n",
      " 79%|███████▉  | 1756/2224 [30:55<08:07,  1.04s/it]\u001b[A\n",
      " 79%|███████▉  | 1757/2224 [30:56<08:07,  1.04s/it]\u001b[A\n",
      " 79%|███████▉  | 1758/2224 [30:57<08:05,  1.04s/it]\u001b[A\n",
      " 79%|███████▉  | 1759/2224 [30:58<08:01,  1.03s/it]\u001b[A\n",
      " 79%|███████▉  | 1760/2224 [30:59<08:01,  1.04s/it]\u001b[A\n",
      " 79%|███████▉  | 1761/2224 [31:00<08:01,  1.04s/it]\u001b[A\n",
      " 79%|███████▉  | 1762/2224 [31:01<07:57,  1.03s/it]\u001b[A\n",
      " 79%|███████▉  | 1763/2224 [31:02<07:54,  1.03s/it]\u001b[A\n",
      " 79%|███████▉  | 1764/2224 [31:03<07:55,  1.03s/it]\u001b[A\n",
      " 79%|███████▉  | 1765/2224 [31:04<07:56,  1.04s/it]\u001b[A\n",
      " 79%|███████▉  | 1766/2224 [31:05<07:57,  1.04s/it]\u001b[A\n",
      " 79%|███████▉  | 1767/2224 [31:07<07:56,  1.04s/it]\u001b[A\n",
      " 79%|███████▉  | 1768/2224 [31:08<07:53,  1.04s/it]\u001b[A\n",
      " 80%|███████▉  | 1769/2224 [31:09<07:49,  1.03s/it]\u001b[A\n",
      " 80%|███████▉  | 1770/2224 [31:10<07:48,  1.03s/it]\u001b[A\n",
      " 80%|███████▉  | 1771/2224 [31:11<07:49,  1.04s/it]\u001b[A\n",
      " 80%|███████▉  | 1772/2224 [31:12<07:49,  1.04s/it]\u001b[A\n",
      " 80%|███████▉  | 1773/2224 [31:13<07:46,  1.03s/it]\u001b[A\n",
      " 80%|███████▉  | 1774/2224 [31:14<07:46,  1.04s/it]\u001b[A\n",
      " 80%|███████▉  | 1775/2224 [31:15<07:47,  1.04s/it]\u001b[A\n",
      " 80%|███████▉  | 1776/2224 [31:16<07:49,  1.05s/it]\u001b[A\n",
      " 80%|███████▉  | 1777/2224 [31:17<07:50,  1.05s/it]\u001b[A\n",
      " 80%|███████▉  | 1778/2224 [31:18<07:44,  1.04s/it]\u001b[A\n",
      " 80%|███████▉  | 1779/2224 [31:19<07:41,  1.04s/it]\u001b[A\n",
      " 80%|████████  | 1780/2224 [31:20<07:41,  1.04s/it]\u001b[A\n",
      " 80%|████████  | 1781/2224 [31:21<07:42,  1.04s/it]\u001b[A\n",
      " 80%|████████  | 1782/2224 [31:22<07:40,  1.04s/it]\u001b[A\n",
      " 80%|████████  | 1783/2224 [31:23<07:37,  1.04s/it]\u001b[A\n",
      " 80%|████████  | 1784/2224 [31:24<07:34,  1.03s/it]\u001b[A\n",
      " 80%|████████  | 1785/2224 [31:25<07:35,  1.04s/it]\u001b[A\n",
      " 80%|████████  | 1786/2224 [31:26<07:35,  1.04s/it]\u001b[A\n",
      " 80%|████████  | 1787/2224 [31:27<07:35,  1.04s/it]\u001b[A\n",
      " 80%|████████  | 1788/2224 [31:28<07:34,  1.04s/it]\u001b[A\n",
      " 80%|████████  | 1789/2224 [31:29<07:30,  1.04s/it]\u001b[A\n",
      " 80%|████████  | 1790/2224 [31:30<07:29,  1.04s/it]\u001b[A\n",
      " 81%|████████  | 1791/2224 [31:31<07:30,  1.04s/it]\u001b[A\n",
      " 81%|████████  | 1792/2224 [31:33<07:28,  1.04s/it]\u001b[A\n",
      " 81%|████████  | 1793/2224 [31:34<07:27,  1.04s/it]\u001b[A\n",
      " 81%|████████  | 1794/2224 [31:35<07:25,  1.04s/it]\u001b[A\n",
      " 81%|████████  | 1795/2224 [31:36<07:24,  1.04s/it]\u001b[A\n",
      " 81%|████████  | 1796/2224 [31:37<07:23,  1.04s/it]\u001b[A\n",
      " 81%|████████  | 1797/2224 [31:38<07:32,  1.06s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 1798/2224 [31:39<07:30,  1.06s/it]\u001b[A\n",
      " 81%|████████  | 1799/2224 [31:40<07:30,  1.06s/it]\u001b[A\n",
      " 81%|████████  | 1800/2224 [31:41<07:26,  1.05s/it]\u001b[A\n",
      " 81%|████████  | 1801/2224 [31:42<07:23,  1.05s/it]\u001b[A\n",
      " 81%|████████  | 1802/2224 [31:43<07:20,  1.04s/it]\u001b[A\n",
      " 81%|████████  | 1803/2224 [31:44<07:18,  1.04s/it]\u001b[A\n",
      " 81%|████████  | 1804/2224 [31:45<07:18,  1.04s/it]\u001b[A\n",
      " 81%|████████  | 1805/2224 [31:46<07:15,  1.04s/it]\u001b[A\n",
      " 81%|████████  | 1806/2224 [31:47<07:12,  1.04s/it]\u001b[A\n",
      " 81%|████████▏ | 1807/2224 [31:48<07:08,  1.03s/it]\u001b[A\n",
      " 81%|████████▏ | 1808/2224 [31:49<07:09,  1.03s/it]\u001b[A\n",
      " 81%|████████▏ | 1809/2224 [31:50<07:08,  1.03s/it]\u001b[A\n",
      " 81%|████████▏ | 1810/2224 [31:51<07:07,  1.03s/it]\u001b[A\n",
      " 81%|████████▏ | 1811/2224 [31:52<07:06,  1.03s/it]\u001b[A\n",
      " 81%|████████▏ | 1812/2224 [31:53<07:06,  1.03s/it]\u001b[A\n",
      " 82%|████████▏ | 1813/2224 [31:54<07:04,  1.03s/it]\u001b[A\n",
      " 82%|████████▏ | 1814/2224 [31:55<07:04,  1.03s/it]\u001b[A\n",
      " 82%|████████▏ | 1815/2224 [31:56<07:03,  1.03s/it]\u001b[A\n",
      " 82%|████████▏ | 1816/2224 [31:57<07:01,  1.03s/it]\u001b[A\n",
      " 82%|████████▏ | 1817/2224 [31:58<07:01,  1.04s/it]\u001b[A\n",
      " 82%|████████▏ | 1818/2224 [32:00<07:00,  1.03s/it]\u001b[A\n",
      " 82%|████████▏ | 1819/2224 [32:01<06:59,  1.04s/it]\u001b[A\n",
      " 82%|████████▏ | 1820/2224 [32:02<06:58,  1.04s/it]\u001b[A\n",
      " 82%|████████▏ | 1821/2224 [32:03<06:57,  1.04s/it]\u001b[A\n",
      " 82%|████████▏ | 1822/2224 [32:04<06:53,  1.03s/it]\u001b[A\n",
      " 82%|████████▏ | 1823/2224 [32:05<06:53,  1.03s/it]\u001b[A\n",
      " 82%|████████▏ | 1824/2224 [32:06<06:52,  1.03s/it]\u001b[A\n",
      " 82%|████████▏ | 1825/2224 [32:07<06:51,  1.03s/it]\u001b[A\n",
      " 82%|████████▏ | 1826/2224 [32:08<06:53,  1.04s/it]\u001b[A\n",
      " 82%|████████▏ | 1827/2224 [32:09<06:52,  1.04s/it]\u001b[A\n",
      " 82%|████████▏ | 1828/2224 [32:10<06:51,  1.04s/it]\u001b[A\n",
      " 82%|████████▏ | 1829/2224 [32:11<06:49,  1.04s/it]\u001b[A\n",
      " 82%|████████▏ | 1830/2224 [32:12<06:49,  1.04s/it]\u001b[A\n",
      " 82%|████████▏ | 1831/2224 [32:13<06:48,  1.04s/it]\u001b[A\n",
      " 82%|████████▏ | 1832/2224 [32:14<06:47,  1.04s/it]\u001b[A\n",
      " 82%|████████▏ | 1833/2224 [32:15<06:48,  1.04s/it]\u001b[A\n",
      " 82%|████████▏ | 1834/2224 [32:16<06:47,  1.04s/it]\u001b[A\n",
      " 83%|████████▎ | 1835/2224 [32:17<06:45,  1.04s/it]\u001b[A\n",
      " 83%|████████▎ | 1836/2224 [32:18<06:43,  1.04s/it]\u001b[A\n",
      " 83%|████████▎ | 1837/2224 [32:19<06:43,  1.04s/it]\u001b[A\n",
      " 83%|████████▎ | 1838/2224 [32:20<06:41,  1.04s/it]\u001b[A\n",
      " 83%|████████▎ | 1839/2224 [32:21<06:40,  1.04s/it]\u001b[A\n",
      " 83%|████████▎ | 1840/2224 [32:22<06:39,  1.04s/it]\u001b[A\n",
      " 83%|████████▎ | 1841/2224 [32:23<06:35,  1.03s/it]\u001b[A\n",
      " 83%|████████▎ | 1842/2224 [32:24<06:32,  1.03s/it]\u001b[A\n",
      " 83%|████████▎ | 1843/2224 [32:25<06:33,  1.03s/it]\u001b[A\n",
      " 83%|████████▎ | 1844/2224 [32:26<06:32,  1.03s/it]\u001b[A\n",
      " 83%|████████▎ | 1845/2224 [32:28<06:32,  1.03s/it]\u001b[A\n",
      " 83%|████████▎ | 1846/2224 [32:29<06:30,  1.03s/it]\u001b[A\n",
      " 83%|████████▎ | 1847/2224 [32:30<06:27,  1.03s/it]\u001b[A\n",
      " 83%|████████▎ | 1848/2224 [32:31<06:25,  1.02s/it]\u001b[A\n",
      " 83%|████████▎ | 1849/2224 [32:32<06:26,  1.03s/it]\u001b[A\n",
      " 83%|████████▎ | 1850/2224 [32:33<06:25,  1.03s/it]\u001b[A\n",
      " 83%|████████▎ | 1851/2224 [32:34<06:24,  1.03s/it]\u001b[A\n",
      " 83%|████████▎ | 1852/2224 [32:35<06:26,  1.04s/it]\u001b[A\n",
      " 83%|████████▎ | 1853/2224 [32:36<06:26,  1.04s/it]\u001b[A\n",
      " 83%|████████▎ | 1854/2224 [32:37<06:24,  1.04s/it]\u001b[A\n",
      " 83%|████████▎ | 1855/2224 [32:38<06:23,  1.04s/it]\u001b[A\n",
      " 83%|████████▎ | 1856/2224 [32:39<06:21,  1.04s/it]\u001b[A\n",
      " 83%|████████▎ | 1857/2224 [32:40<06:20,  1.04s/it]\u001b[A\n",
      " 84%|████████▎ | 1858/2224 [32:41<06:19,  1.04s/it]\u001b[A\n",
      " 84%|████████▎ | 1859/2224 [32:42<06:17,  1.03s/it]\u001b[A\n",
      " 84%|████████▎ | 1860/2224 [32:43<06:14,  1.03s/it]\u001b[A\n",
      " 84%|████████▎ | 1861/2224 [32:44<06:14,  1.03s/it]\u001b[A\n",
      " 84%|████████▎ | 1862/2224 [32:45<06:15,  1.04s/it]\u001b[A\n",
      " 84%|████████▍ | 1863/2224 [32:46<06:13,  1.04s/it]\u001b[A\n",
      " 84%|████████▍ | 1864/2224 [32:47<06:13,  1.04s/it]\u001b[A\n",
      " 84%|████████▍ | 1865/2224 [32:48<06:11,  1.04s/it]\u001b[A\n",
      " 84%|████████▍ | 1866/2224 [32:49<06:08,  1.03s/it]\u001b[A\n",
      " 84%|████████▍ | 1867/2224 [32:50<06:08,  1.03s/it]\u001b[A\n",
      " 84%|████████▍ | 1868/2224 [32:51<06:07,  1.03s/it]\u001b[A\n",
      " 84%|████████▍ | 1869/2224 [32:52<06:09,  1.04s/it]\u001b[A\n",
      " 84%|████████▍ | 1870/2224 [32:53<06:10,  1.05s/it]\u001b[A\n",
      " 84%|████████▍ | 1871/2224 [32:54<06:08,  1.05s/it]\u001b[A\n",
      " 84%|████████▍ | 1872/2224 [32:56<06:06,  1.04s/it]\u001b[A\n",
      " 84%|████████▍ | 1873/2224 [32:57<06:03,  1.04s/it]\u001b[A\n",
      " 84%|████████▍ | 1874/2224 [32:58<06:03,  1.04s/it]\u001b[A\n",
      " 84%|████████▍ | 1875/2224 [32:59<06:02,  1.04s/it]\u001b[A\n",
      " 84%|████████▍ | 1876/2224 [33:00<06:00,  1.04s/it]\u001b[A\n",
      " 84%|████████▍ | 1877/2224 [33:01<05:58,  1.03s/it]\u001b[A\n",
      " 84%|████████▍ | 1878/2224 [33:02<05:59,  1.04s/it]\u001b[A\n",
      " 84%|████████▍ | 1879/2224 [33:03<05:57,  1.04s/it]\u001b[A\n",
      " 85%|████████▍ | 1880/2224 [33:04<05:57,  1.04s/it]\u001b[A\n",
      " 85%|████████▍ | 1881/2224 [33:05<05:56,  1.04s/it]\u001b[A\n",
      " 85%|████████▍ | 1882/2224 [33:06<05:55,  1.04s/it]\u001b[A\n",
      " 85%|████████▍ | 1883/2224 [33:07<05:54,  1.04s/it]\u001b[A\n",
      " 85%|████████▍ | 1884/2224 [33:08<05:53,  1.04s/it]\u001b[A\n",
      " 85%|████████▍ | 1885/2224 [33:09<05:50,  1.04s/it]\u001b[A\n",
      " 85%|████████▍ | 1886/2224 [33:10<05:48,  1.03s/it]\u001b[A\n",
      " 85%|████████▍ | 1887/2224 [33:11<05:48,  1.04s/it]\u001b[A\n",
      " 85%|████████▍ | 1888/2224 [33:12<05:47,  1.04s/it]\u001b[A\n",
      " 85%|████████▍ | 1889/2224 [33:13<05:47,  1.04s/it]\u001b[A\n",
      " 85%|████████▍ | 1890/2224 [33:14<05:47,  1.04s/it]\u001b[A\n",
      " 85%|████████▌ | 1891/2224 [33:15<05:48,  1.05s/it]\u001b[A\n",
      " 85%|████████▌ | 1892/2224 [33:16<05:47,  1.05s/it]\u001b[A\n",
      " 85%|████████▌ | 1893/2224 [33:17<05:45,  1.05s/it]\u001b[A\n",
      " 85%|████████▌ | 1894/2224 [33:18<05:44,  1.04s/it]\u001b[A\n",
      " 85%|████████▌ | 1895/2224 [33:19<05:43,  1.04s/it]\u001b[A\n",
      " 85%|████████▌ | 1896/2224 [33:20<05:42,  1.04s/it]\u001b[A\n",
      " 85%|████████▌ | 1897/2224 [33:21<05:41,  1.04s/it]\u001b[A\n",
      " 85%|████████▌ | 1898/2224 [33:23<05:39,  1.04s/it]\u001b[A\n",
      " 85%|████████▌ | 1899/2224 [33:24<05:38,  1.04s/it]\u001b[A\n",
      " 85%|████████▌ | 1900/2224 [33:25<05:37,  1.04s/it]\u001b[A\n",
      " 85%|████████▌ | 1901/2224 [33:26<05:36,  1.04s/it]\u001b[A\n",
      " 86%|████████▌ | 1902/2224 [33:27<05:33,  1.04s/it]\u001b[A\n",
      " 86%|████████▌ | 1903/2224 [33:28<05:32,  1.04s/it]\u001b[A\n",
      " 86%|████████▌ | 1904/2224 [33:29<05:32,  1.04s/it]\u001b[A\n",
      " 86%|████████▌ | 1905/2224 [33:30<05:32,  1.04s/it]\u001b[A\n",
      " 86%|████████▌ | 1906/2224 [33:31<05:31,  1.04s/it]\u001b[A\n",
      " 86%|████████▌ | 1907/2224 [33:32<05:30,  1.04s/it]\u001b[A\n",
      " 86%|████████▌ | 1908/2224 [33:33<05:29,  1.04s/it]\u001b[A\n",
      " 86%|████████▌ | 1909/2224 [33:34<05:27,  1.04s/it]\u001b[A\n",
      " 86%|████████▌ | 1910/2224 [33:35<05:27,  1.04s/it]\u001b[A\n",
      " 86%|████████▌ | 1911/2224 [33:36<05:23,  1.03s/it]\u001b[A\n",
      " 86%|████████▌ | 1912/2224 [33:37<05:20,  1.03s/it]\u001b[A\n",
      " 86%|████████▌ | 1913/2224 [33:38<05:28,  1.05s/it]\u001b[A\n",
      " 86%|████████▌ | 1914/2224 [33:39<05:27,  1.06s/it]\u001b[A\n",
      " 86%|████████▌ | 1915/2224 [33:40<05:29,  1.07s/it]\u001b[A\n",
      " 86%|████████▌ | 1916/2224 [33:41<05:26,  1.06s/it]\u001b[A\n",
      " 86%|████████▌ | 1917/2224 [33:42<05:25,  1.06s/it]\u001b[A\n",
      " 86%|████████▌ | 1918/2224 [33:43<05:22,  1.05s/it]\u001b[A\n",
      " 86%|████████▋ | 1919/2224 [33:44<05:20,  1.05s/it]\u001b[A\n",
      " 86%|████████▋ | 1920/2224 [33:46<05:20,  1.05s/it]\u001b[A\n",
      " 86%|████████▋ | 1921/2224 [33:47<05:18,  1.05s/it]\u001b[A\n",
      " 86%|████████▋ | 1922/2224 [33:48<05:17,  1.05s/it]\u001b[A\n",
      " 86%|████████▋ | 1923/2224 [33:49<05:15,  1.05s/it]\u001b[A\n",
      " 87%|████████▋ | 1924/2224 [33:50<05:12,  1.04s/it]\u001b[A\n",
      " 87%|████████▋ | 1925/2224 [33:51<05:09,  1.03s/it]\u001b[A\n",
      " 87%|████████▋ | 1926/2224 [33:52<05:08,  1.03s/it]\u001b[A\n",
      " 87%|████████▋ | 1927/2224 [33:53<05:07,  1.04s/it]\u001b[A\n",
      " 87%|████████▋ | 1928/2224 [33:54<05:07,  1.04s/it]\u001b[A\n",
      " 87%|████████▋ | 1929/2224 [33:55<05:06,  1.04s/it]\u001b[A\n",
      " 87%|████████▋ | 1930/2224 [33:56<05:06,  1.04s/it]\u001b[A\n",
      " 87%|████████▋ | 1931/2224 [33:57<05:05,  1.04s/it]\u001b[A\n",
      " 87%|████████▋ | 1932/2224 [33:58<05:06,  1.05s/it]\u001b[A\n",
      " 87%|████████▋ | 1933/2224 [33:59<05:02,  1.04s/it]\u001b[A\n",
      " 87%|████████▋ | 1934/2224 [34:00<05:01,  1.04s/it]\u001b[A\n",
      " 87%|████████▋ | 1935/2224 [34:01<05:00,  1.04s/it]\u001b[A\n",
      " 87%|████████▋ | 1936/2224 [34:02<04:59,  1.04s/it]\u001b[A\n",
      " 87%|████████▋ | 1937/2224 [34:03<04:57,  1.04s/it]\u001b[A\n",
      " 87%|████████▋ | 1938/2224 [34:04<04:56,  1.04s/it]\u001b[A\n",
      " 87%|████████▋ | 1939/2224 [34:05<04:57,  1.05s/it]\u001b[A\n",
      " 87%|████████▋ | 1940/2224 [34:06<04:56,  1.04s/it]\u001b[A\n",
      " 87%|████████▋ | 1941/2224 [34:07<04:54,  1.04s/it]\u001b[A\n",
      " 87%|████████▋ | 1942/2224 [34:08<04:52,  1.04s/it]\u001b[A\n",
      " 87%|████████▋ | 1943/2224 [34:09<04:50,  1.03s/it]\u001b[A\n",
      " 87%|████████▋ | 1944/2224 [34:10<04:48,  1.03s/it]\u001b[A\n",
      " 87%|████████▋ | 1945/2224 [34:11<04:46,  1.03s/it]\u001b[A\n",
      " 88%|████████▊ | 1946/2224 [34:13<04:46,  1.03s/it]\u001b[A\n",
      " 88%|████████▊ | 1947/2224 [34:14<04:45,  1.03s/it]\u001b[A\n",
      " 88%|████████▊ | 1948/2224 [34:15<04:46,  1.04s/it]\u001b[A\n",
      " 88%|████████▊ | 1949/2224 [34:16<04:45,  1.04s/it]\u001b[A\n",
      " 88%|████████▊ | 1950/2224 [34:17<04:43,  1.03s/it]\u001b[A\n",
      " 88%|████████▊ | 1951/2224 [34:18<04:41,  1.03s/it]\u001b[A\n",
      " 88%|████████▊ | 1952/2224 [34:19<04:39,  1.03s/it]\u001b[A\n",
      " 88%|████████▊ | 1953/2224 [34:20<04:38,  1.03s/it]\u001b[A\n",
      " 88%|████████▊ | 1954/2224 [34:21<04:57,  1.10s/it]\u001b[A\n",
      " 88%|████████▊ | 1955/2224 [34:22<04:50,  1.08s/it]\u001b[A\n",
      " 88%|████████▊ | 1956/2224 [34:23<04:45,  1.06s/it]\u001b[A\n",
      " 88%|████████▊ | 1957/2224 [34:24<04:40,  1.05s/it]\u001b[A\n",
      " 88%|████████▊ | 1958/2224 [34:25<04:37,  1.04s/it]\u001b[A\n",
      " 88%|████████▊ | 1959/2224 [34:26<04:34,  1.04s/it]\u001b[A\n",
      " 88%|████████▊ | 1960/2224 [34:27<04:32,  1.03s/it]\u001b[A\n",
      " 88%|████████▊ | 1961/2224 [34:28<04:29,  1.02s/it]\u001b[A\n",
      " 88%|████████▊ | 1962/2224 [34:29<04:28,  1.02s/it]\u001b[A\n",
      " 88%|████████▊ | 1963/2224 [34:30<04:27,  1.03s/it]\u001b[A\n",
      " 88%|████████▊ | 1964/2224 [34:31<04:27,  1.03s/it]\u001b[A\n",
      " 88%|████████▊ | 1965/2224 [34:32<04:27,  1.03s/it]\u001b[A\n",
      " 88%|████████▊ | 1966/2224 [34:33<04:26,  1.03s/it]\u001b[A\n",
      " 88%|████████▊ | 1967/2224 [34:34<04:27,  1.04s/it]\u001b[A\n",
      " 88%|████████▊ | 1968/2224 [34:35<04:25,  1.04s/it]\u001b[A\n",
      " 89%|████████▊ | 1969/2224 [34:36<04:24,  1.04s/it]\u001b[A\n",
      " 89%|████████▊ | 1970/2224 [34:37<04:22,  1.03s/it]\u001b[A\n",
      " 89%|████████▊ | 1971/2224 [34:39<04:20,  1.03s/it]\u001b[A\n",
      " 89%|████████▊ | 1972/2224 [34:40<04:19,  1.03s/it]\u001b[A\n",
      " 89%|████████▊ | 1973/2224 [34:41<04:16,  1.02s/it]\u001b[A\n",
      " 89%|████████▉ | 1974/2224 [34:42<04:14,  1.02s/it]\u001b[A\n",
      " 89%|████████▉ | 1975/2224 [34:43<04:14,  1.02s/it]\u001b[A\n",
      " 89%|████████▉ | 1976/2224 [34:44<04:13,  1.02s/it]\u001b[A\n",
      " 89%|████████▉ | 1977/2224 [34:45<04:12,  1.02s/it]\u001b[A\n",
      " 89%|████████▉ | 1978/2224 [34:46<04:12,  1.03s/it]\u001b[A\n",
      " 89%|████████▉ | 1979/2224 [34:47<04:11,  1.03s/it]\u001b[A\n",
      " 89%|████████▉ | 1980/2224 [34:48<04:11,  1.03s/it]\u001b[A\n",
      " 89%|████████▉ | 1981/2224 [34:49<04:10,  1.03s/it]\u001b[A\n",
      " 89%|████████▉ | 1982/2224 [34:50<04:09,  1.03s/it]\u001b[A\n",
      " 89%|████████▉ | 1983/2224 [34:51<04:08,  1.03s/it]\u001b[A\n",
      " 89%|████████▉ | 1984/2224 [34:52<04:05,  1.02s/it]\u001b[A\n",
      " 89%|████████▉ | 1986/2224 [34:54<04:00,  1.01s/it]\u001b[A\n",
      " 89%|████████▉ | 1987/2224 [34:55<04:01,  1.02s/it]\u001b[A\n",
      " 89%|████████▉ | 1988/2224 [34:56<04:11,  1.06s/it]\u001b[A\n",
      " 89%|████████▉ | 1989/2224 [34:57<04:27,  1.14s/it]\u001b[A\n",
      " 89%|████████▉ | 1990/2224 [34:59<04:33,  1.17s/it]\u001b[A\n",
      " 90%|████████▉ | 1991/2224 [35:00<04:22,  1.13s/it]\u001b[A\n",
      " 90%|████████▉ | 1992/2224 [35:01<04:14,  1.10s/it]\u001b[A\n",
      " 90%|████████▉ | 1993/2224 [35:02<04:06,  1.07s/it]\u001b[A\n",
      " 90%|████████▉ | 1994/2224 [35:03<04:02,  1.06s/it]\u001b[A\n",
      " 90%|████████▉ | 1995/2224 [35:04<03:59,  1.05s/it]\u001b[A\n",
      " 90%|████████▉ | 1996/2224 [35:05<03:57,  1.04s/it]\u001b[A\n",
      " 90%|████████▉ | 1997/2224 [35:06<03:56,  1.04s/it]\u001b[A\n",
      " 90%|████████▉ | 1998/2224 [35:07<03:54,  1.04s/it]\u001b[A\n",
      " 90%|████████▉ | 1999/2224 [35:08<03:52,  1.03s/it]\u001b[A\n",
      " 90%|████████▉ | 2000/2224 [35:09<03:50,  1.03s/it]\u001b[A\n",
      " 90%|████████▉ | 2001/2224 [35:10<03:48,  1.03s/it]\u001b[A\n",
      " 90%|█████████ | 2003/2224 [35:12<03:44,  1.02s/it]\u001b[A\n",
      " 90%|█████████ | 2004/2224 [35:13<03:44,  1.02s/it]\u001b[A\n",
      " 90%|█████████ | 2005/2224 [35:14<03:48,  1.04s/it]\u001b[A\n",
      " 90%|█████████ | 2006/2224 [35:15<03:48,  1.05s/it]\u001b[A\n",
      " 90%|█████████ | 2007/2224 [35:16<03:47,  1.05s/it]\u001b[A\n",
      " 90%|█████████ | 2008/2224 [35:17<03:45,  1.04s/it]\u001b[A\n",
      " 90%|█████████ | 2009/2224 [35:18<03:43,  1.04s/it]\u001b[A\n",
      " 90%|█████████ | 2010/2224 [35:19<03:42,  1.04s/it]\u001b[A\n",
      " 90%|█████████ | 2011/2224 [35:20<03:41,  1.04s/it]\u001b[A\n",
      " 90%|█████████ | 2012/2224 [35:21<03:39,  1.04s/it]\u001b[A\n",
      " 91%|█████████ | 2013/2224 [35:22<03:38,  1.03s/it]\u001b[A\n",
      " 91%|█████████ | 2014/2224 [35:23<03:39,  1.04s/it]\u001b[A\n",
      " 91%|█████████ | 2015/2224 [35:24<03:39,  1.05s/it]\u001b[A\n",
      " 91%|█████████ | 2016/2224 [35:25<03:37,  1.05s/it]\u001b[A\n",
      " 91%|█████████ | 2017/2224 [35:26<03:36,  1.05s/it]\u001b[A\n",
      " 91%|█████████ | 2018/2224 [35:27<03:33,  1.04s/it]\u001b[A\n",
      " 91%|█████████ | 2019/2224 [35:28<03:30,  1.03s/it]\u001b[A\n",
      " 91%|█████████ | 2020/2224 [35:30<03:29,  1.03s/it]\u001b[A\n",
      " 91%|█████████ | 2021/2224 [35:31<03:28,  1.03s/it]\u001b[A\n",
      " 91%|█████████ | 2022/2224 [35:32<03:28,  1.03s/it]\u001b[A\n",
      " 91%|█████████ | 2023/2224 [35:33<03:27,  1.03s/it]\u001b[A\n",
      " 91%|█████████ | 2024/2224 [35:34<03:25,  1.03s/it]\u001b[A\n",
      " 91%|█████████ | 2025/2224 [35:35<03:25,  1.03s/it]\u001b[A\n",
      " 91%|█████████ | 2026/2224 [35:36<03:24,  1.03s/it]\u001b[A\n",
      " 91%|█████████ | 2027/2224 [35:37<03:22,  1.03s/it]\u001b[A\n",
      " 91%|█████████ | 2028/2224 [35:38<03:24,  1.04s/it]\u001b[A\n",
      " 91%|█████████ | 2029/2224 [35:39<03:23,  1.04s/it]\u001b[A\n",
      " 91%|█████████▏| 2030/2224 [35:40<03:25,  1.06s/it]\u001b[A\n",
      " 91%|█████████▏| 2031/2224 [35:41<03:22,  1.05s/it]\u001b[A\n",
      " 91%|█████████▏| 2032/2224 [35:42<03:20,  1.05s/it]\u001b[A\n",
      " 91%|█████████▏| 2033/2224 [35:43<03:18,  1.04s/it]\u001b[A\n",
      " 91%|█████████▏| 2034/2224 [35:44<03:17,  1.04s/it]\u001b[A\n",
      " 92%|█████████▏| 2035/2224 [35:45<03:16,  1.04s/it]\u001b[A\n",
      " 92%|█████████▏| 2036/2224 [35:46<03:15,  1.04s/it]\u001b[A\n",
      " 92%|█████████▏| 2037/2224 [35:47<03:13,  1.03s/it]\u001b[A\n",
      " 92%|█████████▏| 2038/2224 [35:48<03:12,  1.03s/it]\u001b[A\n",
      " 92%|█████████▏| 2039/2224 [35:49<03:10,  1.03s/it]\u001b[A\n",
      " 92%|█████████▏| 2040/2224 [35:50<03:09,  1.03s/it]\u001b[A\n",
      " 92%|█████████▏| 2041/2224 [35:51<03:08,  1.03s/it]\u001b[A\n",
      " 92%|█████████▏| 2042/2224 [35:52<03:07,  1.03s/it]\u001b[A\n",
      " 92%|█████████▏| 2043/2224 [35:53<03:08,  1.04s/it]\u001b[A\n",
      " 92%|█████████▏| 2044/2224 [35:54<03:07,  1.04s/it]\u001b[A\n",
      " 92%|█████████▏| 2045/2224 [35:55<03:06,  1.04s/it]\u001b[A\n",
      " 92%|█████████▏| 2046/2224 [35:56<03:04,  1.04s/it]\u001b[A\n",
      " 92%|█████████▏| 2047/2224 [35:58<03:02,  1.03s/it]\u001b[A\n",
      " 92%|█████████▏| 2048/2224 [35:59<03:01,  1.03s/it]\u001b[A\n",
      " 92%|█████████▏| 2049/2224 [36:00<03:00,  1.03s/it]\u001b[A\n",
      " 92%|█████████▏| 2050/2224 [36:01<02:59,  1.03s/it]\u001b[A\n",
      " 92%|█████████▏| 2051/2224 [36:02<02:58,  1.03s/it]\u001b[A\n",
      " 92%|█████████▏| 2052/2224 [36:03<02:58,  1.04s/it]\u001b[A\n",
      " 92%|█████████▏| 2053/2224 [36:04<02:56,  1.03s/it]\u001b[A\n",
      " 92%|█████████▏| 2054/2224 [36:05<02:55,  1.03s/it]\u001b[A\n",
      " 92%|█████████▏| 2055/2224 [36:06<02:54,  1.03s/it]\u001b[A\n",
      " 92%|█████████▏| 2056/2224 [36:07<02:54,  1.04s/it]\u001b[A\n",
      " 92%|█████████▏| 2057/2224 [36:08<02:53,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2058/2224 [36:09<02:52,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2059/2224 [36:10<02:52,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2060/2224 [36:11<02:50,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2061/2224 [36:12<02:49,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2062/2224 [36:13<02:47,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2063/2224 [36:14<02:46,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2064/2224 [36:15<02:46,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2065/2224 [36:16<02:46,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2066/2224 [36:17<02:44,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2067/2224 [36:18<02:43,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2068/2224 [36:19<02:42,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2069/2224 [36:20<02:40,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2070/2224 [36:21<02:39,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2071/2224 [36:22<02:38,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2072/2224 [36:23<02:37,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2073/2224 [36:24<02:36,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2074/2224 [36:26<02:35,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2075/2224 [36:27<02:35,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2076/2224 [36:28<02:33,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2077/2224 [36:29<02:32,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2078/2224 [36:30<02:31,  1.04s/it]\u001b[A\n",
      " 93%|█████████▎| 2079/2224 [36:31<02:30,  1.04s/it]\u001b[A\n",
      " 94%|█████████▎| 2080/2224 [36:32<02:29,  1.04s/it]\u001b[A\n",
      " 94%|█████████▎| 2081/2224 [36:33<02:28,  1.04s/it]\u001b[A\n",
      " 94%|█████████▎| 2082/2224 [36:34<02:27,  1.04s/it]\u001b[A\n",
      " 94%|█████████▎| 2083/2224 [36:35<02:27,  1.04s/it]\u001b[A\n",
      " 94%|█████████▎| 2084/2224 [36:36<02:26,  1.04s/it]\u001b[A\n",
      " 94%|█████████▍| 2085/2224 [36:37<02:24,  1.04s/it]\u001b[A\n",
      " 94%|█████████▍| 2086/2224 [36:38<02:23,  1.04s/it]\u001b[A\n",
      " 94%|█████████▍| 2087/2224 [36:39<02:22,  1.04s/it]\u001b[A\n",
      " 94%|█████████▍| 2088/2224 [36:40<02:21,  1.04s/it]\u001b[A\n",
      " 94%|█████████▍| 2089/2224 [36:41<02:20,  1.04s/it]\u001b[A\n",
      " 94%|█████████▍| 2090/2224 [36:42<02:19,  1.04s/it]\u001b[A\n",
      " 94%|█████████▍| 2091/2224 [36:43<02:18,  1.04s/it]\u001b[A\n",
      " 94%|█████████▍| 2092/2224 [36:44<02:17,  1.04s/it]\u001b[A\n",
      " 94%|█████████▍| 2093/2224 [36:45<02:18,  1.06s/it]\u001b[A\n",
      " 94%|█████████▍| 2094/2224 [36:46<02:16,  1.05s/it]\u001b[A\n",
      " 94%|█████████▍| 2095/2224 [36:47<02:15,  1.05s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 2096/2224 [36:48<02:13,  1.04s/it]\u001b[A\n",
      " 94%|█████████▍| 2097/2224 [36:49<02:11,  1.03s/it]\u001b[A\n",
      " 94%|█████████▍| 2098/2224 [36:51<02:10,  1.04s/it]\u001b[A\n",
      " 94%|█████████▍| 2099/2224 [36:52<02:09,  1.03s/it]\u001b[A\n",
      " 94%|█████████▍| 2100/2224 [36:53<02:07,  1.03s/it]\u001b[A\n",
      " 94%|█████████▍| 2101/2224 [36:54<02:07,  1.03s/it]\u001b[A\n",
      " 95%|█████████▍| 2102/2224 [36:55<02:06,  1.04s/it]\u001b[A\n",
      " 95%|█████████▍| 2103/2224 [36:56<02:05,  1.04s/it]\u001b[A\n",
      " 95%|█████████▍| 2104/2224 [36:57<02:04,  1.03s/it]\u001b[A\n",
      " 95%|█████████▍| 2105/2224 [36:58<02:02,  1.03s/it]\u001b[A\n",
      " 95%|█████████▍| 2106/2224 [36:59<02:02,  1.04s/it]\u001b[A\n",
      " 95%|█████████▍| 2107/2224 [37:00<02:02,  1.04s/it]\u001b[A\n",
      " 95%|█████████▍| 2108/2224 [37:01<02:00,  1.04s/it]\u001b[A\n",
      " 95%|█████████▍| 2109/2224 [37:02<01:59,  1.04s/it]\u001b[A\n",
      " 95%|█████████▍| 2110/2224 [37:03<01:57,  1.03s/it]\u001b[A\n",
      " 95%|█████████▍| 2111/2224 [37:04<01:56,  1.03s/it]\u001b[A\n",
      " 95%|█████████▍| 2112/2224 [37:05<01:55,  1.03s/it]\u001b[A\n",
      " 95%|█████████▌| 2113/2224 [37:06<01:54,  1.03s/it]\u001b[A\n",
      " 95%|█████████▌| 2114/2224 [37:07<01:52,  1.03s/it]\u001b[A\n",
      " 95%|█████████▌| 2115/2224 [37:08<01:51,  1.03s/it]\u001b[A\n",
      " 95%|█████████▌| 2116/2224 [37:09<01:51,  1.03s/it]\u001b[A\n",
      " 95%|█████████▌| 2117/2224 [37:10<01:51,  1.04s/it]\u001b[A\n",
      " 95%|█████████▌| 2118/2224 [37:11<01:49,  1.04s/it]\u001b[A\n",
      " 95%|█████████▌| 2119/2224 [37:12<01:48,  1.03s/it]\u001b[A\n",
      " 95%|█████████▌| 2120/2224 [37:13<01:47,  1.03s/it]\u001b[A\n",
      " 95%|█████████▌| 2121/2224 [37:14<01:46,  1.03s/it]\u001b[A\n",
      " 95%|█████████▌| 2122/2224 [37:15<01:45,  1.03s/it]\u001b[A\n",
      " 95%|█████████▌| 2123/2224 [37:16<01:44,  1.03s/it]\u001b[A\n",
      " 96%|█████████▌| 2124/2224 [37:17<01:43,  1.03s/it]\u001b[A\n",
      " 96%|█████████▌| 2125/2224 [37:18<01:42,  1.03s/it]\u001b[A\n",
      " 96%|█████████▌| 2126/2224 [37:19<01:41,  1.03s/it]\u001b[A\n",
      " 96%|█████████▌| 2127/2224 [37:21<01:40,  1.03s/it]\u001b[A\n",
      " 96%|█████████▌| 2128/2224 [37:22<01:38,  1.03s/it]\u001b[A\n",
      " 96%|█████████▌| 2129/2224 [37:23<01:37,  1.03s/it]\u001b[A\n",
      " 96%|█████████▌| 2130/2224 [37:24<01:36,  1.03s/it]\u001b[A\n",
      " 96%|█████████▌| 2131/2224 [37:25<01:35,  1.03s/it]\u001b[A\n",
      " 96%|█████████▌| 2132/2224 [37:26<01:34,  1.03s/it]\u001b[A\n",
      " 96%|█████████▌| 2133/2224 [37:27<01:33,  1.03s/it]\u001b[A\n",
      " 96%|█████████▌| 2134/2224 [37:28<01:32,  1.03s/it]\u001b[A\n",
      " 96%|█████████▌| 2135/2224 [37:29<01:31,  1.03s/it]\u001b[A\n",
      " 96%|█████████▌| 2136/2224 [37:30<01:30,  1.03s/it]\u001b[A\n",
      " 96%|█████████▌| 2137/2224 [37:31<01:29,  1.03s/it]\u001b[A\n",
      " 96%|█████████▌| 2138/2224 [37:32<01:28,  1.03s/it]\u001b[A\n",
      " 96%|█████████▌| 2139/2224 [37:33<01:28,  1.04s/it]\u001b[A\n",
      " 96%|█████████▌| 2140/2224 [37:34<01:27,  1.04s/it]\u001b[A\n",
      " 96%|█████████▋| 2141/2224 [37:35<01:25,  1.03s/it]\u001b[A\n",
      " 96%|█████████▋| 2142/2224 [37:36<01:24,  1.03s/it]\u001b[A\n",
      " 96%|█████████▋| 2143/2224 [37:37<01:23,  1.03s/it]\u001b[A\n",
      " 96%|█████████▋| 2144/2224 [37:38<01:23,  1.05s/it]\u001b[A\n",
      " 96%|█████████▋| 2145/2224 [37:39<01:22,  1.04s/it]\u001b[A\n",
      " 96%|█████████▋| 2146/2224 [37:40<01:22,  1.05s/it]\u001b[A\n",
      " 97%|█████████▋| 2147/2224 [37:41<01:20,  1.05s/it]\u001b[A\n",
      " 97%|█████████▋| 2148/2224 [37:42<01:19,  1.04s/it]\u001b[A\n",
      " 97%|█████████▋| 2149/2224 [37:43<01:18,  1.05s/it]\u001b[A\n",
      " 97%|█████████▋| 2150/2224 [37:44<01:17,  1.04s/it]\u001b[A\n",
      " 97%|█████████▋| 2151/2224 [37:45<01:16,  1.04s/it]\u001b[A\n",
      " 97%|█████████▋| 2152/2224 [37:46<01:14,  1.04s/it]\u001b[A\n",
      " 97%|█████████▋| 2153/2224 [37:47<01:13,  1.03s/it]\u001b[A\n",
      " 97%|█████████▋| 2154/2224 [37:48<01:11,  1.03s/it]\u001b[A\n",
      " 97%|█████████▋| 2155/2224 [37:49<01:10,  1.03s/it]\u001b[A\n",
      " 97%|█████████▋| 2156/2224 [37:51<01:10,  1.03s/it]\u001b[A\n",
      " 97%|█████████▋| 2157/2224 [37:52<01:09,  1.04s/it]\u001b[A\n",
      " 97%|█████████▋| 2158/2224 [37:53<01:08,  1.03s/it]\u001b[A\n",
      " 97%|█████████▋| 2159/2224 [37:54<01:06,  1.03s/it]\u001b[A\n",
      " 97%|█████████▋| 2160/2224 [37:55<01:05,  1.02s/it]\u001b[A\n",
      " 97%|█████████▋| 2161/2224 [37:56<01:04,  1.02s/it]\u001b[A\n",
      " 97%|█████████▋| 2162/2224 [37:57<01:03,  1.02s/it]\u001b[A\n",
      " 97%|█████████▋| 2163/2224 [37:58<01:02,  1.03s/it]\u001b[A\n",
      " 97%|█████████▋| 2164/2224 [37:59<01:02,  1.03s/it]\u001b[A\n",
      " 97%|█████████▋| 2165/2224 [38:00<01:01,  1.03s/it]\u001b[A\n",
      " 97%|█████████▋| 2166/2224 [38:01<00:59,  1.03s/it]\u001b[A\n",
      " 97%|█████████▋| 2167/2224 [38:02<00:58,  1.03s/it]\u001b[A\n",
      " 97%|█████████▋| 2168/2224 [38:03<00:57,  1.03s/it]\u001b[A\n",
      " 98%|█████████▊| 2169/2224 [38:04<00:56,  1.03s/it]\u001b[A\n",
      " 98%|█████████▊| 2170/2224 [38:05<00:55,  1.03s/it]\u001b[A\n",
      " 98%|█████████▊| 2171/2224 [38:06<00:54,  1.03s/it]\u001b[A\n",
      " 98%|█████████▊| 2172/2224 [38:07<00:53,  1.03s/it]\u001b[A\n",
      " 98%|█████████▊| 2173/2224 [38:08<00:52,  1.03s/it]\u001b[A\n",
      " 98%|█████████▊| 2174/2224 [38:09<00:51,  1.04s/it]\u001b[A\n",
      " 98%|█████████▊| 2175/2224 [38:10<00:51,  1.05s/it]\u001b[A\n",
      " 98%|█████████▊| 2176/2224 [38:11<00:50,  1.04s/it]\u001b[A\n",
      " 98%|█████████▊| 2177/2224 [38:12<00:48,  1.04s/it]\u001b[A\n",
      " 98%|█████████▊| 2178/2224 [38:13<00:47,  1.04s/it]\u001b[A\n",
      " 98%|█████████▊| 2179/2224 [38:14<00:46,  1.04s/it]\u001b[A\n",
      " 98%|█████████▊| 2180/2224 [38:15<00:45,  1.04s/it]\u001b[A\n",
      " 98%|█████████▊| 2181/2224 [38:16<00:44,  1.04s/it]\u001b[A\n",
      " 98%|█████████▊| 2182/2224 [38:17<00:43,  1.04s/it]\u001b[A\n",
      " 98%|█████████▊| 2183/2224 [38:18<00:42,  1.04s/it]\u001b[A\n",
      " 98%|█████████▊| 2184/2224 [38:19<00:41,  1.04s/it]\u001b[A\n",
      " 98%|█████████▊| 2185/2224 [38:21<00:40,  1.04s/it]\u001b[A\n",
      " 98%|█████████▊| 2186/2224 [38:22<00:39,  1.03s/it]\u001b[A\n",
      " 98%|█████████▊| 2187/2224 [38:23<00:38,  1.03s/it]\u001b[A\n",
      " 98%|█████████▊| 2188/2224 [38:24<00:37,  1.03s/it]\u001b[A\n",
      " 98%|█████████▊| 2189/2224 [38:25<00:36,  1.03s/it]\u001b[A\n",
      " 98%|█████████▊| 2190/2224 [38:26<00:35,  1.03s/it]\u001b[A\n",
      " 99%|█████████▊| 2191/2224 [38:27<00:34,  1.03s/it]\u001b[A\n",
      " 99%|█████████▊| 2192/2224 [38:28<00:33,  1.03s/it]\u001b[A\n",
      " 99%|█████████▊| 2193/2224 [38:29<00:32,  1.03s/it]\u001b[A\n",
      " 99%|█████████▊| 2194/2224 [38:30<00:31,  1.05s/it]\u001b[A\n",
      " 99%|█████████▊| 2195/2224 [38:31<00:30,  1.05s/it]\u001b[A\n",
      " 99%|█████████▊| 2196/2224 [38:32<00:29,  1.05s/it]\u001b[A\n",
      " 99%|█████████▉| 2197/2224 [38:33<00:28,  1.04s/it]\u001b[A\n",
      " 99%|█████████▉| 2198/2224 [38:34<00:27,  1.05s/it]\u001b[A\n",
      " 99%|█████████▉| 2199/2224 [38:35<00:26,  1.05s/it]\u001b[A\n",
      " 99%|█████████▉| 2200/2224 [38:36<00:24,  1.04s/it]\u001b[A\n",
      " 99%|█████████▉| 2201/2224 [38:37<00:23,  1.03s/it]\u001b[A\n",
      " 99%|█████████▉| 2202/2224 [38:38<00:22,  1.03s/it]\u001b[A\n",
      " 99%|█████████▉| 2203/2224 [38:39<00:21,  1.03s/it]\u001b[A\n",
      " 99%|█████████▉| 2204/2224 [38:40<00:20,  1.03s/it]\u001b[A\n",
      " 99%|█████████▉| 2205/2224 [38:41<00:19,  1.04s/it]\u001b[A\n",
      " 99%|█████████▉| 2206/2224 [38:42<00:18,  1.04s/it]\u001b[A\n",
      " 99%|█████████▉| 2207/2224 [38:43<00:17,  1.04s/it]\u001b[A\n",
      " 99%|█████████▉| 2208/2224 [38:44<00:16,  1.04s/it]\u001b[A\n",
      " 99%|█████████▉| 2209/2224 [38:45<00:15,  1.04s/it]\u001b[A\n",
      " 99%|█████████▉| 2210/2224 [38:46<00:14,  1.04s/it]\u001b[A\n",
      " 99%|█████████▉| 2211/2224 [38:48<00:13,  1.04s/it]\u001b[A\n",
      " 99%|█████████▉| 2212/2224 [38:49<00:12,  1.04s/it]\u001b[A\n",
      "100%|█████████▉| 2213/2224 [38:50<00:11,  1.05s/it]\u001b[A\n",
      "100%|█████████▉| 2214/2224 [38:51<00:10,  1.09s/it]\u001b[A\n",
      "100%|█████████▉| 2215/2224 [38:52<00:09,  1.11s/it]\u001b[A\n",
      "100%|█████████▉| 2216/2224 [38:53<00:08,  1.09s/it]\u001b[A\n",
      "100%|█████████▉| 2217/2224 [38:54<00:07,  1.07s/it]\u001b[A\n",
      "100%|█████████▉| 2218/2224 [38:55<00:06,  1.10s/it]\u001b[A\n",
      "100%|█████████▉| 2219/2224 [38:56<00:05,  1.09s/it]\u001b[A\n",
      "100%|█████████▉| 2220/2224 [38:57<00:04,  1.08s/it]\u001b[A\n",
      "100%|█████████▉| 2221/2224 [38:58<00:03,  1.07s/it]\u001b[A\n",
      "100%|█████████▉| 2222/2224 [38:59<00:02,  1.06s/it]\u001b[A\n",
      "100%|█████████▉| 2223/2224 [39:00<00:01,  1.06s/it]\u001b[A\n",
      "100%|██████████| 2224/2224 [39:02<00:00,  1.06s/it]\u001b[A\n",
      "\n",
      "100%|██████████| 2224/2224 [39:02<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(evaluate(\"../data/processed/dbrd/test\", model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap, vmin=0, aspect=\"equal\")\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.ylim(len(tick_marks) - 0.5, -0.5)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[1012  100]\n",
      " [  89 1023]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnf_matrix = confusion_matrix(results['true'], results['predicted'] ) # index to evaluate partial runs\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "title=\"Confusion matrix\"\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "fig = plt.figure(figsize=(5,5), dpi=100)\n",
    "#fig.set_size_inches(6,6)\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix, classes=[\"Negative\", \"Positive\"],normalize=False, \n",
    "                      title=title, cmap=plt.cm.Blues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(actual_vector=results['true'].values, predict_vector=results['predicted'].values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Statistics : \n",
      "\n",
      "95% CI                                                            (0.90343,0.92661)\n",
      "ACC Macro                                                         0.91502\n",
      "ARI                                                               0.68882\n",
      "AUNP                                                              0.91502\n",
      "AUNU                                                              0.91502\n",
      "Bennett S                                                         0.83004\n",
      "CBA                                                               0.91051\n",
      "CSI                                                               0.83008\n",
      "Chi-Squared                                                       1532.39635\n",
      "Chi-Squared DF                                                    1\n",
      "Conditional Entropy                                               0.41927\n",
      "Cramer V                                                          0.83008\n",
      "Cross Entropy                                                     1.00007\n",
      "F1 Macro                                                          0.91502\n",
      "F1 Micro                                                          0.91502\n",
      "FNR Macro                                                         0.08498\n",
      "FNR Micro                                                         0.08498\n",
      "FPR Macro                                                         0.08498\n",
      "FPR Micro                                                         0.08498\n",
      "Gwet AC1                                                          0.83004\n",
      "Hamming Loss                                                      0.08498\n",
      "Joint Entropy                                                     1.41927\n",
      "KL Divergence                                                     7e-05\n",
      "Kappa                                                             0.83004\n",
      "Kappa 95% CI                                                      (0.80686,0.85322)\n",
      "Kappa No Prevalence                                               0.83004\n",
      "Kappa Standard Error                                              0.01183\n",
      "Kappa Unbiased                                                    0.83003\n",
      "Lambda A                                                          0.83004\n",
      "Lambda B                                                          0.82834\n",
      "Mutual Information                                                0.58066\n",
      "NIR                                                               0.5\n",
      "Overall ACC                                                       0.91502\n",
      "Overall CEN                                                       0.38703\n",
      "Overall J                                                         (1.68669,0.84335)\n",
      "Overall MCC                                                       0.83008\n",
      "Overall MCEN                                                      0.31205\n",
      "Overall RACC                                                      0.5\n",
      "Overall RACCU                                                     0.50001\n",
      "P-Value                                                           None\n",
      "PPV Macro                                                         0.91506\n",
      "PPV Micro                                                         0.91502\n",
      "Pearson C                                                         0.6387\n",
      "Phi-Squared                                                       0.68903\n",
      "RCI                                                               0.58066\n",
      "RR                                                                1112.0\n",
      "Reference Entropy                                                 1.0\n",
      "Response Entropy                                                  0.99993\n",
      "SOA1(Landis & Koch)                                               Almost Perfect\n",
      "SOA2(Fleiss)                                                      Excellent\n",
      "SOA3(Altman)                                                      Very Good\n",
      "SOA4(Cicchetti)                                                   Excellent\n",
      "SOA5(Cramer)                                                      Very Strong\n",
      "SOA6(Matthews)                                                    Strong\n",
      "Scott PI                                                          0.83003\n",
      "Standard Error                                                    0.00591\n",
      "TNR Macro                                                         0.91502\n",
      "TNR Micro                                                         0.91502\n",
      "TPR Macro                                                         0.91502\n",
      "TPR Micro                                                         0.91502\n",
      "Zero-one Loss                                                     189\n",
      "\n",
      "Class Statistics :\n",
      "\n",
      "Classes                                                           0             1             \n",
      "ACC(Accuracy)                                                     0.91502       0.91502       \n",
      "AGF(Adjusted F-score)                                             0.91231       0.91774       \n",
      "AGM(Adjusted geometric mean)                                      0.91666       0.91336       \n",
      "AM(Difference between automatic and manual classification)        -11           11            \n",
      "AUC(Area under the ROC curve)                                     0.91502       0.91502       \n",
      "AUCI(AUC value interpretation)                                    Excellent     Excellent     \n",
      "AUPR(Area under the PR curve)                                     0.91462       0.91546       \n",
      "BCD(Bray-Curtis dissimilarity)                                    0.00247       0.00247       \n",
      "BM(Informedness or bookmaker informedness)                        0.83004       0.83004       \n",
      "CEN(Confusion entropy)                                            0.38834       0.38573       \n",
      "DOR(Diagnostic odds ratio)                                        116.32315     116.32315     \n",
      "DP(Discriminant power)                                            1.13886       1.13886       \n",
      "DPI(Discriminant power interpretation)                            Limited       Limited       \n",
      "ERR(Error rate)                                                   0.08498       0.08498       \n",
      "F0.5(F0.5 score)                                                  0.91733       0.91274       \n",
      "F1(F1 score - harmonic mean of precision and sensitivity)         0.9146        0.91544       \n",
      "F2(F2 score)                                                      0.91188       0.91815       \n",
      "FDR(False discovery rate)                                         0.08084       0.08905       \n",
      "FN(False negative/miss/type 2 error)                              100           89            \n",
      "FNR(Miss rate or false negative rate)                             0.08993       0.08004       \n",
      "FOR(False omission rate)                                          0.08905       0.08084       \n",
      "FP(False positive/type 1 error/false alarm)                       89            100           \n",
      "FPR(Fall-out or false positive rate)                              0.08004       0.08993       \n",
      "G(G-measure geometric mean of precision and sensitivity)          0.91461       0.91545       \n",
      "GI(Gini index)                                                    0.83004       0.83004       \n",
      "GM(G-mean geometric mean of specificity and sensitivity)          0.915         0.915         \n",
      "IBA(Index of balanced accuracy)                                   0.82895       0.84552       \n",
      "ICSI(Individual classification success index)                     0.82924       0.83092       \n",
      "IS(Information score)                                             0.87839       0.86545       \n",
      "J(Jaccard index)                                                  0.84263       0.84406       \n",
      "LS(Lift score)                                                    1.83833       1.82191       \n",
      "MCC(Matthews correlation coefficient)                             0.83008       0.83008       \n",
      "MCCI(Matthews correlation coefficient interpretation)             Strong        Strong        \n",
      "MCEN(Modified confusion entropy)                                  0.57681       0.57363       \n",
      "MK(Markedness)                                                    0.83012       0.83012       \n",
      "N(Condition negative)                                             1112          1112          \n",
      "NLR(Negative likelihood ratio)                                    0.09775       0.08794       \n",
      "NLRI(Negative likelihood ratio interpretation)                    Good          Good          \n",
      "NPV(Negative predictive value)                                    0.91095       0.91916       \n",
      "OC(Overlap coefficient)                                           0.91916       0.91996       \n",
      "OOC(Otsuka-Ochiai coefficient)                                    0.91461       0.91545       \n",
      "OP(Optimized precision)                                           0.90961       0.90961       \n",
      "P(Condition positive or support)                                  1112          1112          \n",
      "PLR(Positive likelihood ratio)                                    11.37079      10.23         \n",
      "PLRI(Positive likelihood ratio interpretation)                    Good          Good          \n",
      "POP(Population)                                                   2224          2224          \n",
      "PPV(Precision or positive predictive value)                       0.91916       0.91095       \n",
      "PRE(Prevalence)                                                   0.5           0.5           \n",
      "Q(Yule Q - coefficient of colligation)                            0.98295       0.98295       \n",
      "QI(Yule Q interpretation)                                         Strong        Strong        \n",
      "RACC(Random accuracy)                                             0.24753       0.25247       \n",
      "RACCU(Random accuracy unbiased)                                   0.24753       0.25248       \n",
      "TN(True negative/correct rejection)                               1023          1012          \n",
      "TNR(Specificity or true negative rate)                            0.91996       0.91007       \n",
      "TON(Test outcome negative)                                        1123          1101          \n",
      "TOP(Test outcome positive)                                        1101          1123          \n",
      "TP(True positive/hit)                                             1012          1023          \n",
      "TPR(Sensitivity, recall, hit rate, or true positive rate)         0.91007       0.91996       \n",
      "Y(Youden index)                                                   0.83004       0.83004       \n",
      "dInd(Distance index)                                              0.12039       0.12039       \n",
      "sInd(Similarity index)                                            0.91487       0.91487       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm.stat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./dbrd_model/vocab.json', './dbrd_model/merges.txt')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import WEIGHTS_NAME, CONFIG_NAME\n",
    "\n",
    "output_dir = \"./dbrd_model/\"\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "\n",
    "# If we save using the predefined names, we can load using `from_pretrained`\n",
    "output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
    "\n",
    "output_config_file = os.path.join(output_dir, CONFIG_NAME)\n",
    "\n",
    "torch.save(model.state_dict(), \"./dbrd_model/model.pt\")\n",
    "model_to_save.config.to_json_file(output_config_file)\n",
    "model_to_save.config.to_json_file(output_model_file)\n",
    "tokenizer.save_vocabulary(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in ./dbrd_model/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in ./dbrd_model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "## Save finetuned model\n",
    "model.save_pretrained(\"./dbrd_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file ./dbrd_model/config.json\n",
      "INFO:transformers.configuration_utils:Model config RobertaConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file ./dbrd_model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "## Load finetuned model\n",
    "model = model.from_pretrained(\"./dbrd_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, model):\n",
    "    results = []\n",
    "    for item in dataset:\n",
    "        tokenized_text = tokenizer.encode(tokenizer.tokenize(item))\n",
    "        \n",
    "        pad_token = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "        \n",
    "        input_mask = [0] * len(tokenized_text)\n",
    "        \n",
    "        batch = tuple(torch.tensor(t).to(torch.device(\"cpu\")) for t in [tokenized_text[0 : len(tokenized_text)], input_mask[0 : len(tokenized_text)], [0], [1]])\n",
    "        # Manually set a label but not use it, just to not break the code.\n",
    "        \n",
    "        inputs = {\"input_ids\": batch[0].unsqueeze(0), \"attention_mask\": batch[1].unsqueeze(0), \"labels\": batch[3].unsqueeze(0)}\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        results.append({\"text\": item, \"predicted\": outputs[1][0].argmax().item()})\n",
    "\n",
    "    model.train() # make sure the model is back in training mode\n",
    "    return results #, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [(\"Mijn vrouw vond het een prachtig boek, ik niet\"), (\"Mijn man vond het een prachtig boek, ik niet\"), (\"Mijn partner vond het een prachtig boek, ik niet\")]\n",
    "resulttest1 = pd.DataFrame(predict(texts, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               text  predicted\n",
      "0    Mijn vrouw vond het een prachtig boek, ik niet          1\n",
      "1      Mijn man vond het een prachtig boek, ik niet          1\n",
      "2  Mijn partner vond het een prachtig boek, ik niet          1\n"
     ]
    }
   ],
   "source": [
    "print(resulttest1)\n",
    "\n",
    "## 0 is negative, 1 is positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [(\"Mijn vrouw vond het geen mooi boek, ik wel\"), (\"Mijn man vond het geen mooi boek, ik wel\")]\n",
    "resulttest2 = pd.DataFrame(predict(texts, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         text  predicted\n",
      "0  Mijn vrouw vond het geen mooi boek, ik wel          0\n",
      "1    Mijn man vond het geen mooi boek, ik wel          0\n"
     ]
    }
   ],
   "source": [
    "print(resulttest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"De tijden dat boeken lezen leuk was zijn er niet meer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "textsss = [(text)]\n",
    "result_textsss = pd.DataFrame(predict(textsss, model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
